{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold, TimeSeriesSplit, StratifiedKFold, GroupKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gc, re, sys, os, datetime, pickle\n",
    "from sklearn.metrics import roc_auc_score\n",
    "sys.path.append('..')\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(590540, 806)\n",
      "(506691, 806)\n"
     ]
    }
   ],
   "source": [
    "train_df = pickle.load(open('../input/df_train_baseline.pkl', 'rb'))\n",
    "test_df = pickle.load(open('../input/df_test_baseline.pkl', 'rb'))\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 1295.31 Mb (43.0% reduction)\n",
      "Mem. usage decreased to 1119.21 Mb (42.8% reduction)\n"
     ]
    }
   ],
   "source": [
    "train_df = reduce_mem_usage(train_df)\n",
    "test_df  = reduce_mem_usage(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\高铭\\AppData\\Roaming\\Python\\Python36\\site-packages\\lightgbm\\engine.py:123: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.951499\tvalid_1's auc: 0.89813\n",
      "[200]\ttraining's auc: 0.978144\tvalid_1's auc: 0.91533\n",
      "[300]\ttraining's auc: 0.990859\tvalid_1's auc: 0.923991\n",
      "[400]\ttraining's auc: 0.996123\tvalid_1's auc: 0.929344\n",
      "[500]\ttraining's auc: 0.998393\tvalid_1's auc: 0.93242\n",
      "[600]\ttraining's auc: 0.999303\tvalid_1's auc: 0.93403\n",
      "[700]\ttraining's auc: 0.999684\tvalid_1's auc: 0.934962\n",
      "[800]\ttraining's auc: 0.999853\tvalid_1's auc: 0.93574\n",
      "[900]\ttraining's auc: 0.999933\tvalid_1's auc: 0.936052\n",
      "[1000]\ttraining's auc: 0.999972\tvalid_1's auc: 0.936219\n",
      "[1100]\ttraining's auc: 0.999989\tvalid_1's auc: 0.936282\n",
      "[1200]\ttraining's auc: 0.999996\tvalid_1's auc: 0.936413\n",
      "[1300]\ttraining's auc: 0.999999\tvalid_1's auc: 0.9362\n",
      "Early stopping, best iteration is:\n",
      "[1208]\ttraining's auc: 0.999996\tvalid_1's auc: 0.936452\n"
     ]
    }
   ],
   "source": [
    "features = [x for x in train_df.columns if x not in remove_features and train_df[x].dtype!='object']\n",
    "params = {\n",
    "                    'objective':'binary',\n",
    "                    'boosting_type':'gbdt',\n",
    "                    'metric':'auc',\n",
    "                    'n_jobs':-1,\n",
    "                    'learning_rate':0.01,\n",
    "                    'num_leaves': 2**8,\n",
    "                    'max_depth':-1,\n",
    "                    'tree_learner':'serial',\n",
    "                    'colsample_bytree': 0.7,\n",
    "                    'subsample_freq':1,\n",
    "                    'subsample':0.7,\n",
    "                    'n_estimators':80000,\n",
    "                    'max_bin':255,\n",
    "                    'verbose':100,\n",
    "                    'seed': 42,\n",
    "                    'early_stopping_rounds':100, \n",
    "                } \n",
    "_, model = local_valid(train_df, 'isFraud', features, params, return_model=True, sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column: C1 - 0.93444\n",
      "column: C2 - 0.93588\n",
      "column: C3 - 0.93639\n",
      "column: C4 - 0.93651\n",
      "column: C5 - 0.93629\n",
      "column: C6 - 0.93587\n",
      "column: C7 - 0.93648\n",
      "column: C8 - 0.93631\n",
      "column: C9 - 0.93622\n",
      "column: C10 - 0.93644\n",
      "column: C11 - 0.9348\n",
      "column: C12 - 0.93648\n",
      "column: C13 - 0.93157\n",
      "column: C14 - 0.93436\n",
      "column: D1 - 0.9363\n",
      "column: D2 - 0.93622\n",
      "column: D3 - 0.93645\n",
      "column: D4 - 0.93635\n",
      "column: D5 - 0.93644\n",
      "column: D6 - 0.93651\n",
      "column: D7 - 0.93645\n",
      "column: D8 - 0.93643\n",
      "column: D9 - 0.9365\n",
      "column: D10 - 0.93639\n",
      "column: D11 - 0.9364\n",
      "column: D12 - 0.93644\n",
      "column: D13 - 0.93646\n",
      "column: D14 - 0.93645\n",
      "column: D15 - 0.93637\n",
      "column: M1 - 0.93644\n",
      "column: M2 - 0.93644\n",
      "column: M3 - 0.93609\n",
      "column: M4 - 0.93458\n",
      "column: M5 - 0.93445\n",
      "column: M6 - 0.93523\n",
      "column: M7 - 0.93639\n",
      "column: M8 - 0.93644\n",
      "column: M9 - 0.93636\n",
      "column: is_december - 0.93645\n",
      "column: is_holiday - 0.93645\n",
      "column: card1_fq_enc - 0.93646\n",
      "column: card2_fq_enc - 0.93643\n",
      "column: card3_fq_enc - 0.93655\n",
      "column: card5_fq_enc - 0.93645\n",
      "column: uid_fq_enc - 0.93644\n",
      "column: uid2_fq_enc - 0.93649\n",
      "column: uid3_fq_enc - 0.93638\n",
      "column: uid4_fq_enc - 0.93637\n",
      "column: uid5_fq_enc - 0.93641\n",
      "column: card3_DT_D_hour_dist - 0.93641\n",
      "column: card3_DT_W_week_day_dist - 0.9364\n",
      "column: card3_DT_M_month_day_dist - 0.93636\n",
      "column: card3_DT_D_hour_dist_best - 0.93653\n",
      "column: card3_DT_W_week_day_dist_best - 0.93648\n",
      "column: card3_DT_M_month_day_dist_best - 0.93647\n",
      "column: card5_DT_D_hour_dist - 0.93629\n",
      "column: card5_DT_W_week_day_dist - 0.93641\n",
      "column: card5_DT_M_month_day_dist - 0.93648\n",
      "column: card5_DT_D_hour_dist_best - 0.93643\n",
      "column: card5_DT_W_week_day_dist_best - 0.93647\n",
      "column: card5_DT_M_month_day_dist_best - 0.93626\n",
      "column: bank_type_DT_D_hour_dist - 0.93645\n",
      "column: bank_type_DT_W_week_day_dist - 0.93644\n",
      "column: bank_type_DT_M_month_day_dist - 0.93648\n",
      "column: bank_type_DT_D_hour_dist_best - 0.93645\n",
      "column: bank_type_DT_W_week_day_dist_best - 0.93642\n",
      "column: bank_type_DT_M_month_day_dist_best - 0.93638\n",
      "column: uid_DT_M - 0.93649\n",
      "column: uid2_DT_M - 0.93639\n",
      "column: uid3_DT_M - 0.93632\n",
      "column: uid4_DT_M - 0.93641\n",
      "column: uid5_DT_M - 0.93623\n",
      "column: bank_type_DT_M - 0.93643\n",
      "column: uid_DT_W - 0.93642\n",
      "column: uid2_DT_W - 0.9365\n",
      "column: uid3_DT_W - 0.93645\n",
      "column: uid4_DT_W - 0.93613\n",
      "column: uid5_DT_W - 0.93638\n",
      "column: bank_type_DT_W - 0.93651\n",
      "column: uid_DT_D - 0.93646\n",
      "column: uid2_DT_D - 0.93652\n",
      "column: uid3_DT_D - 0.93646\n",
      "column: uid4_DT_D - 0.93646\n",
      "column: uid5_DT_D - 0.93629\n",
      "column: bank_type_DT_D - 0.93651\n",
      "column: uid_D1_mean - 0.93645\n",
      "column: uid_D1_std - 0.93642\n",
      "column: uid2_D1_mean - 0.93647\n",
      "column: uid2_D1_std - 0.93646\n",
      "column: uid3_D1_mean - 0.93646\n",
      "column: uid3_D1_std - 0.93641\n",
      "column: uid4_D1_mean - 0.93635\n",
      "column: uid4_D1_std - 0.93641\n",
      "column: uid5_D1_mean - 0.93652\n",
      "column: uid5_D1_std - 0.93653\n",
      "column: bank_type_D1_mean - 0.93647\n",
      "column: bank_type_D1_std - 0.93647\n",
      "column: uid_D2_mean - 0.93633\n",
      "column: uid_D2_std - 0.93641\n",
      "column: uid2_D2_mean - 0.93645\n",
      "column: uid2_D2_std - 0.93638\n",
      "column: uid3_D2_mean - 0.93649\n",
      "column: uid3_D2_std - 0.93643\n",
      "column: uid4_D2_mean - 0.93622\n",
      "column: uid4_D2_std - 0.93631\n",
      "column: uid5_D2_mean - 0.93656\n",
      "column: uid5_D2_std - 0.93636\n",
      "column: bank_type_D2_mean - 0.93647\n",
      "column: bank_type_D2_std - 0.93652\n",
      "column: uid_D3_mean - 0.93634\n",
      "column: uid_D3_std - 0.93637\n",
      "column: uid2_D3_mean - 0.93641\n",
      "column: uid2_D3_std - 0.9364\n",
      "column: uid3_D3_mean - 0.93648\n",
      "column: uid3_D3_std - 0.93645\n",
      "column: uid4_D3_mean - 0.93614\n",
      "column: uid4_D3_std - 0.93639\n",
      "column: uid5_D3_mean - 0.93652\n",
      "column: uid5_D3_std - 0.93644\n",
      "column: bank_type_D3_mean - 0.93644\n",
      "column: bank_type_D3_std - 0.93653\n",
      "column: uid_D4_mean - 0.93648\n",
      "column: uid_D4_std - 0.93656\n",
      "column: uid2_D4_mean - 0.93649\n",
      "column: uid2_D4_std - 0.93647\n",
      "column: uid3_D4_mean - 0.93647\n",
      "column: uid3_D4_std - 0.93641\n",
      "column: uid4_D4_mean - 0.93627\n",
      "column: uid4_D4_std - 0.93641\n",
      "column: uid5_D4_mean - 0.93634\n",
      "column: uid5_D4_std - 0.93651\n",
      "column: bank_type_D4_mean - 0.93646\n",
      "column: bank_type_D4_std - 0.93646\n",
      "column: uid_D5_mean - 0.93653\n",
      "column: uid_D5_std - 0.9364\n",
      "column: uid2_D5_mean - 0.93641\n",
      "column: uid2_D5_std - 0.93644\n",
      "column: uid3_D5_mean - 0.93647\n",
      "column: uid3_D5_std - 0.93619\n",
      "column: uid4_D5_mean - 0.93641\n",
      "column: uid4_D5_std - 0.93623\n",
      "column: uid5_D5_mean - 0.93646\n",
      "column: uid5_D5_std - 0.93611\n",
      "column: bank_type_D5_mean - 0.93647\n",
      "column: bank_type_D5_std - 0.93647\n",
      "column: uid_D6_mean - 0.93633\n",
      "column: uid_D6_std - 0.93639\n",
      "column: uid2_D6_mean - 0.93639\n",
      "column: uid2_D6_std - 0.9365\n",
      "column: uid3_D6_mean - 0.93655\n",
      "column: uid3_D6_std - 0.9364\n",
      "column: uid4_D6_mean - 0.93638\n",
      "column: uid4_D6_std - 0.93631\n",
      "column: uid5_D6_mean - 0.93644\n",
      "column: uid5_D6_std - 0.93645\n",
      "column: bank_type_D6_mean - 0.9365\n",
      "column: bank_type_D6_std - 0.93647\n",
      "column: uid_D7_mean - 0.93634\n",
      "column: uid_D7_std - 0.9361\n",
      "column: uid2_D7_mean - 0.93646\n",
      "column: uid2_D7_std - 0.93617\n",
      "column: uid3_D7_mean - 0.93644\n",
      "column: uid3_D7_std - 0.93624\n",
      "column: uid4_D7_mean - 0.93648\n",
      "column: uid4_D7_std - 0.93636\n",
      "column: uid5_D7_mean - 0.93637\n",
      "column: uid5_D7_std - 0.93646\n",
      "column: bank_type_D7_mean - 0.93648\n",
      "column: bank_type_D7_std - 0.9365\n",
      "column: uid_D8_mean - 0.9362\n",
      "column: uid_D8_std - 0.93647\n",
      "column: uid2_D8_mean - 0.93634\n",
      "column: uid2_D8_std - 0.9363\n",
      "column: uid3_D8_mean - 0.93618\n",
      "column: uid3_D8_std - 0.93644\n",
      "column: uid4_D8_mean - 0.93645\n",
      "column: uid4_D8_std - 0.93643\n",
      "column: uid5_D8_mean - 0.93643\n",
      "column: uid5_D8_std - 0.93643\n",
      "column: bank_type_D8_mean - 0.93642\n",
      "column: bank_type_D8_std - 0.93645\n",
      "column: uid_D9_mean - 0.93635\n",
      "column: uid_D9_std - 0.93646\n",
      "column: uid2_D9_mean - 0.93622\n",
      "column: uid2_D9_std - 0.93621\n",
      "column: uid3_D9_mean - 0.93641\n",
      "column: uid3_D9_std - 0.93654\n",
      "column: uid4_D9_mean - 0.93611\n",
      "column: uid4_D9_std - 0.93639\n",
      "column: uid5_D9_mean - 0.93647\n",
      "column: uid5_D9_std - 0.93641\n",
      "column: bank_type_D9_mean - 0.9364\n",
      "column: bank_type_D9_std - 0.93645\n",
      "column: uid_D10_mean - 0.93643\n",
      "column: uid_D10_std - 0.93641\n",
      "column: uid2_D10_mean - 0.93642\n",
      "column: uid2_D10_std - 0.93636\n",
      "column: uid3_D10_mean - 0.9364\n",
      "column: uid3_D10_std - 0.93643\n",
      "column: uid4_D10_mean - 0.93642\n",
      "column: uid4_D10_std - 0.93635\n",
      "column: uid5_D10_mean - 0.93638\n",
      "column: uid5_D10_std - 0.93652\n",
      "column: bank_type_D10_mean - 0.93648\n",
      "column: bank_type_D10_std - 0.93646\n",
      "column: uid_D11_mean - 0.93648\n",
      "column: uid_D11_std - 0.93641\n",
      "column: uid2_D11_mean - 0.93648\n",
      "column: uid2_D11_std - 0.93638\n",
      "column: uid3_D11_mean - 0.93641\n",
      "column: uid3_D11_std - 0.93644\n",
      "column: uid4_D11_mean - 0.93635\n",
      "column: uid4_D11_std - 0.93652\n",
      "column: uid5_D11_mean - 0.93647\n",
      "column: uid5_D11_std - 0.93647\n",
      "column: bank_type_D11_mean - 0.93644\n",
      "column: bank_type_D11_std - 0.93638\n",
      "column: uid_D12_mean - 0.93643\n",
      "column: uid_D12_std - 0.9364\n",
      "column: uid2_D12_mean - 0.93645\n",
      "column: uid2_D12_std - 0.93642\n",
      "column: uid3_D12_mean - 0.93654\n",
      "column: uid3_D12_std - 0.93645\n",
      "column: uid4_D12_mean - 0.93643\n",
      "column: uid4_D12_std - 0.93642\n",
      "column: uid5_D12_mean - 0.93647\n",
      "column: uid5_D12_std - 0.93646\n",
      "column: bank_type_D12_mean - 0.93638\n",
      "column: bank_type_D12_std - 0.9364\n",
      "column: uid_D13_mean - 0.9364\n",
      "column: uid_D13_std - 0.93647\n",
      "column: uid2_D13_mean - 0.93649\n",
      "column: uid2_D13_std - 0.93641\n",
      "column: uid3_D13_mean - 0.93641\n",
      "column: uid3_D13_std - 0.93651\n",
      "column: uid4_D13_mean - 0.93643\n",
      "column: uid4_D13_std - 0.93645\n",
      "column: uid5_D13_mean - 0.93651\n",
      "column: uid5_D13_std - 0.9364\n",
      "column: bank_type_D13_mean - 0.93652\n",
      "column: bank_type_D13_std - 0.93647\n",
      "column: uid_D14_mean - 0.93646\n",
      "column: uid_D14_std - 0.93635\n",
      "column: uid2_D14_mean - 0.93644\n",
      "column: uid2_D14_std - 0.93647\n",
      "column: uid3_D14_mean - 0.93646\n",
      "column: uid3_D14_std - 0.93638\n",
      "column: uid4_D14_mean - 0.9364\n",
      "column: uid4_D14_std - 0.93635\n",
      "column: uid5_D14_mean - 0.93635\n",
      "column: uid5_D14_std - 0.93645\n",
      "column: bank_type_D14_mean - 0.93643\n",
      "column: bank_type_D14_std - 0.93648\n",
      "column: uid_D15_mean - 0.93649\n",
      "column: uid_D15_std - 0.9364\n",
      "column: uid2_D15_mean - 0.93642\n",
      "column: uid2_D15_std - 0.93642\n",
      "column: uid3_D15_mean - 0.93637\n",
      "column: uid3_D15_std - 0.93652\n",
      "column: uid4_D15_mean - 0.93625\n",
      "column: uid4_D15_std - 0.93652\n",
      "column: uid5_D15_mean - 0.93643\n",
      "column: uid5_D15_std - 0.93647\n",
      "column: bank_type_D15_mean - 0.93644\n",
      "column: bank_type_D15_std - 0.9365\n",
      "column: D9_not_na - 0.93645\n",
      "column: D8_not_same_day - 0.93645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column: D8_D9_decimal_dist - 0.93643\n",
      "column: D3_DT_D_min_max - 0.93642\n",
      "column: D3_DT_D_std_score - 0.93628\n",
      "column: D4_DT_D_min_max - 0.93629\n",
      "column: D4_DT_D_std_score - 0.9363\n",
      "column: D5_DT_D_min_max - 0.9364\n",
      "column: D5_DT_D_std_score - 0.93644\n",
      "column: D6_DT_D_min_max - 0.93644\n",
      "column: D6_DT_D_std_score - 0.93641\n",
      "column: D7_DT_D_min_max - 0.93644\n",
      "column: D7_DT_D_std_score - 0.93645\n",
      "column: D8_DT_D_min_max - 0.93639\n",
      "column: D8_DT_D_std_score - 0.93644\n",
      "column: D10_DT_D_min_max - 0.93636\n",
      "column: D10_DT_D_std_score - 0.93625\n",
      "column: D11_DT_D_min_max - 0.93639\n",
      "column: D11_DT_D_std_score - 0.93637\n",
      "column: D12_DT_D_min_max - 0.93643\n",
      "column: D12_DT_D_std_score - 0.93641\n",
      "column: D13_DT_D_min_max - 0.93644\n",
      "column: D13_DT_D_std_score - 0.93666\n",
      "column: D14_DT_D_min_max - 0.93646\n",
      "column: D14_DT_D_std_score - 0.93635\n",
      "column: D15_DT_D_min_max - 0.93607\n",
      "column: D15_DT_D_std_score - 0.93633\n",
      "column: D3_DT_W_min_max - 0.93642\n",
      "column: D3_DT_W_std_score - 0.93648\n",
      "column: D4_DT_W_min_max - 0.93635\n",
      "column: D4_DT_W_std_score - 0.93623\n",
      "column: D5_DT_W_min_max - 0.93639\n",
      "column: D5_DT_W_std_score - 0.93648\n",
      "column: D6_DT_W_min_max - 0.93645\n",
      "column: D6_DT_W_std_score - 0.93642\n",
      "column: D7_DT_W_min_max - 0.93646\n",
      "column: D7_DT_W_std_score - 0.93646\n",
      "column: D8_DT_W_min_max - 0.93646\n",
      "column: D8_DT_W_std_score - 0.93649\n",
      "column: D10_DT_W_min_max - 0.93627\n",
      "column: D10_DT_W_std_score - 0.9364\n",
      "column: D11_DT_W_min_max - 0.9364\n",
      "column: D11_DT_W_std_score - 0.93639\n",
      "column: D12_DT_W_min_max - 0.93644\n",
      "column: D12_DT_W_std_score - 0.93646\n",
      "column: D13_DT_W_min_max - 0.93647\n",
      "column: D13_DT_W_std_score - 0.93643\n",
      "column: D14_DT_W_min_max - 0.93645\n",
      "column: D14_DT_W_std_score - 0.93643\n",
      "column: D15_DT_W_min_max - 0.93631\n",
      "column: D15_DT_W_std_score - 0.9361\n",
      "column: D3_DT_M_min_max - 0.93647\n",
      "column: D3_DT_M_std_score - 0.93647\n",
      "column: D4_DT_M_min_max - 0.93645\n",
      "column: D4_DT_M_std_score - 0.93636\n",
      "column: D5_DT_M_min_max - 0.93642\n",
      "column: D5_DT_M_std_score - 0.93641\n",
      "column: D6_DT_M_min_max - 0.93648\n",
      "column: D6_DT_M_std_score - 0.93644\n",
      "column: D7_DT_M_min_max - 0.93647\n",
      "column: D7_DT_M_std_score - 0.93644\n",
      "column: D8_DT_M_min_max - 0.93651\n",
      "column: D8_DT_M_std_score - 0.93647\n",
      "column: D10_DT_M_min_max - 0.93631\n",
      "column: D10_DT_M_std_score - 0.93639\n",
      "column: D11_DT_M_min_max - 0.93638\n",
      "column: D11_DT_M_std_score - 0.93634\n",
      "column: D12_DT_M_min_max - 0.93645\n",
      "column: D12_DT_M_std_score - 0.93644\n",
      "column: D13_DT_M_min_max - 0.93645\n",
      "column: D13_DT_M_std_score - 0.93642\n",
      "column: D14_DT_M_min_max - 0.93644\n",
      "column: D14_DT_M_std_score - 0.93637\n",
      "column: D15_DT_M_min_max - 0.93623\n",
      "column: D15_DT_M_std_score - 0.93647\n",
      "column: D1_scaled - 0.93562\n",
      "column: D2_scaled - 0.93359\n",
      "column: TransactionAmt_check - 0.93645\n",
      "column: card1_TransactionAmt_mean - 0.93637\n",
      "column: card1_TransactionAmt_std - 0.93646\n",
      "column: card2_TransactionAmt_mean - 0.93634\n",
      "column: card2_TransactionAmt_std - 0.93625\n",
      "column: card3_TransactionAmt_mean - 0.93639\n",
      "column: card3_TransactionAmt_std - 0.9364\n",
      "column: card5_TransactionAmt_mean - 0.93636\n",
      "column: card5_TransactionAmt_std - 0.93644\n",
      "column: uid_TransactionAmt_mean - 0.93635\n",
      "column: uid_TransactionAmt_std - 0.93645\n",
      "column: uid2_TransactionAmt_mean - 0.93624\n",
      "column: uid2_TransactionAmt_std - 0.93644\n",
      "column: uid3_TransactionAmt_mean - 0.93639\n",
      "column: uid3_TransactionAmt_std - 0.93632\n",
      "column: uid4_TransactionAmt_mean - 0.93641\n",
      "column: uid4_TransactionAmt_std - 0.9364\n",
      "column: uid5_TransactionAmt_mean - 0.93621\n",
      "column: uid5_TransactionAmt_std - 0.93646\n",
      "column: bank_type_TransactionAmt_mean - 0.93645\n",
      "column: bank_type_TransactionAmt_std - 0.93646\n",
      "column: TransactionAmt_DT_D_min_max - 0.93612\n",
      "column: TransactionAmt_DT_D_std_score - 0.93636\n",
      "column: TransactionAmt_DT_W_min_max - 0.93631\n",
      "column: TransactionAmt_DT_W_std_score - 0.93643\n",
      "column: TransactionAmt_DT_M_min_max - 0.93638\n",
      "column: TransactionAmt_DT_M_std_score - 0.9362\n",
      "column: product_type - 0.93635\n",
      "column: product_type_DT_D - 0.93613\n",
      "column: product_type_DT_W - 0.93612\n",
      "column: product_type_DT_M - 0.9361\n",
      "column: C1_fq_enc - 0.93352\n",
      "column: C2_fq_enc - 0.93596\n",
      "column: C3_fq_enc - 0.93634\n",
      "column: C4_fq_enc - 0.93656\n",
      "column: C5_fq_enc - 0.93632\n",
      "column: C6_fq_enc - 0.93593\n",
      "column: C7_fq_enc - 0.93645\n",
      "column: C8_fq_enc - 0.93637\n",
      "column: C9_fq_enc - 0.93621\n",
      "column: C10_fq_enc - 0.93645\n",
      "column: C11_fq_enc - 0.93541\n",
      "column: C12_fq_enc - 0.93645\n",
      "column: C13_fq_enc - 0.93608\n",
      "column: C14_fq_enc - 0.93631\n",
      "column: id_01 - 0.93638\n",
      "column: id_02 - 0.93613\n",
      "column: id_03 - 0.93647\n",
      "column: id_04 - 0.93643\n",
      "column: id_05 - 0.93632\n",
      "column: id_06 - 0.93645\n",
      "column: id_07 - 0.93642\n",
      "column: id_08 - 0.93644\n",
      "column: id_09 - 0.93646\n",
      "column: id_10 - 0.93645\n",
      "column: id_11 - 0.93641\n",
      "column: id_12 - 0.93645\n",
      "column: id_13 - 0.93644\n",
      "column: id_14 - 0.93635\n",
      "column: id_15 - 0.93648\n",
      "column: id_16 - 0.93645\n",
      "column: id_17 - 0.9364\n",
      "column: id_18 - 0.9365\n",
      "column: id_19 - 0.93635\n",
      "column: id_20 - 0.93628\n",
      "column: id_21 - 0.93645\n",
      "column: id_22 - 0.93645\n",
      "column: id_23 - 0.93645\n",
      "column: id_24 - 0.93645\n",
      "column: id_25 - 0.93646\n",
      "column: id_26 - 0.93645\n",
      "column: id_27 - 0.93645\n",
      "column: id_28 - 0.93645\n",
      "column: id_29 - 0.93644\n",
      "column: id_30 - 0.93642\n",
      "column: id_31 - 0.93632\n",
      "column: id_32 - 0.93645\n",
      "column: id_33 - 0.93643\n",
      "column: id_34 - 0.93646\n",
      "column: id_35 - 0.93645\n",
      "column: id_36 - 0.93646\n",
      "column: id_37 - 0.93645\n",
      "column: id_38 - 0.93642\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "train and valid dataset categorical_feature do not match.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-8ae08e65a026>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[0mX_val\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m             \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m             \u001b[0mres_lst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mX_val\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfreezed_col\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X, raw_score, num_iteration, pred_leaf, pred_contrib, **kwargs)\u001b[0m\n\u001b[0;32m    798\u001b[0m         \"\"\"\n\u001b[0;32m    799\u001b[0m         result = super(LGBMClassifier, self).predict(X, raw_score, num_iteration,\n\u001b[1;32m--> 800\u001b[1;33m                                                      pred_leaf, pred_contrib, **kwargs)\n\u001b[0m\u001b[0;32m    801\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_classes\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mraw_score\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mpred_leaf\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mpred_contrib\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    802\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X, raw_score, num_iteration, pred_leaf, pred_contrib, **kwargs)\u001b[0m\n\u001b[0;32m    605\u001b[0m                              % (self._n_features, n_features))\n\u001b[0;32m    606\u001b[0m         return self.booster_.predict(X, raw_score=raw_score, num_iteration=num_iteration,\n\u001b[1;32m--> 607\u001b[1;33m                                      pred_leaf=pred_leaf, pred_contrib=pred_contrib, **kwargs)\n\u001b[0m\u001b[0;32m    608\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, data, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, is_reshape, **kwargs)\u001b[0m\n\u001b[0;32m   2201\u001b[0m         return predictor.predict(data, num_iteration,\n\u001b[0;32m   2202\u001b[0m                                  \u001b[0mraw_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_leaf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_contrib\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2203\u001b[1;33m                                  data_has_header, is_reshape)\n\u001b[0m\u001b[0;32m   2204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2205\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrefit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecay_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.9\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, data, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, is_reshape)\u001b[0m\n\u001b[0;32m    434\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Cannot use Dataset instance for prediction, please use raw data instead\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 436\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_data_from_pandas\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpandas_categorical\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    437\u001b[0m         \u001b[0mpredict_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mC_API_PREDICT_NORMAL\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mraw_score\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36m_data_from_pandas\u001b[1;34m(data, feature_name, categorical_feature, pandas_categorical)\u001b[0m\n\u001b[0;32m    252\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcat_cols\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpandas_categorical\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 254\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train and valid dataset categorical_feature do not match.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    255\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategory\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcat_cols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpandas_categorical\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcategories\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcategory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: train and valid dataset categorical_feature do not match."
     ]
    }
   ],
   "source": [
    "df = train_df\n",
    "n = df.shape[0]\n",
    "valid_idx = list(df.index[int(n*0.8):])\n",
    "X_val, y_val = df.loc[valid_idx, features], df.loc[valid_idx, 'isFraud']\n",
    "columns = [x for x in features if not re.match('^V[0-9]+$', x) and 'emaildomain' not in x]\n",
    "\n",
    "# results = {}\n",
    "\n",
    "# y_pred = model.predict_proba(X_val)[:,1]\n",
    "\n",
    "# results['base_score'] = roc_auc_score(y_val, y_pred)\n",
    "# print(f'Base score {results[\"base_score\"]:.5}')\n",
    "\n",
    "for col in columns:\n",
    "    if col not in results:\n",
    "        res_lst = []\n",
    "        freezed_col = X_val[col].copy()\n",
    "        for _ in range(4):\n",
    "            X_val[col] = np.random.permutation(X_val[col])\n",
    "            preds = model.predict_proba(X_val)[:,1]\n",
    "            res_lst.append(roc_auc_score(y_val, preds))\n",
    "        X_val[col] = freezed_col\n",
    "        results[col] = np.mean(res_lst)\n",
    "        print(f'column: {col} - {results[col]:.5}')\n",
    "        gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base_score': 0.9364484865559555,\n",
       " 'TransactionAmt': 0.9360876007122682,\n",
       " 'ProductCD': 0.936033096132671,\n",
       " 'card1': 0.9362017147874546,\n",
       " 'card2': 0.9363244485327117,\n",
       " 'card3': 0.9364657679695806,\n",
       " 'card4': 0.9362822660897288,\n",
       " 'card5': 0.936394987424732,\n",
       " 'card6': 0.9359844014696151,\n",
       " 'addr1': 0.9360700005110958,\n",
       " 'addr2': 0.9364371207819844,\n",
       " 'dist1': 0.936077010061319,\n",
       " 'dist2': 0.9365781370740108,\n",
       " 'id_31_device': 0.936513038067639,\n",
       " 'C1': 0.9344426531904594,\n",
       " 'C2': 0.9358845260321546,\n",
       " 'C3': 0.9363910880758622,\n",
       " 'C4': 0.9365103939110253,\n",
       " 'C5': 0.9362886866111837,\n",
       " 'C6': 0.9358745767321262,\n",
       " 'C7': 0.9364755435816388,\n",
       " 'C8': 0.9363132084397872,\n",
       " 'C9': 0.9362231096931921,\n",
       " 'C10': 0.9364409440749419,\n",
       " 'C11': 0.9348015836959737,\n",
       " 'C12': 0.9364815617079827,\n",
       " 'C13': 0.9315731892970859,\n",
       " 'C14': 0.9343574398225771,\n",
       " 'D1': 0.9363048865205224,\n",
       " 'D2': 0.9362245256277311,\n",
       " 'D3': 0.9364536076540564,\n",
       " 'D4': 0.9363545699104392,\n",
       " 'D5': 0.9364404505206169,\n",
       " 'D6': 0.9365091171426237,\n",
       " 'D7': 0.9364490027652332,\n",
       " 'D8': 0.9364279865208469,\n",
       " 'D9': 0.9365034372223582,\n",
       " 'D10': 0.9363864006582829,\n",
       " 'D11': 0.9363962334471265,\n",
       " 'D12': 0.9364381434912744,\n",
       " 'D13': 0.9364578559970775,\n",
       " 'D14': 0.9364526378063226,\n",
       " 'D15': 0.9363715114997747,\n",
       " 'M1': 0.9364423163177866,\n",
       " 'M2': 0.9364379401361044,\n",
       " 'M3': 0.9360928895648992,\n",
       " 'M4': 0.9345843286337268,\n",
       " 'M5': 0.9344468443566954,\n",
       " 'M6': 0.9352315806302622,\n",
       " 'M7': 0.9363941589007503,\n",
       " 'M8': 0.9364392260743678,\n",
       " 'M9': 0.9363583656938115,\n",
       " 'is_december': 0.9364484865559555,\n",
       " 'is_holiday': 0.936445466435009,\n",
       " 'card1_fq_enc': 0.9364603728544335,\n",
       " 'card2_fq_enc': 0.936425239338139,\n",
       " 'card3_fq_enc': 0.9365474919353547,\n",
       " 'card5_fq_enc': 0.9364531497003713,\n",
       " 'uid_fq_enc': 0.936442820120781,\n",
       " 'uid2_fq_enc': 0.9364852803566355,\n",
       " 'uid3_fq_enc': 0.9363812245410116,\n",
       " 'uid4_fq_enc': 0.9363686585939548,\n",
       " 'uid5_fq_enc': 0.9364115341706074,\n",
       " 'card3_DT_D_hour_dist': 0.9364117655747665,\n",
       " 'card3_DT_W_week_day_dist': 0.9363968219364912,\n",
       " 'card3_DT_M_month_day_dist': 0.9363605686182526,\n",
       " 'card3_DT_D_hour_dist_best': 0.9365254567575038,\n",
       " 'card3_DT_W_week_day_dist_best': 0.9364793949235853,\n",
       " 'card3_DT_M_month_day_dist_best': 0.9364738023867083,\n",
       " 'card5_DT_D_hour_dist': 0.9362866309439344,\n",
       " 'card5_DT_W_week_day_dist': 0.9364148768549272,\n",
       " 'card5_DT_M_month_day_dist': 0.9364762539762247,\n",
       " 'card5_DT_D_hour_dist_best': 0.9364255877928868,\n",
       " 'card5_DT_W_week_day_dist_best': 0.9364702763051531,\n",
       " 'card5_DT_M_month_day_dist_best': 0.9362634538485906,\n",
       " 'bank_type_DT_D_hour_dist': 0.9364453714999694,\n",
       " 'bank_type_DT_W_week_day_dist': 0.9364388447159985,\n",
       " 'bank_type_DT_M_month_day_dist': 0.936478145664769,\n",
       " 'bank_type_DT_D_hour_dist_best': 0.93645075528764,\n",
       " 'bank_type_DT_W_week_day_dist_best': 0.9364174444162248,\n",
       " 'bank_type_DT_M_month_day_dist_best': 0.936384137320635,\n",
       " 'uid_DT_M': 0.9364871251170637,\n",
       " 'uid2_DT_M': 0.9363915266110164,\n",
       " 'uid3_DT_M': 0.9363190129622923,\n",
       " 'uid4_DT_M': 0.9364111139751765,\n",
       " 'uid5_DT_M': 0.9362274135947874,\n",
       " 'bank_type_DT_M': 0.9364326777142514,\n",
       " 'uid_DT_W': 0.9364205670238617,\n",
       " 'uid2_DT_W': 0.9364997018521931,\n",
       " 'uid3_DT_W': 0.9364460204025412,\n",
       " 'uid4_DT_W': 0.9361286951781217,\n",
       " 'uid5_DT_W': 0.9363844329138262,\n",
       " 'bank_type_DT_W': 0.9365133546975722,\n",
       " 'uid_DT_D': 0.9364572793745929,\n",
       " 'uid2_DT_D': 0.936517787516636,\n",
       " 'uid3_DT_D': 0.9364591705237335,\n",
       " 'uid4_DT_D': 0.9364551945795475,\n",
       " 'uid5_DT_D': 0.9362879357613252,\n",
       " 'bank_type_DT_D': 0.9365132635383581,\n",
       " 'uid_D1_mean': 0.9364510729963804,\n",
       " 'uid_D1_std': 0.9364205211745529,\n",
       " 'uid2_D1_mean': 0.936466210819964,\n",
       " 'uid2_D1_std': 0.936458083625411,\n",
       " 'uid3_D1_mean': 0.9364572340646875,\n",
       " 'uid3_D1_std': 0.9364089374815137,\n",
       " 'uid4_D1_mean': 0.9363483203799362,\n",
       " 'uid4_D1_std': 0.936410823236618,\n",
       " 'uid5_D1_mean': 0.9365153461757889,\n",
       " 'uid5_D1_std': 0.9365331642960294,\n",
       " 'bank_type_D1_mean': 0.9364701856853427,\n",
       " 'bank_type_D1_std': 0.9364743002562624,\n",
       " 'uid_D2_mean': 0.9363286537234421,\n",
       " 'uid_D2_std': 0.936408886777572,\n",
       " 'uid2_D2_mean': 0.9364521447914012,\n",
       " 'uid2_D2_std': 0.9363762906159717,\n",
       " 'uid3_D2_mean': 0.9364882864530875,\n",
       " 'uid3_D2_std': 0.9364312358883379,\n",
       " 'uid4_D2_mean': 0.9362238222453927,\n",
       " 'uid4_D2_std': 0.9363144997720868,\n",
       " 'uid5_D2_mean': 0.9365577379073817,\n",
       " 'uid5_D2_std': 0.9363568979765236,\n",
       " 'bank_type_D2_mean': 0.9364650257501801,\n",
       " 'bank_type_D2_std': 0.9365191937419097,\n",
       " 'uid_D3_mean': 0.9363356940196724,\n",
       " 'uid_D3_std': 0.9363716760178832,\n",
       " 'uid2_D3_mean': 0.9364097784117789,\n",
       " 'uid2_D3_std': 0.936401941416381,\n",
       " 'uid3_D3_mean': 0.9364841352027204,\n",
       " 'uid3_D3_std': 0.9364498248163715,\n",
       " 'uid4_D3_mean': 0.9361435028866811,\n",
       " 'uid4_D3_std': 0.9363921825258354,\n",
       " 'uid5_D3_mean': 0.9365242355476766,\n",
       " 'uid5_D3_std': 0.9364386656339921,\n",
       " 'bank_type_D3_mean': 0.9364402266681088,\n",
       " 'bank_type_D3_std': 0.9365322456916408,\n",
       " 'uid_D4_mean': 0.9364759858926186,\n",
       " 'uid_D4_std': 0.9365622888558416,\n",
       " 'uid2_D4_mean': 0.9364942603483335,\n",
       " 'uid2_D4_std': 0.9364675242678127,\n",
       " 'uid3_D4_mean': 0.9364654205936402,\n",
       " 'uid3_D4_std': 0.9364067275448252,\n",
       " 'uid4_D4_mean': 0.9362670705499562,\n",
       " 'uid4_D4_std': 0.936405367708264,\n",
       " 'uid5_D4_mean': 0.9363434447104888,\n",
       " 'uid5_D4_std': 0.9365094995798003,\n",
       " 'bank_type_D4_mean': 0.9364614915775704,\n",
       " 'bank_type_D4_std': 0.9364623157863231,\n",
       " 'uid_D5_mean': 0.9365312402432672,\n",
       " 'uid_D5_std': 0.9363953045940688,\n",
       " 'uid2_D5_mean': 0.936413531582264,\n",
       " 'uid2_D5_std': 0.9364431599450702,\n",
       " 'uid3_D5_mean': 0.9364727192642112,\n",
       " 'uid3_D5_std': 0.9361897033473336,\n",
       " 'uid4_D5_mean': 0.9364139846813165,\n",
       " 'uid4_D5_std': 0.9362260127635501,\n",
       " 'uid5_D5_mean': 0.9364550656620789,\n",
       " 'uid5_D5_std': 0.936108418995521,\n",
       " 'bank_type_D5_mean': 0.9364695605165309,\n",
       " 'bank_type_D5_std': 0.9364694299808515,\n",
       " 'uid_D6_mean': 0.9363290205179131,\n",
       " 'uid_D6_std': 0.9363864637685082,\n",
       " 'uid2_D6_mean': 0.9363942872788151,\n",
       " 'uid2_D6_std': 0.9365038655088435,\n",
       " 'uid3_D6_mean': 0.936551769406172,\n",
       " 'uid3_D6_std': 0.9363968435126364,\n",
       " 'uid4_D6_mean': 0.9363839555416102,\n",
       " 'uid4_D6_std': 0.9363134716687606,\n",
       " 'uid5_D6_mean': 0.9364404952911185,\n",
       " 'uid5_D6_std': 0.9364546292845392,\n",
       " 'bank_type_D6_mean': 0.9365021059741895,\n",
       " 'bank_type_D6_std': 0.936468801575618,\n",
       " 'uid_D7_mean': 0.9363386337694775,\n",
       " 'uid_D7_std': 0.9361034036205325,\n",
       " 'uid2_D7_mean': 0.9364588506573785,\n",
       " 'uid2_D7_std': 0.9361736776653686,\n",
       " 'uid3_D7_mean': 0.936438419665935,\n",
       " 'uid3_D7_std': 0.9362435762852754,\n",
       " 'uid4_D7_mean': 0.9364759141519353,\n",
       " 'uid4_D7_std': 0.9363600858520001,\n",
       " 'uid5_D7_mean': 0.9363712159065833,\n",
       " 'uid5_D7_std': 0.9364632273784645,\n",
       " 'bank_type_D7_mean': 0.9364803680077408,\n",
       " 'bank_type_D7_std': 0.9364992368862606,\n",
       " 'uid_D8_mean': 0.9361960542857197,\n",
       " 'uid_D8_std': 0.9364699990516852,\n",
       " 'uid2_D8_mean': 0.9363427580496628,\n",
       " 'uid2_D8_std': 0.9362956767428762,\n",
       " 'uid3_D8_mean': 0.9361797195254725,\n",
       " 'uid3_D8_std': 0.9364393415067453,\n",
       " 'uid4_D8_mean': 0.9364514888765822,\n",
       " 'uid4_D8_std': 0.936433098449086,\n",
       " 'uid5_D8_mean': 0.9364332996466415,\n",
       " 'uid5_D8_std': 0.9364262248285784,\n",
       " 'bank_type_D8_mean': 0.9364220719600005,\n",
       " 'bank_type_D8_std': 0.9364454987992272,\n",
       " 'uid_D9_mean': 0.9363475263777872,\n",
       " 'uid_D9_std': 0.9364569665204852,\n",
       " 'uid2_D9_mean': 0.9362197918214394,\n",
       " 'uid2_D9_std': 0.9362130325545023,\n",
       " 'uid3_D9_mean': 0.9364095971721579,\n",
       " 'uid3_D9_std': 0.9365369304122018,\n",
       " 'uid4_D9_mean': 0.9361070327281817,\n",
       " 'uid4_D9_std': 0.936391699759583,\n",
       " 'uid5_D9_mean': 0.9364721917274572,\n",
       " 'uid5_D9_std': 0.9364100184463959,\n",
       " 'bank_type_D9_mean': 0.9363979735632497,\n",
       " 'bank_type_D9_std': 0.9364485453509517,\n",
       " 'uid_D10_mean': 0.936432404236609,\n",
       " 'uid_D10_std': 0.9364121647334556,\n",
       " 'uid2_D10_mean': 0.9364151978000894,\n",
       " 'uid2_D10_std': 0.9363609699345563,\n",
       " 'uid3_D10_mean': 0.9363995097847991,\n",
       " 'uid3_D10_std': 0.9364279735751597,\n",
       " 'uid4_D10_mean': 0.9364222262294397,\n",
       " 'uid4_D10_std': 0.9363464065758429,\n",
       " 'uid5_D10_mean': 0.9363767776974532,\n",
       " 'uid5_D10_std': 0.9365229404395513,\n",
       " 'bank_type_D10_mean': 0.9364804888341549,\n",
       " 'bank_type_D10_std': 0.9364556730305709,\n",
       " 'uid_D11_mean': 0.9364788404166495,\n",
       " 'uid_D11_std': 0.9364103927925181,\n",
       " 'uid2_D11_mean': 0.9364818804955306,\n",
       " 'uid2_D11_std': 0.9363811846251425,\n",
       " 'uid3_D11_mean': 0.9364133028751231,\n",
       " 'uid3_D11_std': 0.9364393647011018,\n",
       " 'uid4_D11_mean': 0.9363464993532681,\n",
       " 'uid4_D11_std': 0.9365184784926911,\n",
       " 'uid5_D11_mean': 0.9364682718812494,\n",
       " 'uid5_D11_std': 0.9364711997641744,\n",
       " 'bank_type_D11_mean': 0.9364360058346731,\n",
       " 'bank_type_D11_std': 0.9363827936661828,\n",
       " 'uid_D12_mean': 0.9364270948866399,\n",
       " 'uid_D12_std': 0.9363984013103313,\n",
       " 'uid2_D12_mean': 0.9364457345186151,\n",
       " 'uid2_D12_std': 0.9364193943603616,\n",
       " 'uid3_D12_mean': 0.9365417111466096,\n",
       " 'uid3_D12_std': 0.9364526583036606,\n",
       " 'uid4_D12_mean': 0.9364344048846873,\n",
       " 'uid4_D12_std': 0.936422090299724,\n",
       " 'uid5_D12_mean': 0.9364653439983242,\n",
       " 'uid5_D12_std': 0.9364552528351401,\n",
       " 'bank_type_D12_mean': 0.9363820358040769,\n",
       " 'bank_type_D12_std': 0.9364011630569373,\n",
       " 'uid_D13_mean': 0.9364017364430002,\n",
       " 'uid_D13_std': 0.936465298688419,\n",
       " 'uid2_D13_mean': 0.9364911075340931,\n",
       " 'uid2_D13_std': 0.9364081440187682,\n",
       " 'uid3_D13_mean': 0.9364117375257773,\n",
       " 'uid3_D13_std': 0.9365098075792753,\n",
       " 'uid4_D13_mean': 0.9364308636998304,\n",
       " 'uid4_D13_std': 0.9364529921945101,\n",
       " 'uid5_D13_mean': 0.9365068947996518,\n",
       " 'uid5_D13_std': 0.9364032494701936,\n",
       " 'bank_type_D13_mean': 0.9365163375996679,\n",
       " 'bank_type_D13_std': 0.9364666364094312,\n",
       " 'uid_D14_mean': 0.9364647900307921,\n",
       " 'uid_D14_std': 0.936350270324073,\n",
       " 'uid2_D14_mean': 0.936444362815174,\n",
       " 'uid2_D14_std': 0.9364653067794734,\n",
       " 'uid3_D14_mean': 0.9364612261909825,\n",
       " 'uid3_D14_std': 0.9363821749702146,\n",
       " 'uid4_D14_mean': 0.9363998183236778,\n",
       " 'uid4_D14_std': 0.936350435381585,\n",
       " 'uid5_D14_mean': 0.9363526178086881,\n",
       " 'uid5_D14_std': 0.9364510212136316,\n",
       " 'bank_type_D14_mean': 0.9364345807302721,\n",
       " 'bank_type_D14_std': 0.9364794779917449,\n",
       " 'uid_D15_mean': 0.9364890928615204,\n",
       " 'uid_D15_std': 0.9363980695770965,\n",
       " 'uid2_D15_mean': 0.9364165457697706,\n",
       " 'uid2_D15_std': 0.9364219025872594,\n",
       " 'uid3_D15_mean': 0.9363743072288095,\n",
       " 'uid3_D15_std': 0.9365230488596819,\n",
       " 'uid4_D15_mean': 0.9362508555373157,\n",
       " 'uid4_D15_std': 0.936521620518859,\n",
       " 'uid5_D15_mean': 0.9364321048675923,\n",
       " 'uid5_D15_std': 0.9364656929924754,\n",
       " 'bank_type_D15_mean': 0.9364364853645036,\n",
       " 'bank_type_D15_std': 0.9365041379076787,\n",
       " 'D9_not_na': 0.9364487346816274,\n",
       " 'D8_not_same_day': 0.9364485572178316,\n",
       " 'D8_D9_decimal_dist': 0.9364284908632446,\n",
       " 'D3_DT_D_min_max': 0.9364155635157532,\n",
       " 'D3_DT_D_std_score': 0.936281111765952,\n",
       " 'D4_DT_D_min_max': 0.9362923577923163,\n",
       " 'D4_DT_D_std_score': 0.9362997411492581,\n",
       " 'D5_DT_D_min_max': 0.9363993948918252,\n",
       " 'D5_DT_D_std_score': 0.9364385766323926,\n",
       " 'D6_DT_D_min_max': 0.9364447231368015,\n",
       " 'D6_DT_D_std_score': 0.9364117186466503,\n",
       " 'D7_DT_D_min_max': 0.9364445586186931,\n",
       " 'D7_DT_D_std_score': 0.9364509634974428,\n",
       " 'D8_DT_D_min_max': 0.9363899364491037,\n",
       " 'D8_DT_D_std_score': 0.9364373532649506,\n",
       " 'D10_DT_D_min_max': 0.9363613841965471,\n",
       " 'D10_DT_D_std_score': 0.9362529710783682,\n",
       " 'D11_DT_D_min_max': 0.9363948806228125,\n",
       " 'D11_DT_D_std_score': 0.936368792366056,\n",
       " 'D12_DT_D_min_max': 0.936434110909707,\n",
       " 'D12_DT_D_std_score': 0.936407797721635,\n",
       " 'D13_DT_D_min_max': 0.9364369956403413,\n",
       " 'D13_DT_D_std_score': 0.9366551450338134,\n",
       " 'D14_DT_D_min_max': 0.9364598151110761,\n",
       " 'D14_DT_D_std_score': 0.9363464804741409,\n",
       " 'D15_DT_D_min_max': 0.936072987189017,\n",
       " 'D15_DT_D_std_score': 0.9363335234594494,\n",
       " 'D3_DT_W_min_max': 0.9364183295775881,\n",
       " 'D3_DT_W_std_score': 0.936484063462037,\n",
       " 'D4_DT_W_min_max': 0.9363503490770035,\n",
       " 'D4_DT_W_std_score': 0.9362342462206188,\n",
       " 'D5_DT_W_min_max': 0.9363874967264672,\n",
       " 'D5_DT_W_std_score': 0.9364798669017649,\n",
       " 'D6_DT_W_min_max': 0.9364508475256614,\n",
       " 'D6_DT_W_std_score': 0.9364180264327457,\n",
       " 'D7_DT_W_min_max': 0.9364606544231304,\n",
       " 'D7_DT_W_std_score': 0.9364616053917372,\n",
       " 'D8_DT_W_min_max': 0.9364562928053463,\n",
       " 'D8_DT_W_std_score': 0.9364907202422839,\n",
       " 'D10_DT_W_min_max': 0.9362732731523432,\n",
       " 'D10_DT_W_std_score': 0.9364022165122343,\n",
       " 'D11_DT_W_min_max': 0.9364023961336445,\n",
       " 'D11_DT_W_std_score': 0.9363944577303636,\n",
       " 'D12_DT_W_min_max': 0.9364374341754957,\n",
       " 'D12_DT_W_std_score': 0.9364611096797976,\n",
       " 'D13_DT_W_min_max': 0.9364662879546836,\n",
       " 'D13_DT_W_std_score': 0.9364287411465309,\n",
       " 'D14_DT_W_min_max': 0.9364538239549136,\n",
       " 'D14_DT_W_std_score': 0.9364310595033496,\n",
       " 'D15_DT_W_min_max': 0.9363078856047273,\n",
       " 'D15_DT_W_std_score': 0.9360980424878146,\n",
       " 'D3_DT_M_min_max': 0.9364692633051286,\n",
       " 'D3_DT_M_std_score': 0.936467886207651,\n",
       " 'D4_DT_M_min_max': 0.9364481774776734,\n",
       " 'D4_DT_M_std_score': 0.9363562442193192,\n",
       " 'D5_DT_M_min_max': 0.9364209224908565,\n",
       " 'D5_DT_M_std_score': 0.9364145300183906,\n",
       " 'D6_DT_M_min_max': 0.9364763872089222,\n",
       " 'D6_DT_M_std_score': 0.9364392783965204,\n",
       " 'D7_DT_M_min_max': 0.9364682875239547,\n",
       " 'D7_DT_M_std_score': 0.9364402946329666,\n",
       " 'D8_DT_M_min_max': 0.9365085286532592,\n",
       " 'D8_DT_M_std_score': 0.9364698534127041,\n",
       " 'D10_DT_M_min_max': 0.9363147020484496,\n",
       " 'D10_DT_M_std_score': 0.9363853644639022,\n",
       " 'D11_DT_M_min_max': 0.9363757199269269,\n",
       " 'D11_DT_M_std_score': 0.9363425530762819,\n",
       " 'D12_DT_M_min_max': 0.9364478910543437,\n",
       " 'D12_DT_M_std_score': 0.9364423691793429,\n",
       " 'D13_DT_M_min_max': 0.9364528805379578,\n",
       " 'D13_DT_M_std_score': 0.9364172513097238,\n",
       " 'D14_DT_M_min_max': 0.9364434749567926,\n",
       " 'D14_DT_M_std_score': 0.9363651637978103,\n",
       " 'D15_DT_M_min_max': 0.9362332903973793,\n",
       " 'D15_DT_M_std_score': 0.9364664373694902,\n",
       " 'D1_scaled': 0.9356199258947439,\n",
       " 'D2_scaled': 0.9335937543152291,\n",
       " 'TransactionAmt_check': 0.9364483603355052,\n",
       " 'card1_TransactionAmt_mean': 0.9363734700743697,\n",
       " 'card1_TransactionAmt_std': 0.9364558602036318,\n",
       " 'card2_TransactionAmt_mean': 0.9363413631518653,\n",
       " 'card2_TransactionAmt_std': 0.9362533826433408,\n",
       " 'card3_TransactionAmt_mean': 0.9363856546630571,\n",
       " 'card3_TransactionAmt_std': 0.9364038730207944,\n",
       " 'card5_TransactionAmt_mean': 0.936358724397228,\n",
       " 'card5_TransactionAmt_std': 0.9364369535668579,\n",
       " 'uid_TransactionAmt_mean': 0.9363451082312959,\n",
       " 'uid_TransactionAmt_std': 0.9364516512370761,\n",
       " 'uid2_TransactionAmt_mean': 0.9362365537893649,\n",
       " 'uid2_TransactionAmt_std': 0.9364394563997194,\n",
       " 'uid3_TransactionAmt_mean': 0.9363945127495341,\n",
       " 'uid3_TransactionAmt_std': 0.9363234867760323,\n",
       " 'uid4_TransactionAmt_mean': 0.9364114424719896,\n",
       " 'uid4_TransactionAmt_std': 0.9364033481810583,\n",
       " 'uid5_TransactionAmt_mean': 0.9362054285814744,\n",
       " 'uid5_TransactionAmt_std': 0.936458278350123,\n",
       " 'bank_type_TransactionAmt_mean': 0.9364461423077624,\n",
       " 'bank_type_TransactionAmt_std': 0.9364578608517102,\n",
       " 'TransactionAmt_DT_D_min_max': 0.9361190042524339,\n",
       " 'TransactionAmt_DT_D_std_score': 0.9363616371768515,\n",
       " 'TransactionAmt_DT_W_min_max': 0.9363068812351608,\n",
       " 'TransactionAmt_DT_W_std_score': 0.9364321393894247,\n",
       " 'TransactionAmt_DT_M_min_max': 0.9363792681240312,\n",
       " 'TransactionAmt_DT_M_std_score': 0.9361976751936398,\n",
       " 'product_type': 0.9363497573512171,\n",
       " 'product_type_DT_D': 0.9361277253303877,\n",
       " 'product_type_DT_W': 0.9361204239627984,\n",
       " 'product_type_DT_M': 0.9361006165219558,\n",
       " 'C1_fq_enc': 0.933516819174917,\n",
       " 'C2_fq_enc': 0.9359633442305525,\n",
       " 'C3_fq_enc': 0.9363405481129745,\n",
       " 'C4_fq_enc': 0.936555848376452,\n",
       " 'C5_fq_enc': 0.9363217207685346,\n",
       " 'C6_fq_enc': 0.9359254009607287,\n",
       " 'C7_fq_enc': 0.9364496824138122,\n",
       " 'C8_fq_enc': 0.9363674168867894,\n",
       " 'C9_fq_enc': 0.9362110405368822,\n",
       " 'C10_fq_enc': 0.9364530272557463,\n",
       " 'C11_fq_enc': 0.9354136158716334,\n",
       " 'C12_fq_enc': 0.9364536815523542,\n",
       " 'C13_fq_enc': 0.9360763056001732,\n",
       " 'C14_fq_enc': 0.9363063278070324,\n",
       " 'id_01': 0.9363846470570691,\n",
       " 'id_02': 0.9361251971455554,\n",
       " 'id_03': 0.9364692557534777,\n",
       " 'id_04': 0.936434482019407,\n",
       " 'id_05': 0.9363242381652944,\n",
       " 'id_06': 0.9364477680703153,\n",
       " 'id_07': 0.9364194013726088,\n",
       " 'id_08': 0.936440515249053,\n",
       " 'id_09': 0.9364608469902278,\n",
       " 'id_10': 0.9364518799442169,\n",
       " 'id_11': 0.9364148752367162,\n",
       " 'id_12': 0.9364467933679486,\n",
       " 'id_13': 0.9364351239097314,\n",
       " 'id_14': 0.9363451476077613,\n",
       " 'id_15': 0.936478337153059,\n",
       " 'id_16': 0.9364493490623663,\n",
       " 'id_17': 0.9364048568930227,\n",
       " 'id_18': 0.9364990195065961,\n",
       " 'id_19': 0.9363517310291138,\n",
       " 'id_20': 0.9362812040039733,\n",
       " 'id_21': 0.9364500982940138,\n",
       " 'id_22': 0.9364485604542535,\n",
       " 'id_23': 0.9364469546496352,\n",
       " 'id_24': 0.9364455478849578,\n",
       " 'id_25': 0.9364621609774801,\n",
       " 'id_26': 0.936449265454803,\n",
       " 'id_27': 0.9364484865559555,\n",
       " 'id_28': 0.9364514845613532,\n",
       " 'id_29': 0.9364444016522355,\n",
       " 'id_30': 0.9364215940483809,\n",
       " 'id_31': 0.9363176903445818,\n",
       " 'id_32': 0.9364513292131066,\n",
       " 'id_33': 0.9364281213717554,\n",
       " 'id_34': 0.9364557490864834,\n",
       " 'id_35': 0.9364488824782229,\n",
       " 'id_36': 0.9364624625041115,\n",
       " 'id_37': 0.9364515476715785,\n",
       " 'id_38': 0.9364203755355718}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>C13</td>\n",
       "      <td>0.931573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>C1_fq_enc</td>\n",
       "      <td>0.933517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>D2_scaled</td>\n",
       "      <td>0.933594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>C14</td>\n",
       "      <td>0.934357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>C1</td>\n",
       "      <td>0.934443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>C4_fq_enc</td>\n",
       "      <td>0.936556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>uid5_D2_mean</td>\n",
       "      <td>0.936558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>uid_D4_std</td>\n",
       "      <td>0.936562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>dist2</td>\n",
       "      <td>0.936578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>D13_DT_D_std_score</td>\n",
       "      <td>0.936655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>439 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       score\n",
       "C13                 0.931573\n",
       "C1_fq_enc           0.933517\n",
       "D2_scaled           0.933594\n",
       "C14                 0.934357\n",
       "C1                  0.934443\n",
       "...                      ...\n",
       "C4_fq_enc           0.936556\n",
       "uid5_D2_mean        0.936558\n",
       "uid_D4_std          0.936562\n",
       "dist2               0.936578\n",
       "D13_DT_D_std_score  0.936655\n",
       "\n",
       "[439 rows x 1 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perm_imp = pd.DataFrame.from_dict(results, orient='index', columns=['score'])\n",
    "perm_imp.sort_values('score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm_imp.to_csv('../result/perm_imp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "371"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(perm_imp['score'] > 0.9363).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_features = pickle.load(open('../input/remove_features.pkl', 'rb'))\n",
    "remove_features = list(remove_features['features_to_remove'])\n",
    "remove_features += [x for x in results if x!='base_score' and results[x]>0.9364]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\高铭\\AppData\\Roaming\\Python\\Python36\\site-packages\\lightgbm\\engine.py:123: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.953555\tvalid_1's auc: 0.898551\n",
      "[200]\ttraining's auc: 0.974493\tvalid_1's auc: 0.913637\n",
      "[300]\ttraining's auc: 0.986777\tvalid_1's auc: 0.923242\n",
      "[400]\ttraining's auc: 0.993331\tvalid_1's auc: 0.929279\n",
      "[500]\ttraining's auc: 0.996806\tvalid_1's auc: 0.932651\n",
      "[600]\ttraining's auc: 0.998576\tvalid_1's auc: 0.934334\n",
      "[700]\ttraining's auc: 0.999406\tvalid_1's auc: 0.935317\n",
      "[800]\ttraining's auc: 0.999767\tvalid_1's auc: 0.936123\n",
      "[900]\ttraining's auc: 0.999915\tvalid_1's auc: 0.93669\n",
      "[1000]\ttraining's auc: 0.999973\tvalid_1's auc: 0.936946\n",
      "[1100]\ttraining's auc: 0.999993\tvalid_1's auc: 0.937491\n",
      "[1200]\ttraining's auc: 0.999999\tvalid_1's auc: 0.937688\n",
      "[1300]\ttraining's auc: 1\tvalid_1's auc: 0.937833\n",
      "[1400]\ttraining's auc: 1\tvalid_1's auc: 0.937913\n",
      "[1500]\ttraining's auc: 1\tvalid_1's auc: 0.938082\n",
      "Early stopping, best iteration is:\n",
      "[1439]\ttraining's auc: 1\tvalid_1's auc: 0.938031\n"
     ]
    }
   ],
   "source": [
    "features = [x for x in train_df.columns if x not in remove_features and train_df[x].dtype!='object']\n",
    "print(len(features))\n",
    "params = {\n",
    "                    'objective':'binary',\n",
    "                    'boosting_type':'gbdt',\n",
    "                    'metric':'auc',\n",
    "                    'n_jobs':-1,\n",
    "                    'learning_rate':0.01,\n",
    "                    'num_leaves': 2**8,\n",
    "                    'max_depth':-1,\n",
    "                    'tree_learner':'serial',\n",
    "                    'colsample_bytree': 0.7,\n",
    "                    'subsample_freq':1,\n",
    "                    'subsample':0.7,\n",
    "                    'n_estimators':80000,\n",
    "                    'max_bin':255,\n",
    "                    'verbose':100,\n",
    "                    'seed': 42,\n",
    "                    'early_stopping_rounds':100, \n",
    "                } \n",
    "_, model = local_valid(train_df, 'isFraud', features, params, return_model=True, sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\高铭\\AppData\\Roaming\\Python\\Python36\\site-packages\\lightgbm\\engine.py:123: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.955633\tvalid_1's auc: 0.899024\n",
      "[200]\ttraining's auc: 0.975971\tvalid_1's auc: 0.915457\n",
      "[300]\ttraining's auc: 0.987887\tvalid_1's auc: 0.924647\n",
      "[400]\ttraining's auc: 0.994276\tvalid_1's auc: 0.930303\n",
      "[500]\ttraining's auc: 0.997423\tvalid_1's auc: 0.933321\n",
      "[600]\ttraining's auc: 0.998912\tvalid_1's auc: 0.935142\n",
      "[700]\ttraining's auc: 0.999584\tvalid_1's auc: 0.936235\n",
      "[800]\ttraining's auc: 0.999849\tvalid_1's auc: 0.936794\n",
      "[900]\ttraining's auc: 0.999951\tvalid_1's auc: 0.937362\n",
      "[1000]\ttraining's auc: 0.999987\tvalid_1's auc: 0.937724\n",
      "[1100]\ttraining's auc: 0.999998\tvalid_1's auc: 0.937779\n",
      "[1200]\ttraining's auc: 1\tvalid_1's auc: 0.938074\n",
      "[1300]\ttraining's auc: 1\tvalid_1's auc: 0.93828\n",
      "[1400]\ttraining's auc: 1\tvalid_1's auc: 0.938562\n",
      "[1500]\ttraining's auc: 1\tvalid_1's auc: 0.938611\n",
      "Early stopping, best iteration is:\n",
      "[1452]\ttraining's auc: 1\tvalid_1's auc: 0.938659\n"
     ]
    }
   ],
   "source": [
    "remove_features = pickle.load(open('../input/remove_features.pkl', 'rb'))\n",
    "remove_features = list(remove_features['features_to_remove'])\n",
    "remove_features += [x for x in results if x!='base_score' and results[x]>0.93644]\n",
    "features = [x for x in train_df.columns if x not in remove_features and train_df[x].dtype!='object']\n",
    "print(len(features))\n",
    "params = {\n",
    "                    'objective':'binary',\n",
    "                    'boosting_type':'gbdt',\n",
    "                    'metric':'auc',\n",
    "                    'n_jobs':-1,\n",
    "                    'learning_rate':0.01,\n",
    "                    'num_leaves': 2**8,\n",
    "                    'max_depth':-1,\n",
    "                    'tree_learner':'serial',\n",
    "                    'colsample_bytree': 0.7,\n",
    "                    'subsample_freq':1,\n",
    "                    'subsample':0.7,\n",
    "                    'n_estimators':80000,\n",
    "                    'max_bin':255,\n",
    "                    'verbose':100,\n",
    "                    'seed': 42,\n",
    "                    'early_stopping_rounds':100, \n",
    "                } \n",
    "_, model = local_valid(train_df, 'isFraud', features, params, return_model=True, sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's auc: 0.946078\n",
      "[200]\ttraining's auc: 0.971687\n",
      "[300]\ttraining's auc: 0.985589\n",
      "[400]\ttraining's auc: 0.992441\n",
      "[500]\ttraining's auc: 0.996068\n",
      "[600]\ttraining's auc: 0.997974\n",
      "[700]\ttraining's auc: 0.998945\n",
      "[800]\ttraining's auc: 0.999433\n",
      "[900]\ttraining's auc: 0.999693\n",
      "[1000]\ttraining's auc: 0.999829\n",
      "[1100]\ttraining's auc: 0.999907\n",
      "[1200]\ttraining's auc: 0.999951\n",
      "[1300]\ttraining's auc: 0.999975\n",
      "[1400]\ttraining's auc: 0.999988\n",
      "[1500]\ttraining's auc: 0.999995\n",
      "[1600]\ttraining's auc: 0.999998\n",
      "[1700]\ttraining's auc: 0.999999\n",
      "[1800]\ttraining's auc: 1\n",
      "[1900]\ttraining's auc: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.7,\n",
       "        importance_type='split', learning_rate=0.01, max_bin=255,\n",
       "        max_depth=-1, metric='auc', min_child_samples=20,\n",
       "        min_child_weight=0.001, min_split_gain=0.0, n_estimators=1900,\n",
       "        n_jobs=-1, num_leaves=256, objective='binary', random_state=None,\n",
       "        reg_alpha=0.0, reg_lambda=0.0, seed=42, silent=True, subsample=0.7,\n",
       "        subsample_for_bin=200000, subsample_freq=1, tree_learner='serial',\n",
       "        verbose=100)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "                    'objective':'binary',\n",
    "                    'boosting_type':'gbdt',\n",
    "                    'metric':'auc',\n",
    "                    'n_jobs':-1,\n",
    "                    'learning_rate':0.01,\n",
    "                    'num_leaves': 2**8,\n",
    "                    'max_depth':-1,\n",
    "                    'tree_learner':'serial',\n",
    "                    'colsample_bytree': 0.7,\n",
    "                    'subsample_freq':1,\n",
    "                    'subsample':0.7,\n",
    "                    'n_estimators': 1900,\n",
    "                    'max_bin':255,\n",
    "                    'verbose':100,\n",
    "                    'seed': 42,\n",
    "                }\n",
    "X_train = train_df[features]\n",
    "y_train = train_df['isFraud']\n",
    "model = lgb.LGBMClassifier(**params)\n",
    "model.fit(X_train, y_train, \n",
    "        eval_set=[(X_train, y_train)], eval_metric='auc', verbose=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['isFraud'] = model.predict_proba(test_df[features])[:, 1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[['TransactionID', 'isFraud']].to_csv('../result/baseline_perm_imp_0915.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n",
      "Fold: 0\n",
      "453219 137321\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.949966\tvalid_1's auc: 0.877888\n",
      "[200]\ttraining's auc: 0.975443\tvalid_1's auc: 0.891396\n",
      "[300]\ttraining's auc: 0.988073\tvalid_1's auc: 0.899044\n",
      "[400]\ttraining's auc: 0.994528\tvalid_1's auc: 0.903837\n",
      "[500]\ttraining's auc: 0.997401\tvalid_1's auc: 0.907659\n",
      "[600]\ttraining's auc: 0.998751\tvalid_1's auc: 0.910078\n",
      "[700]\ttraining's auc: 0.999411\tvalid_1's auc: 0.911976\n",
      "[800]\ttraining's auc: 0.999715\tvalid_1's auc: 0.913608\n",
      "[900]\ttraining's auc: 0.999858\tvalid_1's auc: 0.914784\n",
      "[1000]\ttraining's auc: 0.999934\tvalid_1's auc: 0.916046\n",
      "[1100]\ttraining's auc: 0.999969\tvalid_1's auc: 0.916374\n",
      "[1200]\ttraining's auc: 0.999986\tvalid_1's auc: 0.916733\n",
      "[1300]\ttraining's auc: 0.999995\tvalid_1's auc: 0.917473\n",
      "[1400]\ttraining's auc: 0.999998\tvalid_1's auc: 0.91822\n",
      "[1500]\ttraining's auc: 0.999999\tvalid_1's auc: 0.918354\n",
      "[1600]\ttraining's auc: 1\tvalid_1's auc: 0.918468\n",
      "[1700]\ttraining's auc: 1\tvalid_1's auc: 0.918714\n",
      "[1800]\ttraining's auc: 1\tvalid_1's auc: 0.918918\n",
      "[1900]\ttraining's auc: 1\tvalid_1's auc: 0.919213\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1899]\ttraining's auc: 1\tvalid_1's auc: 0.91923\n",
      "Fold: 1\n",
      "488908 101632\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.948783\tvalid_1's auc: 0.9074\n",
      "[200]\ttraining's auc: 0.975714\tvalid_1's auc: 0.925424\n",
      "[300]\ttraining's auc: 0.988066\tvalid_1's auc: 0.934202\n",
      "[400]\ttraining's auc: 0.994437\tvalid_1's auc: 0.939241\n",
      "[500]\ttraining's auc: 0.997444\tvalid_1's auc: 0.94212\n",
      "[600]\ttraining's auc: 0.998799\tvalid_1's auc: 0.943944\n",
      "[700]\ttraining's auc: 0.999428\tvalid_1's auc: 0.944881\n",
      "[800]\ttraining's auc: 0.999714\tvalid_1's auc: 0.945575\n",
      "[900]\ttraining's auc: 0.999858\tvalid_1's auc: 0.945917\n",
      "[1000]\ttraining's auc: 0.999932\tvalid_1's auc: 0.946263\n",
      "[1100]\ttraining's auc: 0.999969\tvalid_1's auc: 0.946531\n",
      "[1200]\ttraining's auc: 0.999986\tvalid_1's auc: 0.94681\n",
      "[1300]\ttraining's auc: 0.999995\tvalid_1's auc: 0.946974\n",
      "[1400]\ttraining's auc: 0.999998\tvalid_1's auc: 0.946953\n",
      "Early stopping, best iteration is:\n",
      "[1357]\ttraining's auc: 0.999997\tvalid_1's auc: 0.947046\n",
      "Fold: 2\n",
      "497955 92585\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.947295\tvalid_1's auc: 0.905898\n",
      "[200]\ttraining's auc: 0.973656\tvalid_1's auc: 0.921786\n",
      "[300]\ttraining's auc: 0.987484\tvalid_1's auc: 0.931074\n",
      "[400]\ttraining's auc: 0.994067\tvalid_1's auc: 0.936202\n",
      "[500]\ttraining's auc: 0.997228\tvalid_1's auc: 0.939382\n",
      "[600]\ttraining's auc: 0.998649\tvalid_1's auc: 0.941558\n",
      "[700]\ttraining's auc: 0.999345\tvalid_1's auc: 0.942801\n",
      "[800]\ttraining's auc: 0.999673\tvalid_1's auc: 0.943818\n",
      "[900]\ttraining's auc: 0.999833\tvalid_1's auc: 0.944063\n",
      "[1000]\ttraining's auc: 0.999915\tvalid_1's auc: 0.944346\n",
      "[1100]\ttraining's auc: 0.999959\tvalid_1's auc: 0.94475\n",
      "[1200]\ttraining's auc: 0.999982\tvalid_1's auc: 0.944772\n",
      "Early stopping, best iteration is:\n",
      "[1122]\ttraining's auc: 0.999965\tvalid_1's auc: 0.944841\n",
      "Fold: 3\n",
      "501214 89326\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.94696\tvalid_1's auc: 0.902328\n",
      "[200]\ttraining's auc: 0.973645\tvalid_1's auc: 0.919571\n",
      "[300]\ttraining's auc: 0.987101\tvalid_1's auc: 0.930404\n",
      "[400]\ttraining's auc: 0.993671\tvalid_1's auc: 0.935041\n",
      "[500]\ttraining's auc: 0.996959\tvalid_1's auc: 0.938592\n",
      "[600]\ttraining's auc: 0.998517\tvalid_1's auc: 0.940295\n",
      "[700]\ttraining's auc: 0.999282\tvalid_1's auc: 0.941358\n",
      "[800]\ttraining's auc: 0.999634\tvalid_1's auc: 0.94211\n",
      "[900]\ttraining's auc: 0.999812\tvalid_1's auc: 0.942937\n",
      "[1000]\ttraining's auc: 0.999903\tvalid_1's auc: 0.9434\n",
      "[1100]\ttraining's auc: 0.999951\tvalid_1's auc: 0.943668\n",
      "[1200]\ttraining's auc: 0.999977\tvalid_1's auc: 0.94385\n",
      "[1300]\ttraining's auc: 0.99999\tvalid_1's auc: 0.943848\n",
      "Early stopping, best iteration is:\n",
      "[1209]\ttraining's auc: 0.999979\tvalid_1's auc: 0.943906\n",
      "Fold: 4\n",
      "504519 86021\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.946586\tvalid_1's auc: 0.921984\n",
      "[200]\ttraining's auc: 0.973564\tvalid_1's auc: 0.936936\n",
      "[300]\ttraining's auc: 0.987074\tvalid_1's auc: 0.943747\n",
      "[400]\ttraining's auc: 0.993604\tvalid_1's auc: 0.947196\n",
      "[500]\ttraining's auc: 0.996909\tvalid_1's auc: 0.949301\n",
      "[600]\ttraining's auc: 0.998457\tvalid_1's auc: 0.950275\n",
      "[700]\ttraining's auc: 0.999221\tvalid_1's auc: 0.951089\n",
      "[800]\ttraining's auc: 0.999605\tvalid_1's auc: 0.951479\n",
      "[900]\ttraining's auc: 0.999795\tvalid_1's auc: 0.951773\n",
      "[1000]\ttraining's auc: 0.999894\tvalid_1's auc: 0.951892\n",
      "Early stopping, best iteration is:\n",
      "[991]\ttraining's auc: 0.999888\tvalid_1's auc: 0.951926\n",
      "Fold: 5\n",
      "506885 83655\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.94557\tvalid_1's auc: 0.912508\n",
      "[200]\ttraining's auc: 0.972208\tvalid_1's auc: 0.933583\n",
      "[300]\ttraining's auc: 0.98655\tvalid_1's auc: 0.944501\n",
      "[400]\ttraining's auc: 0.993299\tvalid_1's auc: 0.95065\n",
      "[500]\ttraining's auc: 0.996693\tvalid_1's auc: 0.953986\n",
      "[600]\ttraining's auc: 0.998366\tvalid_1's auc: 0.955731\n",
      "[700]\ttraining's auc: 0.999193\tvalid_1's auc: 0.956925\n",
      "[800]\ttraining's auc: 0.999583\tvalid_1's auc: 0.95756\n",
      "[900]\ttraining's auc: 0.999785\tvalid_1's auc: 0.957814\n",
      "[1000]\ttraining's auc: 0.999888\tvalid_1's auc: 0.958165\n",
      "[1100]\ttraining's auc: 0.999942\tvalid_1's auc: 0.958292\n",
      "[1200]\ttraining's auc: 0.999972\tvalid_1's auc: 0.958354\n",
      "[1300]\ttraining's auc: 0.999987\tvalid_1's auc: 0.958375\n",
      "[1400]\ttraining's auc: 0.999995\tvalid_1's auc: 0.95842\n",
      "[1500]\ttraining's auc: 0.999998\tvalid_1's auc: 0.958574\n",
      "[1600]\ttraining's auc: 0.999999\tvalid_1's auc: 0.958681\n",
      "[1700]\ttraining's auc: 1\tvalid_1's auc: 0.958489\n",
      "Early stopping, best iteration is:\n",
      "[1601]\ttraining's auc: 0.999999\tvalid_1's auc: 0.958683\n"
     ]
    }
   ],
   "source": [
    "remove_features = pickle.load(open('../input/remove_features.pkl', 'rb'))\n",
    "remove_features = list(remove_features['features_to_remove'])\n",
    "perm_imp = pd.read_csv('../result/perm_imp.csv', index_col=0)\n",
    "remove_features += [x for x in perm_imp.index if x!='base_score' and perm_imp.loc[x, 'score']>0.9364]\n",
    "features = [x for x in train_df.columns if x not in remove_features and train_df[x].dtype!='object']\n",
    "print(len(features))\n",
    "gc.collect()\n",
    "params = {\n",
    "                    'objective':'binary',\n",
    "                    'boosting_type':'gbdt',\n",
    "                    'metric':'auc',\n",
    "                    'n_jobs':-1,\n",
    "                    'learning_rate':0.01,\n",
    "                    'num_leaves': 2**8,\n",
    "                    'max_depth':-1,\n",
    "                    'tree_learner':'serial',\n",
    "                    'colsample_bytree': 0.7,\n",
    "                    'subsample_freq':1,\n",
    "                    'subsample':0.7,\n",
    "                    'n_estimators': 1900,\n",
    "                    'max_bin':255,\n",
    "                    'verbose':100,\n",
    "                    'seed': 42,\n",
    "                }\n",
    "NFOLDS = 6\n",
    "folds = GroupKFold(n_splits=NFOLDS)\n",
    "\n",
    "predictions = np.zeros(len(test_df))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train_df, train_df['isFraud'], groups=train_df['DT_M'])):\n",
    "    print('Fold:',fold_)\n",
    "    tr_x, tr_y = train_df.loc[trn_idx, features], train_df.loc[trn_idx, 'isFraud']\n",
    "    vl_x, vl_y = train_df.loc[val_idx,features], train_df.loc[val_idx, 'isFraud']\n",
    "\n",
    "    print(len(tr_x),len(vl_x))\n",
    "    \n",
    "    estimator = lgb.LGBMRegressor(**params)\n",
    "    estimator.fit(tr_x, tr_y,\n",
    "        eval_set=[(tr_x, tr_y), (vl_x, vl_y)], eval_metric='auc',\n",
    "        verbose=100, early_stopping_rounds=100)\n",
    "\n",
    "    pp_p = estimator.predict(test_df[features])\n",
    "    predictions += pp_p/NFOLDS\n",
    "\n",
    "    \n",
    "    del tr_x, tr_y, vl_x, vl_y\n",
    "    gc.collect()\n",
    "\n",
    "test_df['isFraud'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417\n",
      "Fold: 0\n",
      "453219 137321\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.946083\tvalid_1's auc: 0.87746\n",
      "[200]\ttraining's auc: 0.970506\tvalid_1's auc: 0.891434\n",
      "[300]\ttraining's auc: 0.984613\tvalid_1's auc: 0.898873\n",
      "[400]\ttraining's auc: 0.991886\tvalid_1's auc: 0.904953\n",
      "[500]\ttraining's auc: 0.995749\tvalid_1's auc: 0.908946\n",
      "[600]\ttraining's auc: 0.997721\tvalid_1's auc: 0.911423\n",
      "[700]\ttraining's auc: 0.998821\tvalid_1's auc: 0.913085\n",
      "[800]\ttraining's auc: 0.999377\tvalid_1's auc: 0.914525\n",
      "[900]\ttraining's auc: 0.999663\tvalid_1's auc: 0.91544\n",
      "[1000]\ttraining's auc: 0.999813\tvalid_1's auc: 0.916247\n",
      "[1100]\ttraining's auc: 0.999897\tvalid_1's auc: 0.916764\n",
      "[1200]\ttraining's auc: 0.999946\tvalid_1's auc: 0.917566\n",
      "[1300]\ttraining's auc: 0.999972\tvalid_1's auc: 0.918362\n",
      "[1400]\ttraining's auc: 0.999986\tvalid_1's auc: 0.918718\n",
      "[1500]\ttraining's auc: 0.999993\tvalid_1's auc: 0.918964\n",
      "[1600]\ttraining's auc: 0.999997\tvalid_1's auc: 0.919044\n",
      "[1700]\ttraining's auc: 0.999998\tvalid_1's auc: 0.919088\n",
      "Early stopping, best iteration is:\n",
      "[1653]\ttraining's auc: 0.999998\tvalid_1's auc: 0.919157\n",
      "Fold: 1\n",
      "488908 101632\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.946786\tvalid_1's auc: 0.907995\n",
      "[200]\ttraining's auc: 0.970734\tvalid_1's auc: 0.922495\n",
      "[300]\ttraining's auc: 0.984386\tvalid_1's auc: 0.930993\n",
      "[400]\ttraining's auc: 0.991815\tvalid_1's auc: 0.936024\n",
      "[500]\ttraining's auc: 0.995764\tvalid_1's auc: 0.939091\n",
      "[600]\ttraining's auc: 0.997831\tvalid_1's auc: 0.940737\n",
      "[700]\ttraining's auc: 0.998854\tvalid_1's auc: 0.941851\n",
      "[800]\ttraining's auc: 0.999382\tvalid_1's auc: 0.942579\n",
      "[900]\ttraining's auc: 0.999661\tvalid_1's auc: 0.943175\n",
      "[1000]\ttraining's auc: 0.999813\tvalid_1's auc: 0.943537\n",
      "[1100]\ttraining's auc: 0.999897\tvalid_1's auc: 0.943762\n",
      "[1200]\ttraining's auc: 0.999945\tvalid_1's auc: 0.94392\n",
      "[1300]\ttraining's auc: 0.999972\tvalid_1's auc: 0.944049\n",
      "[1400]\ttraining's auc: 0.999986\tvalid_1's auc: 0.94415\n",
      "[1500]\ttraining's auc: 0.999993\tvalid_1's auc: 0.944145\n",
      "Early stopping, best iteration is:\n",
      "[1431]\ttraining's auc: 0.999989\tvalid_1's auc: 0.944285\n",
      "Fold: 2\n",
      "497955 92585\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.94325\tvalid_1's auc: 0.905485\n",
      "[200]\ttraining's auc: 0.968116\tvalid_1's auc: 0.920265\n",
      "[300]\ttraining's auc: 0.983117\tvalid_1's auc: 0.92901\n",
      "[400]\ttraining's auc: 0.991168\tvalid_1's auc: 0.933652\n",
      "[500]\ttraining's auc: 0.995451\tvalid_1's auc: 0.936567\n",
      "[600]\ttraining's auc: 0.997604\tvalid_1's auc: 0.93846\n",
      "[700]\ttraining's auc: 0.998732\tvalid_1's auc: 0.9395\n",
      "[800]\ttraining's auc: 0.999327\tvalid_1's auc: 0.94046\n",
      "[900]\ttraining's auc: 0.999627\tvalid_1's auc: 0.941183\n",
      "[1000]\ttraining's auc: 0.999787\tvalid_1's auc: 0.941732\n",
      "[1100]\ttraining's auc: 0.99988\tvalid_1's auc: 0.942148\n",
      "[1200]\ttraining's auc: 0.999933\tvalid_1's auc: 0.942411\n",
      "[1300]\ttraining's auc: 0.999964\tvalid_1's auc: 0.942671\n",
      "[1400]\ttraining's auc: 0.999981\tvalid_1's auc: 0.94298\n",
      "[1500]\ttraining's auc: 0.999991\tvalid_1's auc: 0.942959\n",
      "[1600]\ttraining's auc: 0.999996\tvalid_1's auc: 0.943017\n",
      "[1700]\ttraining's auc: 0.999998\tvalid_1's auc: 0.943237\n",
      "Early stopping, best iteration is:\n",
      "[1686]\ttraining's auc: 0.999998\tvalid_1's auc: 0.943273\n",
      "Fold: 3\n",
      "501214 89326\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.943788\tvalid_1's auc: 0.901625\n",
      "[200]\ttraining's auc: 0.967977\tvalid_1's auc: 0.916452\n",
      "[300]\ttraining's auc: 0.982956\tvalid_1's auc: 0.926455\n",
      "[400]\ttraining's auc: 0.990556\tvalid_1's auc: 0.932016\n",
      "[500]\ttraining's auc: 0.995049\tvalid_1's auc: 0.935577\n",
      "[600]\ttraining's auc: 0.997395\tvalid_1's auc: 0.937695\n",
      "[700]\ttraining's auc: 0.998603\tvalid_1's auc: 0.938706\n",
      "[800]\ttraining's auc: 0.999228\tvalid_1's auc: 0.939591\n",
      "[900]\ttraining's auc: 0.999563\tvalid_1's auc: 0.94024\n",
      "[1000]\ttraining's auc: 0.999752\tvalid_1's auc: 0.940596\n",
      "[1100]\ttraining's auc: 0.999856\tvalid_1's auc: 0.941007\n",
      "[1200]\ttraining's auc: 0.99992\tvalid_1's auc: 0.941401\n",
      "[1300]\ttraining's auc: 0.999954\tvalid_1's auc: 0.941791\n",
      "[1400]\ttraining's auc: 0.999974\tvalid_1's auc: 0.942264\n",
      "[1500]\ttraining's auc: 0.999987\tvalid_1's auc: 0.942343\n",
      "[1600]\ttraining's auc: 0.999993\tvalid_1's auc: 0.942574\n",
      "[1700]\ttraining's auc: 0.999996\tvalid_1's auc: 0.942789\n",
      "[1800]\ttraining's auc: 0.999998\tvalid_1's auc: 0.942863\n",
      "[1900]\ttraining's auc: 0.999999\tvalid_1's auc: 0.942972\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1900]\ttraining's auc: 0.999999\tvalid_1's auc: 0.942972\n",
      "Fold: 4\n",
      "504519 86021\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.942326\tvalid_1's auc: 0.921896\n",
      "[200]\ttraining's auc: 0.968654\tvalid_1's auc: 0.935201\n",
      "[300]\ttraining's auc: 0.983228\tvalid_1's auc: 0.941984\n",
      "[400]\ttraining's auc: 0.990708\tvalid_1's auc: 0.94573\n",
      "[500]\ttraining's auc: 0.995119\tvalid_1's auc: 0.94791\n",
      "[600]\ttraining's auc: 0.997402\tvalid_1's auc: 0.949206\n",
      "[700]\ttraining's auc: 0.998549\tvalid_1's auc: 0.950022\n",
      "[800]\ttraining's auc: 0.999194\tvalid_1's auc: 0.950587\n",
      "[900]\ttraining's auc: 0.999547\tvalid_1's auc: 0.950957\n",
      "[1000]\ttraining's auc: 0.999741\tvalid_1's auc: 0.951049\n",
      "[1100]\ttraining's auc: 0.99985\tvalid_1's auc: 0.951206\n",
      "[1200]\ttraining's auc: 0.999914\tvalid_1's auc: 0.951488\n",
      "[1300]\ttraining's auc: 0.999952\tvalid_1's auc: 0.951568\n",
      "Early stopping, best iteration is:\n",
      "[1269]\ttraining's auc: 0.999942\tvalid_1's auc: 0.951654\n",
      "Fold: 5\n",
      "506885 83655\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.940338\tvalid_1's auc: 0.906899\n",
      "[200]\ttraining's auc: 0.966927\tvalid_1's auc: 0.928944\n",
      "[300]\ttraining's auc: 0.982291\tvalid_1's auc: 0.940981\n",
      "[400]\ttraining's auc: 0.990353\tvalid_1's auc: 0.948138\n",
      "[500]\ttraining's auc: 0.994734\tvalid_1's auc: 0.951756\n",
      "[600]\ttraining's auc: 0.997121\tvalid_1's auc: 0.953823\n",
      "[700]\ttraining's auc: 0.998426\tvalid_1's auc: 0.955015\n",
      "[800]\ttraining's auc: 0.999115\tvalid_1's auc: 0.955826\n",
      "[900]\ttraining's auc: 0.999496\tvalid_1's auc: 0.956136\n",
      "[1000]\ttraining's auc: 0.999714\tvalid_1's auc: 0.956725\n",
      "[1100]\ttraining's auc: 0.999834\tvalid_1's auc: 0.956902\n",
      "[1200]\ttraining's auc: 0.999903\tvalid_1's auc: 0.957118\n",
      "[1300]\ttraining's auc: 0.999943\tvalid_1's auc: 0.957336\n",
      "[1400]\ttraining's auc: 0.999969\tvalid_1's auc: 0.957489\n",
      "[1500]\ttraining's auc: 0.999984\tvalid_1's auc: 0.957486\n",
      "Early stopping, best iteration is:\n",
      "[1412]\ttraining's auc: 0.999971\tvalid_1's auc: 0.957544\n"
     ]
    }
   ],
   "source": [
    "remove_features = pickle.load(open('../input/remove_features.pkl', 'rb'))\n",
    "remove_features = list(remove_features['features_to_remove'])\n",
    "perm_imp = pd.read_csv('../result/perm_imp.csv', index_col=0)\n",
    "remove_features += [x for x in perm_imp.index if x!='base_score' and perm_imp.loc[x, 'score']>0.9363]\n",
    "features = [x for x in train_df.columns if x not in remove_features and train_df[x].dtype!='object']\n",
    "print(len(features))\n",
    "gc.collect()\n",
    "params = {\n",
    "                    'objective':'binary',\n",
    "                    'boosting_type':'gbdt',\n",
    "                    'metric':'auc',\n",
    "                    'n_jobs':-1,\n",
    "                    'learning_rate':0.01,\n",
    "                    'num_leaves': 2**8,\n",
    "                    'max_depth':-1,\n",
    "                    'tree_learner':'serial',\n",
    "                    'colsample_bytree': 0.7,\n",
    "                    'subsample_freq':1,\n",
    "                    'subsample':0.7,\n",
    "                    'n_estimators': 1900,\n",
    "                    'max_bin':255,\n",
    "                    'verbose':100,\n",
    "                    'seed': 42,\n",
    "                }\n",
    "NFOLDS = 6\n",
    "folds = GroupKFold(n_splits=NFOLDS)\n",
    "\n",
    "predictions = np.zeros(len(test_df))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train_df, train_df['isFraud'], groups=train_df['DT_M'])):\n",
    "    print('Fold:',fold_)\n",
    "    tr_x, tr_y = train_df.loc[trn_idx, features], train_df.loc[trn_idx, 'isFraud']\n",
    "    vl_x, vl_y = train_df.loc[val_idx,features], train_df.loc[val_idx, 'isFraud']\n",
    "\n",
    "    print(len(tr_x),len(vl_x))\n",
    "    \n",
    "    estimator = lgb.LGBMRegressor(**params)\n",
    "    estimator.fit(tr_x, tr_y,\n",
    "        eval_set=[(tr_x, tr_y), (vl_x, vl_y)], eval_metric='auc',\n",
    "        verbose=100, early_stopping_rounds=100)\n",
    "\n",
    "    pp_p = estimator.predict(test_df[features])\n",
    "    predictions += pp_p/NFOLDS\n",
    "\n",
    "    \n",
    "    del tr_x, tr_y, vl_x, vl_y\n",
    "    gc.collect()\n",
    "\n",
    "test_df['isFraud'] = predictions\n",
    "test_df[['TransactionID', 'isFraud']].to_csv('../result/baseline_perm_imp_gkfold0915_93644.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
