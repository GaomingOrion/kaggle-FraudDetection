{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, sys, gc, warnings, random, datetime, math, re\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append('..')\n",
    "from utils import *\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = 'isFraud'\n",
    "START_DATE = datetime.datetime.strptime('2017-11-30', '%Y-%m-%d')\n",
    "SEED = 42\n",
    "lgb_params = {\n",
    "                    'objective':'binary',\n",
    "                    'boosting_type':'gbdt',\n",
    "                    'metric':'auc',\n",
    "                    'n_jobs':-1,\n",
    "                    'learning_rate':0.01,\n",
    "                    'num_leaves': 2**8,\n",
    "                    'max_depth':-1,\n",
    "                    'tree_learner':'serial',\n",
    "                    'colsample_bytree': 0.7,\n",
    "                    'subsample_freq':1,\n",
    "                    'subsample':0.7,\n",
    "                    'n_estimators':80000,\n",
    "                    'max_bin':255,\n",
    "                    'verbose':100,\n",
    "                    'seed': SEED,\n",
    "                    'early_stopping_rounds':100, \n",
    "                } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def values_normalization(dt_df, periods, columns):\n",
    "    for period in periods:\n",
    "        for col in columns:\n",
    "            new_col = col +'_'+ period\n",
    "            dt_df[col] = dt_df[col].astype(float)  \n",
    "\n",
    "            temp_min = dt_df.groupby([period])[col].agg(['min']).reset_index()\n",
    "            temp_min.index = temp_min[period].values\n",
    "            temp_min = temp_min['min'].to_dict()\n",
    "\n",
    "            temp_max = dt_df.groupby([period])[col].agg(['max']).reset_index()\n",
    "            temp_max.index = temp_max[period].values\n",
    "            temp_max = temp_max['max'].to_dict()\n",
    "\n",
    "            temp_mean = dt_df.groupby([period])[col].agg(['mean']).reset_index()\n",
    "            temp_mean.index = temp_mean[period].values\n",
    "            temp_mean = temp_mean['mean'].to_dict()\n",
    "\n",
    "            temp_std = dt_df.groupby([period])[col].agg(['std']).reset_index()\n",
    "            temp_std.index = temp_std[period].values\n",
    "            temp_std = temp_std['std'].to_dict()\n",
    "\n",
    "            dt_df['temp_min'] = dt_df[period].map(temp_min)\n",
    "            dt_df['temp_max'] = dt_df[period].map(temp_max)\n",
    "            dt_df['temp_mean'] = dt_df[period].map(temp_mean)\n",
    "            dt_df['temp_std'] = dt_df[period].map(temp_std)\n",
    "\n",
    "            dt_df[new_col+'_min_max'] = (dt_df[col]-dt_df['temp_min'])/(dt_df['temp_max']-dt_df['temp_min'])\n",
    "            dt_df[new_col+'_std_score'] = (dt_df[col]-dt_df['temp_mean'])/(dt_df['temp_std'])\n",
    "            del dt_df['temp_min'],dt_df['temp_max'],dt_df['temp_mean'],dt_df['temp_std']\n",
    "    return dt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_encoding(train_df, test_df, columns, self_encoding=False):\n",
    "    for col in columns:\n",
    "        temp_df = pd.concat([train_df[[col]], test_df[[col]]])\n",
    "        fq_encode = temp_df[col].value_counts(dropna=False).to_dict()\n",
    "        if self_encoding:\n",
    "            train_df[col] = train_df[col].map(fq_encode)\n",
    "            test_df[col]  = test_df[col].map(fq_encode)            \n",
    "        else:\n",
    "            train_df[col+'_fq_enc'] = train_df[col].map(fq_encode)\n",
    "            test_df[col+'_fq_enc']  = test_df[col].map(fq_encode)\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeblock_frequency_encoding(train_df, test_df, periods, columns, \n",
    "                                 with_proportions=True, only_proportions=False):\n",
    "    for period in periods:\n",
    "        for col in columns:\n",
    "            new_col = col +'_'+ period\n",
    "            train_df[new_col] = train_df[col].astype(str)+'_'+train_df[period].astype(str)\n",
    "            test_df[new_col]  = test_df[col].astype(str)+'_'+test_df[period].astype(str)\n",
    "\n",
    "            temp_df = pd.concat([train_df[[new_col]], test_df[[new_col]]])\n",
    "            fq_encode = temp_df[new_col].value_counts().to_dict()\n",
    "\n",
    "            train_df[new_col] = train_df[new_col].map(fq_encode)\n",
    "            test_df[new_col]  = test_df[new_col].map(fq_encode)\n",
    "            \n",
    "            if only_proportions:\n",
    "                train_df[new_col] = train_df[new_col]/train_df[period+'_total']\n",
    "                test_df[new_col]  = test_df[new_col]/test_df[period+'_total']\n",
    "\n",
    "            if with_proportions:\n",
    "                train_df[new_col+'_proportions'] = train_df[new_col]/train_df[period+'_total']\n",
    "                test_df[new_col+'_proportions']  = test_df[new_col]/test_df[period+'_total']\n",
    "\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uid_aggregation(train_df, test_df, main_columns, uids, aggregations):\n",
    "    for main_column in main_columns:  \n",
    "        for col in uids:\n",
    "            for agg_type in aggregations:\n",
    "                new_col_name = col+'_'+main_column+'_'+agg_type\n",
    "                temp_df = pd.concat([train_df[[col, main_column]], test_df[[col,main_column]]])\n",
    "                temp_df = temp_df.groupby([col])[main_column].agg([agg_type]).reset_index().rename(\n",
    "                                                        columns={agg_type: new_col_name})\n",
    "\n",
    "                temp_df.index = list(temp_df[col])\n",
    "                temp_df = temp_df[new_col_name].to_dict()   \n",
    "\n",
    "                train_df[new_col_name] = train_df[col].map(temp_df)\n",
    "                test_df[new_col_name]  = test_df[col].map(temp_df)\n",
    "    return train_df, test_df\n",
    "\n",
    "def uid_aggregation_and_normalization(train_df, test_df, main_columns, uids, aggregations):\n",
    "    for main_column in main_columns:  \n",
    "        for col in uids:\n",
    "            \n",
    "            new_norm_col_name = col+'_'+main_column+'_std_norm'\n",
    "            norm_cols = []\n",
    "            \n",
    "            for agg_type in aggregations:\n",
    "                new_col_name = col+'_'+main_column+'_'+agg_type\n",
    "                temp_df = pd.concat([train_df[[col, main_column]], test_df[[col,main_column]]])\n",
    "                temp_df = temp_df.groupby([col])[main_column].agg([agg_type]).reset_index().rename(\n",
    "                                                        columns={agg_type: new_col_name})\n",
    "\n",
    "                temp_df.index = list(temp_df[col])\n",
    "                temp_df = temp_df[new_col_name].to_dict()   \n",
    "\n",
    "                train_df[new_col_name] = train_df[col].map(temp_df)\n",
    "                test_df[new_col_name]  = test_df[col].map(temp_df)\n",
    "                norm_cols.append(new_col_name)\n",
    "            \n",
    "            train_df[new_norm_col_name] = (train_df[main_column]-train_df[norm_cols[0]])/train_df[norm_cols[1]]\n",
    "            test_df[new_norm_col_name]  = (test_df[main_column]-test_df[norm_cols[0]])/test_df[norm_cols[1]]          \n",
    "            \n",
    "            del train_df[norm_cols[0]], train_df[norm_cols[1]]\n",
    "            del test_df[norm_cols[0]], test_df[norm_cols[1]]\n",
    "                                              \n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_cor_and_remove(train_df, test_df, i_cols, new_columns, remove=False):\n",
    "    # Check correllation\n",
    "    print('Correlations','#'*10)\n",
    "    for col in new_columns:\n",
    "        cor_cof = np.corrcoef(train_df[TARGET], train_df[col].fillna(0))[0][1]\n",
    "        print(col, cor_cof)\n",
    "\n",
    "    if remove:\n",
    "        print('#'*10)\n",
    "        print('Best options:')\n",
    "        best_fe_columns = []\n",
    "        for main_col in i_cols:\n",
    "            best_option = ''\n",
    "            best_cof = 0\n",
    "            for col in new_columns:\n",
    "                if main_col in col:\n",
    "                    cor_cof = np.corrcoef(train_df[TARGET], train_df[col].fillna(0))[0][1]\n",
    "                    cor_cof = (cor_cof**2)**0.5\n",
    "                    if cor_cof>best_cof:\n",
    "                        best_cof = cor_cof\n",
    "                        best_option = col\n",
    "\n",
    "            print(main_col, best_option, best_cof)            \n",
    "            best_fe_columns.append(best_option)\n",
    "\n",
    "        for col in new_columns:\n",
    "            if col not in best_fe_columns:\n",
    "                del train_df[col], test_df[col]\n",
    "\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Data\n",
      "Shape control: (590540, 394) (506691, 394)\n"
     ]
    }
   ],
   "source": [
    "print('Load Data')\n",
    "train_df = pd.read_pickle('../input/train_transaction.pkl')\n",
    "test_df = pd.read_pickle('../input/test_transaction.pkl')\n",
    "train_identity = pd.read_pickle('../input/train_identity.pkl')\n",
    "test_identity = pd.read_pickle('../input/test_identity.pkl')\n",
    "\n",
    "print('Shape control:', train_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_features = [\n",
    "    'TransactionID','TransactionDT', # These columns are pure noise right now\n",
    "    TARGET,\n",
    "    ]\n",
    "\n",
    "base_columns = [col for col in list(train_df) if col not in remove_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.932763\tvalid_1's auc: 0.8882\n",
      "[200]\ttraining's auc: 0.950862\tvalid_1's auc: 0.900245\n",
      "[300]\ttraining's auc: 0.966219\tvalid_1's auc: 0.909486\n",
      "[400]\ttraining's auc: 0.976985\tvalid_1's auc: 0.914953\n",
      "[500]\ttraining's auc: 0.983393\tvalid_1's auc: 0.917539\n",
      "[600]\ttraining's auc: 0.987748\tvalid_1's auc: 0.919305\n",
      "[700]\ttraining's auc: 0.990836\tvalid_1's auc: 0.920169\n",
      "[800]\ttraining's auc: 0.992984\tvalid_1's auc: 0.920588\n",
      "[900]\ttraining's auc: 0.994615\tvalid_1's auc: 0.920657\n",
      "[1000]\ttraining's auc: 0.995843\tvalid_1's auc: 0.920759\n",
      "Early stopping, best iteration is:\n",
      "[930]\ttraining's auc: 0.99502\tvalid_1's auc: 0.920815\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(defaultdict(dict,\n",
       "             {'training': {'auc': 0.995020290022887},\n",
       "              'valid_1': {'auc': 0.9208148949348739}}),\n",
       " None)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_params = {\n",
    "                    'objective':'binary',\n",
    "                    'boosting_type':'gbdt',\n",
    "                    'metric':'auc',\n",
    "                    'n_jobs':-1,\n",
    "                    'learning_rate':0.01,\n",
    "                    'num_leaves': 2**8,\n",
    "                    'max_depth':-1,\n",
    "                    'tree_learner':'serial',\n",
    "                    'colsample_bytree': 0.7,\n",
    "                    'subsample_freq':1,\n",
    "                    'subsample':0.7,\n",
    "                    'n_estimators':80000,\n",
    "                    'max_bin':255,\n",
    "                    'seed': SEED,\n",
    "                    'early_stopping_rounds':100, \n",
    "                    'reg_alpha': 0.1,\n",
    "                    'reg_lambda': 0.1,\n",
    "                } \n",
    "features = [x for x in base_columns if train_df[x].dtype != 'object']\n",
    "local_valid(train_df, 'isFraud', features, lgb_params, return_model=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### TransactionDT\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar as calendar\n",
    "dates_range = pd.date_range(start='2017-10-01', end='2019-01-01')\n",
    "us_holidays = calendar().holidays(start=dates_range.min(), end=dates_range.max())\n",
    "\n",
    "# Let's add temporary \"time variables\" for aggregations\n",
    "# and add normal \"time variables\"\n",
    "for df in [train_df, test_df]:\n",
    "    \n",
    "    # Temporary variables for aggregation\n",
    "    df['DT'] = df['TransactionDT'].apply(lambda x: (START_DATE + datetime.timedelta(seconds = x)))\n",
    "    df['DT_M'] = ((df['DT'].dt.year-2017)*12 + df['DT'].dt.month).astype(np.int8)\n",
    "    df['DT_W'] = ((df['DT'].dt.year-2017)*52 + df['DT'].dt.weekofyear).astype(np.int8)\n",
    "    df['DT_D'] = ((df['DT'].dt.year-2017)*365 + df['DT'].dt.dayofyear).astype(np.int16)\n",
    "    \n",
    "    df['DT_hour'] = (df['DT'].dt.hour).astype(np.int8)\n",
    "    df['DT_day_week'] = (df['DT'].dt.dayofweek).astype(np.int8)\n",
    "    df['DT_day_month'] = (df['DT'].dt.day).astype(np.int8)\n",
    "        \n",
    "    # Possible solo feature\n",
    "    df['is_december'] = df['DT'].dt.month\n",
    "    df['is_december'] = (df['is_december']==12).astype(np.int8)\n",
    "\n",
    "    # Holidays\n",
    "    df['is_holiday'] = (df['DT'].dt.date.astype('datetime64').isin(us_holidays)).astype(np.int8)\n",
    "\n",
    "# Remove temporary features from final list\n",
    "remove_features += ['DT','DT_M','DT_W','DT_D','DT_hour','DT_day_week','DT_day_month']\n",
    "    \n",
    "# Total transactions per timeblock\n",
    "for col in ['DT_M','DT_W','DT_D']:\n",
    "    temp_df = pd.concat([train_df[[col]], test_df[[col]]])\n",
    "    fq_encode = temp_df[col].value_counts().to_dict()\n",
    "            \n",
    "    train_df[col+'_total'] = train_df[col].map(fq_encode)\n",
    "    test_df[col+'_total']  = test_df[col].map(fq_encode)\n",
    "    \n",
    "    # We can't use it as solo feature\n",
    "    remove_features.append(col+'_total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rare cards 5993\n",
      "No intersection in Train 10396\n",
      "Intersection in Train 580144\n",
      "####################\n",
      "No intersection in Train card2 5012\n",
      "Intersection in Train card2 585528\n",
      "####################\n",
      "No intersection in Train card3 47\n",
      "Intersection in Train card3 590493\n",
      "####################\n",
      "No intersection in Train card4 0\n",
      "Intersection in Train card4 590540\n",
      "####################\n",
      "No intersection in Train card5 7279\n",
      "Intersection in Train card5 583261\n",
      "####################\n",
      "No intersection in Train card6 30\n",
      "Intersection in Train card6 590510\n",
      "####################\n"
     ]
    }
   ],
   "source": [
    "########################### Card columns \"outliers\"\n",
    "for col in ['card1']: \n",
    "    valid_card = pd.concat([train_df[[col]], test_df[[col]]])\n",
    "    valid_card = valid_card[col].value_counts()\n",
    "    valid_card_std = valid_card.values.std()\n",
    "\n",
    "    invalid_cards = valid_card[valid_card<=2]\n",
    "    print('Rare cards',len(invalid_cards))\n",
    "\n",
    "    valid_card = valid_card[valid_card>2]\n",
    "    valid_card = list(valid_card.index)\n",
    "\n",
    "    print('No intersection in Train', len(train_df[~train_df[col].isin(test_df[col])]))\n",
    "    print('Intersection in Train', len(train_df[train_df[col].isin(test_df[col])]))\n",
    "    \n",
    "    train_df[col] = np.where(train_df[col].isin(test_df[col]), train_df[col], np.nan)\n",
    "    test_df[col]  = np.where(test_df[col].isin(train_df[col]), test_df[col], np.nan)\n",
    "\n",
    "    train_df[col] = np.where(train_df[col].isin(valid_card), train_df[col], np.nan)\n",
    "    test_df[col]  = np.where(test_df[col].isin(valid_card), test_df[col], np.nan)\n",
    "    print('#'*20)\n",
    "\n",
    "for col in ['card2','card3','card4','card5','card6',]: \n",
    "    print('No intersection in Train', col, len(train_df[~train_df[col].isin(test_df[col])]))\n",
    "    print('Intersection in Train', col, len(train_df[train_df[col].isin(test_df[col])]))\n",
    "    \n",
    "    train_df[col] = np.where(train_df[col].isin(test_df[col]), train_df[col], np.nan)\n",
    "    test_df[col]  = np.where(test_df[col].isin(train_df[col]), test_df[col], np.nan)\n",
    "    print('#'*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########\n",
      "Most common uIds:\n",
      "########## uid\n",
      "7919.0_194.0     14891\n",
      "9500.0_321.0     14112\n",
      "15885.0_545.0    10332\n",
      "17188.0_321.0    10312\n",
      "15066.0_170.0     7918\n",
      "12695.0_490.0     7079\n",
      "6019.0_583.0      6766\n",
      "12544.0_321.0     6760\n",
      "2803.0_100.0      6126\n",
      "7585.0_553.0      5325\n",
      "Name: uid, dtype: int64\n",
      "########## uid2\n",
      "9500.0_321.0_150.0_226.0     14112\n",
      "15885.0_545.0_185.0_138.0    10332\n",
      "17188.0_321.0_150.0_226.0    10312\n",
      "7919.0_194.0_150.0_166.0      8844\n",
      "15066.0_170.0_150.0_102.0     7918\n",
      "12695.0_490.0_150.0_226.0     7079\n",
      "6019.0_583.0_150.0_226.0      6766\n",
      "12544.0_321.0_150.0_226.0     6760\n",
      "2803.0_100.0_150.0_226.0      6126\n",
      "7919.0_194.0_150.0_nan        6047\n",
      "Name: uid2, dtype: int64\n",
      "########## uid3\n",
      "15885.0_545.0_185.0_138.0_nan_nan       9900\n",
      "17188.0_321.0_150.0_226.0_299.0_87.0    5862\n",
      "12695.0_490.0_150.0_226.0_325.0_87.0    5766\n",
      "9500.0_321.0_150.0_226.0_204.0_87.0     4647\n",
      "3154.0_408.0_185.0_224.0_nan_nan        4398\n",
      "12839.0_321.0_150.0_226.0_264.0_87.0    3538\n",
      "16132.0_111.0_150.0_226.0_299.0_87.0    3523\n",
      "15497.0_490.0_150.0_226.0_299.0_87.0    3419\n",
      "9500.0_321.0_150.0_226.0_272.0_87.0     2715\n",
      "5812.0_408.0_185.0_224.0_nan_nan        2639\n",
      "Name: uid3, dtype: int64\n",
      "########## uid4\n",
      "15885.0_545.0_185.0_138.0_nan_nan_hotmail.com     4002\n",
      "15885.0_545.0_185.0_138.0_nan_nan_gmail.com       3830\n",
      "17188.0_321.0_150.0_226.0_299.0_87.0_gmail.com    2235\n",
      "12695.0_490.0_150.0_226.0_325.0_87.0_gmail.com    2045\n",
      "9500.0_321.0_150.0_226.0_204.0_87.0_gmail.com     1947\n",
      "3154.0_408.0_185.0_224.0_nan_nan_hotmail.com      1890\n",
      "3154.0_408.0_185.0_224.0_nan_nan_gmail.com        1537\n",
      "12839.0_321.0_150.0_226.0_264.0_87.0_gmail.com    1473\n",
      "15775.0_481.0_150.0_102.0_330.0_87.0_nan          1453\n",
      "15497.0_490.0_150.0_226.0_299.0_87.0_gmail.com    1383\n",
      "Name: uid4, dtype: int64\n",
      "########## uid5\n",
      "12695.0_490.0_150.0_226.0_325.0_87.0_nan         5446\n",
      "17188.0_321.0_150.0_226.0_299.0_87.0_nan         5322\n",
      "9500.0_321.0_150.0_226.0_204.0_87.0_nan          4403\n",
      "15885.0_545.0_185.0_138.0_nan_nan_hotmail.com    4002\n",
      "15885.0_545.0_185.0_138.0_nan_nan_gmail.com      3830\n",
      "12839.0_321.0_150.0_226.0_264.0_87.0_nan         3365\n",
      "16132.0_111.0_150.0_226.0_299.0_87.0_nan         3212\n",
      "15497.0_490.0_150.0_226.0_299.0_87.0_nan         3027\n",
      "9500.0_321.0_150.0_226.0_272.0_87.0_nan          2601\n",
      "7664.0_490.0_150.0_226.0_264.0_87.0_nan          2396\n",
      "Name: uid5, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "########################### Client Virtual ID\n",
    "# Let's add some kind of client uID based on cardID and addr columns\n",
    "# The value will be very specific for each client so we need to remove it\n",
    "# from final features. But we can use it for aggregations.\n",
    "train_df['uid'] = train_df['card1'].astype(str)+'_'+train_df['card2'].astype(str)\n",
    "test_df['uid'] = test_df['card1'].astype(str)+'_'+test_df['card2'].astype(str)\n",
    "\n",
    "train_df['uid2'] = train_df['uid'].astype(str)+'_'+train_df['card3'].astype(str)+'_'+train_df['card5'].astype(str)\n",
    "test_df['uid2'] = test_df['uid'].astype(str)+'_'+test_df['card3'].astype(str)+'_'+test_df['card5'].astype(str)\n",
    "\n",
    "train_df['uid3'] = train_df['uid2'].astype(str)+'_'+train_df['addr1'].astype(str)+'_'+train_df['addr2'].astype(str)\n",
    "test_df['uid3'] = test_df['uid2'].astype(str)+'_'+test_df['addr1'].astype(str)+'_'+test_df['addr2'].astype(str)\n",
    "\n",
    "train_df['uid4'] = train_df['uid3'].astype(str)+'_'+train_df['P_emaildomain'].astype(str)\n",
    "test_df['uid4'] = test_df['uid3'].astype(str)+'_'+test_df['P_emaildomain'].astype(str)\n",
    "\n",
    "train_df['uid5'] = train_df['uid3'].astype(str)+'_'+train_df['R_emaildomain'].astype(str)\n",
    "test_df['uid5'] = test_df['uid3'].astype(str)+'_'+test_df['R_emaildomain'].astype(str)\n",
    "\n",
    "# Add values remove list\n",
    "new_columns = ['uid','uid2','uid3','uid4','uid5']\n",
    "remove_features += new_columns\n",
    "\n",
    "print('#'*10)\n",
    "print('Most common uIds:')\n",
    "for col in new_columns:\n",
    "    print('#'*10, col)\n",
    "    print(train_df[col].value_counts()[:10])\n",
    "\n",
    "# Do Global frequency encoding \n",
    "i_cols = ['card1','card2','card3','card5'] + new_columns\n",
    "train_df, test_df = frequency_encoding(train_df, test_df, i_cols, self_encoding=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### card3/card5 most common hour \n",
    "# card3 or card5 is a bank country?\n",
    "# can we find:\n",
    "# - the most popular Transaction Hour\n",
    "# - the most popular Week Day\n",
    "# and then find distance from it\n",
    "\n",
    "# Prepare bank type feature\n",
    "for df in [train_df, test_df]:\n",
    "    df['bank_type'] = df['card3'].astype(str) +'_'+ df['card5'].astype(str)\n",
    "remove_features.append('bank_type') \n",
    "\n",
    "encoding_mean = {\n",
    "    1: ['DT_D','DT_hour','_hour_dist','DT_hour_mean'],\n",
    "    2: ['DT_W','DT_day_week','_week_day_dist','DT_day_week_mean'],\n",
    "    3: ['DT_M','DT_day_month','_month_day_dist','DT_day_month_mean'],\n",
    "    }\n",
    "\n",
    "encoding_best = {\n",
    "    1: ['DT_D','DT_hour','_hour_dist_best','DT_hour_best'],\n",
    "    2: ['DT_W','DT_day_week','_week_day_dist_best','DT_day_week_best'],\n",
    "    3: ['DT_M','DT_day_month','_month_day_dist_best','DT_day_month_best'],   \n",
    "    }\n",
    "\n",
    "# Some ugly code here (even worse than in other parts)\n",
    "for col in ['card3','card5','bank_type']:\n",
    "    for df in [train_df, test_df]:\n",
    "        for encode in encoding_mean:\n",
    "            encode = encoding_mean[encode].copy()\n",
    "            new_col = col + '_' + encode[0] + encode[2]\n",
    "            df[new_col] = df[col].astype(str) +'_'+ df[encode[0]].astype(str)\n",
    "\n",
    "            temp_dict = df.groupby([new_col])[encode[1]].agg(['mean']).reset_index().rename(\n",
    "                                                                    columns={'mean': encode[3]})\n",
    "            temp_dict.index = temp_dict[new_col].values\n",
    "            temp_dict = temp_dict[encode[3]].to_dict()\n",
    "            df[new_col] = df[encode[1]] - df[new_col].map(temp_dict)\n",
    "\n",
    "        for encode in encoding_best:\n",
    "            encode = encoding_best[encode].copy()\n",
    "            new_col = col + '_' + encode[0] + encode[2]\n",
    "            df[new_col] = df[col].astype(str) +'_'+ df[encode[0]].astype(str)\n",
    "            temp_dict = df.groupby([col,encode[0],encode[1]])[encode[1]].agg(['count']).reset_index().rename(\n",
    "                                                                    columns={'count': encode[3]})\n",
    "\n",
    "            temp_dict.sort_values(by=[col,encode[0],encode[3]], inplace=True)\n",
    "            temp_dict = temp_dict.drop_duplicates(subset=[col,encode[0]], keep='last')\n",
    "            temp_dict[new_col] = temp_dict[col].astype(str) +'_'+ temp_dict[encode[0]].astype(str)\n",
    "            temp_dict.index = temp_dict[new_col].values\n",
    "            temp_dict = temp_dict[encode[1]].to_dict()\n",
    "            df[new_col] = df[encode[1]] - df[new_col].map(temp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.938947\tvalid_1's auc: 0.890185\n",
      "[200]\ttraining's auc: 0.959218\tvalid_1's auc: 0.90213\n",
      "[300]\ttraining's auc: 0.974681\tvalid_1's auc: 0.911274\n",
      "[400]\ttraining's auc: 0.984577\tvalid_1's auc: 0.916627\n",
      "[500]\ttraining's auc: 0.990765\tvalid_1's auc: 0.919903\n",
      "[600]\ttraining's auc: 0.994573\tvalid_1's auc: 0.921677\n",
      "[700]\ttraining's auc: 0.996867\tvalid_1's auc: 0.922585\n",
      "[800]\ttraining's auc: 0.998232\tvalid_1's auc: 0.923459\n",
      "[900]\ttraining's auc: 0.999031\tvalid_1's auc: 0.924209\n",
      "[1000]\ttraining's auc: 0.999485\tvalid_1's auc: 0.924689\n",
      "[1100]\ttraining's auc: 0.999736\tvalid_1's auc: 0.924973\n",
      "[1200]\ttraining's auc: 0.999873\tvalid_1's auc: 0.925184\n",
      "[1300]\ttraining's auc: 0.999941\tvalid_1's auc: 0.925304\n",
      "[1400]\ttraining's auc: 0.999975\tvalid_1's auc: 0.925316\n",
      "Early stopping, best iteration is:\n",
      "[1323]\ttraining's auc: 0.999951\tvalid_1's auc: 0.925393\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(defaultdict(dict,\n",
       "             {'training': {'auc': 0.9999507448940679},\n",
       "              'valid_1': {'auc': 0.925392783369701}}),\n",
       " None)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_params = {\n",
    "                    'objective':'binary',\n",
    "                    'boosting_type':'gbdt',\n",
    "                    'metric':'auc',\n",
    "                    'n_jobs':-1,\n",
    "                    'learning_rate':0.01,\n",
    "                    'num_leaves': 2**8,\n",
    "                    'max_depth':-1,\n",
    "                    'tree_learner':'serial',\n",
    "                    'colsample_bytree': 0.7,\n",
    "                    'subsample_freq':1,\n",
    "                    'subsample':0.7,\n",
    "                    'n_estimators':80000,\n",
    "                    'max_bin':255,\n",
    "                    'seed': SEED,\n",
    "                    'early_stopping_rounds':100, \n",
    "                    'reg_alpha': 0.1,\n",
    "                    'reg_lambda': 0.1,\n",
    "                }\n",
    "features = [x for x in train_df.columns if x not in remove_features and train_df[x].dtype != 'object']\n",
    "local_valid(train_df, 'isFraud', features, lgb_params, return_model=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### bank_type\n",
    "# Tracking normal activity\n",
    "# by doing timeblock frequency encoding\n",
    "#i_cols = ['bank_type'] \n",
    "i_cols = ['uid','uid2','uid3','uid4','uid5','bank_type']\n",
    "periods = ['DT_M','DT_W','DT_D']\n",
    "\n",
    "# We have few options to encode it here:\n",
    "# - Just count transactions\n",
    "# (but some timblocks have more transactions than others)\n",
    "# - Devide to total transactions per timeblock (proportions)\n",
    "# - Use both\n",
    "# - Use only proportions\n",
    "train_df, test_df = timeblock_frequency_encoding(train_df, test_df, periods, i_cols, \n",
    "                                 with_proportions=False, only_proportions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "436\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.941095\tvalid_1's auc: 0.889404\n",
      "[200]\ttraining's auc: 0.962002\tvalid_1's auc: 0.900875\n",
      "[300]\ttraining's auc: 0.977749\tvalid_1's auc: 0.910345\n",
      "[400]\ttraining's auc: 0.987534\tvalid_1's auc: 0.915999\n",
      "[500]\ttraining's auc: 0.993156\tvalid_1's auc: 0.919326\n",
      "[600]\ttraining's auc: 0.996328\tvalid_1's auc: 0.921149\n",
      "[700]\ttraining's auc: 0.998118\tvalid_1's auc: 0.922217\n",
      "[800]\ttraining's auc: 0.999074\tvalid_1's auc: 0.923012\n",
      "[900]\ttraining's auc: 0.999558\tvalid_1's auc: 0.923417\n",
      "[1000]\ttraining's auc: 0.999804\tvalid_1's auc: 0.923788\n",
      "[1100]\ttraining's auc: 0.999917\tvalid_1's auc: 0.923959\n",
      "[1200]\ttraining's auc: 0.99997\tvalid_1's auc: 0.924258\n",
      "[1300]\ttraining's auc: 0.99999\tvalid_1's auc: 0.924289\n",
      "[1400]\ttraining's auc: 0.999997\tvalid_1's auc: 0.924423\n",
      "[1500]\ttraining's auc: 0.999999\tvalid_1's auc: 0.924482\n",
      "[1600]\ttraining's auc: 1\tvalid_1's auc: 0.924657\n",
      "[1700]\ttraining's auc: 1\tvalid_1's auc: 0.924852\n",
      "[1800]\ttraining's auc: 1\tvalid_1's auc: 0.924951\n",
      "Early stopping, best iteration is:\n",
      "[1795]\ttraining's auc: 1\tvalid_1's auc: 0.924989\n"
     ]
    }
   ],
   "source": [
    "lgb_params = {\n",
    "                    'objective':'binary',\n",
    "                    'boosting_type':'gbdt',\n",
    "                    'metric':'auc',\n",
    "                    'n_jobs':-1,\n",
    "                    'learning_rate':0.01,\n",
    "                    'num_leaves': 2**8,\n",
    "                    'max_depth':-1,\n",
    "                    'tree_learner':'serial',\n",
    "                    'colsample_bytree': 0.7,\n",
    "                    'subsample_freq':1,\n",
    "                    'subsample':0.7,\n",
    "                    'n_estimators':80000,\n",
    "                    'max_bin':255,\n",
    "                    'seed': SEED,\n",
    "                    'early_stopping_rounds':100, \n",
    "                    'reg_alpha': 0.0,\n",
    "                    'reg_lambda': 0.0,\n",
    "                }\n",
    "features = [x for x in train_df.columns if x not in remove_features and train_df[x].dtype != 'object'\n",
    "          #  and not re.match('uid[0-9]{0,1}_DT_', x)\n",
    "           ]\n",
    "print(len(features))\n",
    "_, model = local_valid(train_df, 'isFraud', features, lgb_params, return_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "418"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.index('uid_DT_M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base score 0.92499\n",
      "column: uid_DT_M - 0.92451\n",
      "column: uid2_DT_M - 0.92469\n",
      "column: uid3_DT_M - 0.92464\n",
      "column: uid4_DT_M - 0.92376\n",
      "column: uid5_DT_M - 0.92454\n",
      "column: bank_type_DT_M - 0.92466\n",
      "column: uid_DT_W - 0.925\n",
      "column: uid2_DT_W - 0.92476\n",
      "column: uid3_DT_W - 0.92452\n",
      "column: uid4_DT_W - 0.92298\n",
      "column: uid5_DT_W - 0.92412\n",
      "column: bank_type_DT_W - 0.92485\n",
      "column: uid_DT_D - 0.9249\n",
      "column: uid2_DT_D - 0.92496\n",
      "column: uid3_DT_D - 0.92506\n",
      "column: uid4_DT_D - 0.92505\n",
      "column: uid5_DT_D - 0.92472\n",
      "column: bank_type_DT_D - 0.92456\n"
     ]
    }
   ],
   "source": [
    "df = train_df\n",
    "n = df.shape[0]\n",
    "valid_idx = list(df.index[int(n*0.8):])\n",
    "X_val, y_val = df.loc[valid_idx, features], df.loc[valid_idx, TARGET]\n",
    "\n",
    "per_res = permutation_importance_lgb(model, X_val, y_val, roc_auc_score, features[418:], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "430\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.941625\tvalid_1's auc: 0.891418\n",
      "[200]\ttraining's auc: 0.961318\tvalid_1's auc: 0.901469\n",
      "[300]\ttraining's auc: 0.976503\tvalid_1's auc: 0.910513\n",
      "[400]\ttraining's auc: 0.986324\tvalid_1's auc: 0.915862\n",
      "[500]\ttraining's auc: 0.992117\tvalid_1's auc: 0.919077\n",
      "[600]\ttraining's auc: 0.995632\tvalid_1's auc: 0.920911\n",
      "[700]\ttraining's auc: 0.997649\tvalid_1's auc: 0.922053\n",
      "[800]\ttraining's auc: 0.998781\tvalid_1's auc: 0.922814\n",
      "[900]\ttraining's auc: 0.999389\tvalid_1's auc: 0.923133\n",
      "[1000]\ttraining's auc: 0.999706\tvalid_1's auc: 0.923359\n",
      "[1100]\ttraining's auc: 0.999866\tvalid_1's auc: 0.923752\n",
      "[1200]\ttraining's auc: 0.999944\tvalid_1's auc: 0.924046\n",
      "[1300]\ttraining's auc: 0.999979\tvalid_1's auc: 0.924263\n",
      "[1400]\ttraining's auc: 0.999993\tvalid_1's auc: 0.924373\n",
      "[1500]\ttraining's auc: 0.999998\tvalid_1's auc: 0.924559\n",
      "[1600]\ttraining's auc: 1\tvalid_1's auc: 0.924857\n",
      "[1700]\ttraining's auc: 1\tvalid_1's auc: 0.924868\n",
      "[1800]\ttraining's auc: 1\tvalid_1's auc: 0.924967\n",
      "Early stopping, best iteration is:\n",
      "[1780]\ttraining's auc: 1\tvalid_1's auc: 0.925018\n"
     ]
    }
   ],
   "source": [
    "# remove_features += [x for x in per_res if x!= 'base_score' and  per_res['base_score']-per_res[x]<=0.0002]\n",
    "lgb_params = {\n",
    "                    'objective':'binary',\n",
    "                    'boosting_type':'gbdt',\n",
    "                    'metric':'auc',\n",
    "                    'n_jobs':-1,\n",
    "                    'learning_rate':0.01,\n",
    "                    'num_leaves': 2**8,\n",
    "                    'max_depth':-1,\n",
    "                    'tree_learner':'serial',\n",
    "                    'colsample_bytree': 0.7,\n",
    "                    'subsample_freq':1,\n",
    "                    'subsample':0.7,\n",
    "                    'n_estimators':80000,\n",
    "                    'max_bin':255,\n",
    "                    'seed': SEED,\n",
    "                    'early_stopping_rounds':100, \n",
    "                    'reg_alpha': 0.1,\n",
    "                    'reg_lambda': 0.1,\n",
    "                }\n",
    "features = [x for x in train_df.columns if x not in remove_features and train_df[x].dtype != 'object'\n",
    "          #  and not re.match('uid[0-9]{0,1}_DT_', x)\n",
    "           ]\n",
    "print(len(features))\n",
    "_, model = local_valid(train_df, 'isFraud', features, lgb_params, return_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n",
      "418\n"
     ]
    }
   ],
   "source": [
    "print(features.index('card3_DT_D_hour_dist'))\n",
    "print(features.index('uid_DT_M'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base score 0.92502\n",
      "column: card5_DT_M_month_day_dist - 0.92508\n",
      "column: card5_DT_D_hour_dist_best - 0.92509\n",
      "column: card5_DT_W_week_day_dist_best - 0.92499\n",
      "column: card5_DT_M_month_day_dist_best - 0.9253\n",
      "column: bank_type_DT_D_hour_dist - 0.92482\n",
      "column: bank_type_DT_W_week_day_dist - 0.92512\n",
      "column: bank_type_DT_M_month_day_dist - 0.92525\n",
      "column: bank_type_DT_D_hour_dist_best - 0.9251\n",
      "column: bank_type_DT_W_week_day_dist_best - 0.92499\n",
      "column: bank_type_DT_M_month_day_dist_best - 0.92514\n"
     ]
    }
   ],
   "source": [
    "df = train_df\n",
    "n = df.shape[0]\n",
    "valid_idx = list(df.index[int(n*0.8):])\n",
    "X_val, y_val = df.loc[valid_idx, features], df.loc[valid_idx, TARGET]\n",
    "\n",
    "per_res = permutation_importance_lgb(model, X_val, y_val, roc_auc_score, features[408:418], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "423\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.940908\tvalid_1's auc: 0.891213\n",
      "[200]\ttraining's auc: 0.96146\tvalid_1's auc: 0.902973\n",
      "[300]\ttraining's auc: 0.977091\tvalid_1's auc: 0.911383\n",
      "[400]\ttraining's auc: 0.986845\tvalid_1's auc: 0.917175\n",
      "[500]\ttraining's auc: 0.992506\tvalid_1's auc: 0.920487\n",
      "[600]\ttraining's auc: 0.995868\tvalid_1's auc: 0.922072\n",
      "[700]\ttraining's auc: 0.997774\tvalid_1's auc: 0.923244\n",
      "[800]\ttraining's auc: 0.998863\tvalid_1's auc: 0.923441\n",
      "[900]\ttraining's auc: 0.999418\tvalid_1's auc: 0.923873\n",
      "[1000]\ttraining's auc: 0.999716\tvalid_1's auc: 0.924326\n",
      "[1100]\ttraining's auc: 0.999869\tvalid_1's auc: 0.924556\n",
      "[1200]\ttraining's auc: 0.999946\tvalid_1's auc: 0.924904\n",
      "[1300]\ttraining's auc: 0.999979\tvalid_1's auc: 0.925051\n",
      "[1400]\ttraining's auc: 0.999993\tvalid_1's auc: 0.925121\n",
      "[1500]\ttraining's auc: 0.999998\tvalid_1's auc: 0.925408\n",
      "[1600]\ttraining's auc: 0.999999\tvalid_1's auc: 0.925686\n",
      "[1700]\ttraining's auc: 1\tvalid_1's auc: 0.925743\n",
      "[1800]\ttraining's auc: 1\tvalid_1's auc: 0.925925\n",
      "[1900]\ttraining's auc: 1\tvalid_1's auc: 0.926028\n",
      "[2000]\ttraining's auc: 1\tvalid_1's auc: 0.926061\n",
      "[2100]\ttraining's auc: 1\tvalid_1's auc: 0.926184\n",
      "[2200]\ttraining's auc: 1\tvalid_1's auc: 0.926287\n",
      "Early stopping, best iteration is:\n",
      "[2147]\ttraining's auc: 1\tvalid_1's auc: 0.926348\n"
     ]
    }
   ],
   "source": [
    "# remove_features += [x for x in per_res if x!= 'base_score' and  per_res['base_score']-per_res[x]<=0.0]\n",
    "lgb_params = {\n",
    "                    'objective':'binary',\n",
    "                    'boosting_type':'gbdt',\n",
    "                    'metric':'auc',\n",
    "                    'n_jobs':-1,\n",
    "                    'learning_rate':0.01,\n",
    "                    'num_leaves': 2**8,\n",
    "                    'max_depth':-1,\n",
    "                    'tree_learner':'serial',\n",
    "                    'colsample_bytree': 0.7,\n",
    "                    'subsample_freq':1,\n",
    "                    'subsample':0.7,\n",
    "                    'n_estimators':80000,\n",
    "                    'max_bin':255,\n",
    "                    'seed': SEED,\n",
    "                    'early_stopping_rounds':100, \n",
    "                    'reg_alpha': 0.0,\n",
    "                    'reg_lambda': 0.0,\n",
    "                }\n",
    "features = [x for x in train_df.columns if x not in remove_features and train_df[x].dtype != 'object'\n",
    "          #  and not re.match('uid[0-9]{0,1}_DT_', x)\n",
    "           ]\n",
    "print(len(features))\n",
    "_, model = local_valid(train_df, 'isFraud', features, lgb_params, return_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### D Columns\n",
    "# From columns description we know that\n",
    "# D1-D15: timedelta, such as days between previous transaction, etc.\n",
    "# 1. I can't imagine normal negative timedelta values (Let's clip Values)\n",
    "# 2. Normalize (Min-Max, Standard score) All D columns, except D1,D2,D9\n",
    "# 3. Do some aggregations based on uIDs\n",
    "# 4. Freaquency encoding\n",
    "# 5. D1,D2 are clipped by max train_df values (let's scale it)\n",
    "i_cols = ['D'+str(i) for i in range(1,16)]\n",
    "uids = ['uid','uid2','uid3','uid4','uid5','bank_type']\n",
    "aggregations = ['mean','std']\n",
    "\n",
    "####### uIDs aggregations\n",
    "train_df, test_df = uid_aggregation(train_df, test_df, i_cols, uids, aggregations)\n",
    "\n",
    "####### Cleaning Neagtive values and columns transformations\n",
    "for df in [train_df, test_df]:\n",
    "\n",
    "    for col in i_cols:\n",
    "        df[col] = df[col].clip(0) \n",
    "    \n",
    "    # Lets transform D8 and D9 column\n",
    "    # As we almost sure it has connection with hours\n",
    "    df['D9_not_na'] = np.where(df['D9'].isna(),0,1)\n",
    "    df['D8_not_same_day'] = np.where(df['D8']>=1,1,0)\n",
    "    df['D8_D9_decimal_dist'] = df['D8'].fillna(0)-df['D8'].fillna(0).astype(int)\n",
    "    df['D8_D9_decimal_dist'] = ((df['D8_D9_decimal_dist']-df['D9'])**2)**0.5\n",
    "    df['D8'] = df['D8'].fillna(-1).astype(int)\n",
    "\n",
    "####### Values Normalization\n",
    "i_cols.remove('D1')\n",
    "i_cols.remove('D2')\n",
    "i_cols.remove('D9')\n",
    "periods = ['DT_D','DT_W','DT_M']\n",
    "for df in [train_df, test_df]:\n",
    "    df = values_normalization(df, periods, i_cols)\n",
    "\n",
    "for col in ['D1','D2']:\n",
    "    for df in [train_df, test_df]:\n",
    "        df[col+'_scaled'] = df[col]/train_df[col].max()\n",
    "        \n",
    "####### Global Self frequency encoding\n",
    "# self_encoding=True because \n",
    "# we don't need original values anymore\n",
    "i_cols = ['D'+str(i) for i in range(1,16)]\n",
    "train_df, test_df = frequency_encoding(train_df, test_df, i_cols, self_encoding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "680\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.954686\tvalid_1's auc: 0.899269\n",
      "[200]\ttraining's auc: 0.974517\tvalid_1's auc: 0.911778\n",
      "[300]\ttraining's auc: 0.986973\tvalid_1's auc: 0.920285\n",
      "[400]\ttraining's auc: 0.993666\tvalid_1's auc: 0.925597\n",
      "[500]\ttraining's auc: 0.997068\tvalid_1's auc: 0.92868\n",
      "[600]\ttraining's auc: 0.998699\tvalid_1's auc: 0.930277\n",
      "[700]\ttraining's auc: 0.999436\tvalid_1's auc: 0.93118\n",
      "[800]\ttraining's auc: 0.999771\tvalid_1's auc: 0.93188\n",
      "[900]\ttraining's auc: 0.999915\tvalid_1's auc: 0.932105\n",
      "[1000]\ttraining's auc: 0.999971\tvalid_1's auc: 0.93236\n",
      "[1100]\ttraining's auc: 0.999992\tvalid_1's auc: 0.932657\n",
      "[1200]\ttraining's auc: 0.999998\tvalid_1's auc: 0.932874\n",
      "[1300]\ttraining's auc: 1\tvalid_1's auc: 0.933142\n",
      "[1400]\ttraining's auc: 1\tvalid_1's auc: 0.933322\n",
      "[1500]\ttraining's auc: 1\tvalid_1's auc: 0.933376\n",
      "[1600]\ttraining's auc: 1\tvalid_1's auc: 0.933407\n",
      "Early stopping, best iteration is:\n",
      "[1561]\ttraining's auc: 1\tvalid_1's auc: 0.933518\n"
     ]
    }
   ],
   "source": [
    "features = [x for x in train_df.columns if x not in remove_features and train_df[x].dtype != 'object'\n",
    "           ]\n",
    "print(len(features))\n",
    "_, model = local_valid(train_df, 'isFraud', features, lgb_params, return_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA30AAADhCAYAAAB8xtwcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAAIABJREFUeJzt3XucXWV97/HPb88lN3InN3IhREKEoAYYIUhLQRECtQW8FNCj2KJIi6fl1PaI1qpFDwfbY6W8SlUEKlpCQBBEy0VAEC9kyAQiSYghISSTIfdkkgy5ze13/thr7ay99trXmWRm9nzfr9e8Zu+111577XV9fs/ze55t7o6IiIiIiIhUp1Rfr4CIiIiIiIgcOQr6REREREREqpiCPhERERERkSqmoE9ERERERKSKKegTERERERGpYgr6REREREREqpiCPhERkV5iZueZ2cq+Xg8REZEoBX0iItInzOytyF+3mR2IPP9YX69fMWZWa2ZuZjPDae7+nLvP7cXPMDPbYGav9HA5OesqIiKDR21fr4CIiAxO7n5M+NjM1gOfcven881vZrXu3nk01q0feS8wDphiZqe5+8t9vUIiIjLwqKVPRET6JTP7upndb2b3mVkb8D/M7GwzW2xmu81ss5ndZmZ1wfxha9ZnzGytmbWa2W2R5Z1kZs+b2R4z22FmCyOv/buZtZjZXjNbYmbvibxWa2b/aGavB683mdlxwPPBLCuD1skPmdkFQQAbvneumf0yWN/lZvbHkdf+K1j/x82szcxeMLMTYpvhauDHwBPB4+j2+bWZ3RRsj31m9oiZjQ+2114zazSzGcHsOeta2V4REZGBSEGfiIj0Z5cDC4HRwP1AJ/A3wLHAOcAC4DOx91wCnAGcRjpQvCCY/n+A/wbGAtOA2yPvaQTeSbpV7UHgR2Y2JHjt74EPB581BvgUcBA4N3h9rrsf4+4PRVfCzOqBnwWfOQH4X8D9ZnZiZLaPAv8YfG4z8LXI+48BPgjcG/xdZWbxDJ0rg2VMA94O/Ba4I1je68GyKbauIiJS3RT0iYhIf/Zrd/+pu3e7+wF3X+Luje7e6e7rSAc4fxR7z/919z3uvh54DpgXTO8AZgJT3P2gu/8mfIO7/9DddwXpo/8MjALC4OxTwBfdfU2wHsvcfVcJ634OUA/8i7t3BKmrj5MO1EIPunuTu3eQDuzmRV77MPAW8AzwKDAcuDj2GXe5+zp3bwWeBF5z92eD7/Ej0oGviIgMcgr6RESkP9sYfWJmbzez/zazLWa2F7iJdKtf1JbI4/1A2Hfwc0Ad0BSkWmbSJc3sf5vZ781sD9AKjIgsdzrpVrNyHQc0u7tHpm0AppawrpBO57zf3bvc/QDwMLEUT2Br5PGBhOfHICIig54GchERkf7MY8+/CywGrnD3t8zs74APlLQg982kW+0ws3OBp8zsedKtf38LvA94NZh9D2DB443A24DfF1m3uE3AdDOzSOA3Ayg6EqeZHU+6BfN0M7simDwcqDezsUHLXjmKrauIiFQxtfSJiMhAMpJ0QLbPzE4mtz9fXmb2Z2YWtrLtJh0IdQXL7AR2kG4J/Crplr7QncDXzextwU8ozDOzce7eBewEZuX5yN8Gy/2cmdWZ2XtJ9zd8oITV/QTpAHQO6ZTPecHjrWSnh5akhHUVEZEqpqBPREQGks+RTnFsI93qd38Z7z0LWGJm+0iPiHm9uzcDjwFPA2uA9cBeYHPkff8CPEK6b91e0v0IhwavfQVYGIzO+cHoh7n7IeBPgEtJB5S3AR9199dKWNdPALe7+5bI3+bgO8dTPEuVd11FRKS6WXZXAxEREREREakmaukTERERERGpYgr6REREREREqpiCPhERERERkSqmoE9ERERERKSKKegTERERERGpYgP2x9mPPfZYnzlzZl+vhoiIiIiISJ9YunTpDnefUGy+ARv0zZw5k6ampr5eDRERERERkT5hZhtKmU/pnSIiIiIiIlVMQZ+IiIiIiEgVU9AnIiIiIiJSxRT0iZRhYWMzH7+rkYWNzX29KiIiIiIiJRmwA7mIHG0LG5v54sPLAfjVmh0AfPSsGX25SiIiIiIiRamlT6REj6/YXPC5iIiIiEh/pKBPpEQXnzql4HMRERERkf5I6Z0iJQpTOR9fsZmLT52i1E4RERERGRAU9ImU4aNnzVCwJyIiIiIDitI7RUREREREqpiCPhERERERkSpWNOgzs6Fm9qKZ/c7MVprZPwXTTzCzRjNbY2b3m1l9MH1I8Hxt8PrMyLK+EExfbWYXRaYvCKatNbMbe/9rioiIiIiIDE6ltPQdAt7r7u8C5gELzGw+8A3gW+4+G2gFrgnmvwZodfcTgW8F82FmpwBXAnOBBcB/mFmNmdUAtwMXA6cAVwXzioiIiIiISA8VDfo87a3gaV3w58B7gQeD6fcAlwWPLw2eE7z+PjOzYPoidz/k7m8Aa4Ezg7+17r7O3duBRcG8IiIiIiIi0kMl9ekLWuSWAduAp4DXgd3u3hnM0gJMDR5PBTYCBK/vAcZHp8fek2960npca2ZNZta0ffv2UlZdRERERERkUCsp6HP3LnefB0wj3TJ3ctJswX/L81q505PW4w53b3D3hgkTJhRfcRERERERkUGurNE73X038BwwHxhjZuHv/E0DNgWPW4DpAMHro4Fd0emx9+SbLiIiIiIiIj1UyuidE8xsTPB4GHABsAp4FvhwMNvVwE+Cx48Gzwle/4W7ezD9ymB0zxOA2cCLwBJgdjAaaD3pwV4e7Y0vJyIiIiIiMtjVFp+FKcA9wSibKeABd/+Zmb0KLDKzrwMvA3cF898F/NDM1pJu4bsSwN1XmtkDwKtAJ3C9u3cBmNlngSeBGuBud1/Za99QRERERERkELN0I9zA09DQ4E1NTX29GiIiIiIiIn3CzJa6e0Ox+crq0yciIiIiIiIDi4I+ERERERGRKqagT0REREREpIop6BMREREREaliCvpERERERESqmII+ERERERGRKqagT0REREREpIop6BMREREREaliCvpERERERESqmII+ERERERGRKqagT0REREREpIop6BMREREREaliCvpERERERESqmII+ERERERGRKlY06DOz6Wb2rJmtMrOVZvY3wfSvmtmbZrYs+Lsk8p4vmNlaM1ttZhdFpi8Ipq01sxsj008ws0YzW2Nm95tZfW9/URERERERkcGolJa+TuBz7n4yMB+43sxOCV77lrvPC/4eAwheuxKYCywA/sPMasysBrgduBg4BbgqspxvBMuaDbQC1/TS9xMRERERERnUigZ97r7Z3V8KHrcBq4CpBd5yKbDI3Q+5+xvAWuDM4G+tu69z93ZgEXCpmRnwXuDB4P33AJdV+oVERERERETksLL69JnZTOA0oDGY9Fkze8XM7jazscG0qcDGyNtagmn5po8Hdrt7Z2x60udfa2ZNZta0ffv2clZdRERERERkUCo56DOzY4CHgBvcfS/wbeBtwDxgM/DNcNaEt3sF03Mnut/h7g3u3jBhwoRSV11ERERERGTQqi1lJjOrIx3w3evuPwZw962R178H/Cx42gJMj7x9GrApeJw0fQcwxsxqg9a+6PwiIiIiIiLSA6WM3mnAXcAqd//XyPQpkdkuB1YEjx8FrjSzIWZ2AjAbeBFYAswORuqsJz3Yy6Pu7sCzwIeD918N/KRnX0tERERERESgtJa+c4CPA8vNbFkw7YukR9+cRzoVcz3wGQB3X2lmDwCvkh7583p37wIws88CTwI1wN3uvjJY3ueBRWb2deBl0kGmiIiIiIiI9JClG9oGnoaGBm9qaurr1RAREREREekTZrbU3RuKzVfW6J0iIiIiIiIysCjoExERERERqWIK+kRERERERKqYgj4REREREZEqpqBPRERERESkiinoExERERERqWIK+kRERERERKqYgj4REREREZEqpqBPRERERESkiinoExERERERqWIK+kRERERERKqYgj4REREREZEqpqBPRERERESkiinoExERERERqWJFgz4zm25mz5rZKjNbaWZ/E0wfZ2ZPmdma4P/YYLqZ2W1mttbMXjGz0yPLujqYf42ZXR2ZfoaZLQ/ec5uZ2ZH4siIiIiIiIoNNKS19ncDn3P1kYD5wvZmdAtwIPOPus4FngucAFwOzg79rgW9DOkgEvgKcBZwJfCUMFIN5ro28b0HPv5qIiIiIiIgUDfrcfbO7vxQ8bgNWAVOBS4F7gtnuAS4LHl8K/MDTFgNjzGwKcBHwlLvvcvdW4ClgQfDaKHd/wd0d+EFkWSIiIiIiItIDZfXpM7OZwGlAIzDJ3TdDOjAEJgazTQU2Rt7WEkwrNL0lYbqIiIiIiIj0UMlBn5kdAzwE3ODuewvNmjDNK5ietA7XmlmTmTVt37692CqLiIiIiIgMeiUFfWZWRzrgu9fdfxxM3hqkZhL83xZMbwGmR94+DdhUZPq0hOk53P0Od29w94YJEyaUsuoiIiIiIiKDWimjdxpwF7DK3f818tKjQDgC59XATyLTPxGM4jkf2BOkfz4JXGhmY4MBXC4EngxeazOz+cFnfSKyLBEREREREemB2hLmOQf4OLDczJYF074I3AI8YGbXAM3AR4LXHgMuAdYC+4E/B3D3XWb2NWBJMN9N7r4rePyXwPeBYcDjwZ+IiIiIiIj0kKUHzBx4GhoavKmpqa9XQ0REREREpE+Y2VJ3byg2X1mjd4qIiIiIiMjAoqBPRERERESkiinoExERERERqWIK+kRERERERKqYgj4REREREZEqpqBPRERERESkiinoExERERERqWIK+kRERERERKqYgj4REREREZEqpqBPRERERESkiinoExERERERqWIK+kRERERERKqYgj4REREREZEqpqBPRERERESkihUN+szsbjPbZmYrItO+amZvmtmy4O+SyGtfMLO1ZrbazC6KTF8QTFtrZjdGpp9gZo1mtsbM7jez+t78giIiIiIiIoNZKS193wcWJEz/lrvPC/4eAzCzU4ArgbnBe/7DzGrMrAa4HbgYOAW4KpgX4BvBsmYDrcA1PflCIiIiIiIicljRoM/dnwd2lbi8S4FF7n7I3d8A1gJnBn9r3X2du7cDi4BLzcyA9wIPBu+/B7iszO8gIiIiIiIiefSkT99nzeyVIP1zbDBtKrAxMk9LMC3f9PHAbnfvjE0XERERERGRXlBp0Pdt4G3APGAz8M1guiXM6xVMT2Rm15pZk5k1bd++vbw1FhERERERGYQqCvrcfau7d7l7N/A90umbkG6pmx6ZdRqwqcD0HcAYM6uNTc/3uXe4e4O7N0yYMKGSVRcRERERERlUKgr6zGxK5OnlQDiy56PAlWY2xMxOAGYDLwJLgNnBSJ31pAd7edTdHXgW+HDw/quBn1SyTiIiIiIiIpKrttgMZnYfcB5wrJm1AF8BzjOzeaRTMdcDnwFw95Vm9gDwKtAJXO/uXcFyPgs8CdQAd7v7yuAjPg8sMrOvAy8Dd/XatxMRERERERnkLN3YNvA0NDR4U1NTX6+GiIiIiIhInzCzpe7eUGy+nozeKSIiIiIiIv2cgj4REREREZEqpqBPRERERESkiinoExERERERqWIK+kRERERERKqYgj4REREREZEqpqBPRERERESkiinoExERERERqWIK+kRERERERKqYgj4REREREZEqpqBPRERERESkiinoExERERERqWIK+kRERERERKqYgj4REREREZEqVjToM7O7zWybma2ITBtnZk+Z2Zrg/9hgupnZbWa21sxeMbPTI++5Oph/jZldHZl+hpktD95zm5lZb39JERERERGRwaqUlr7vAwti024EnnH32cAzwXOAi4HZwd+1wLchHSQCXwHOAs4EvhIGisE810beF/8sEREREZEeWbqhldufXcvSDa19vSoiR11tsRnc/XkzmxmbfClwXvD4HuA54PPB9B+4uwOLzWyMmU0J5n3K3XcBmNlTwAIzew4Y5e4vBNN/AFwGPN6TLyUiIiIiElq6oZWP3bmY9s5u6mtT3Pup+Zxx/NjibxSpEpX26Zvk7psBgv8Tg+lTgY2R+VqCaYWmtyRMFxERERHpsaUbWrn16ddo7+ym26Gjs5vF63b29WqJHFVFW/rKlNQfzyuYnrxws2tJp4IyY8aMStZPRERERAaJpRtaueqOF2jvShcvUwZ1tSnmzxrfx2smcnRV2tK3NUjbJPi/LZjeAkyPzDcN2FRk+rSE6Ync/Q53b3D3hgkTJlS46iIiIiIyGDz0Uksm4AN4x9TRRz21U30JpT+oNOh7FAhH4Lwa+Elk+ieCUTznA3uC9M8ngQvNbGwwgMuFwJPBa21mNj8YtfMTkWWJiIjIILOwsZmP39XIwsbmvl4VqQI72g5lPZ80auhRD/g+dudivvnz1XzszsUK/KTPFE3vNLP7SA/EcqyZtZAehfMW4AEzuwZoBj4SzP4YcAmwFtgP/DmAu+8ys68BS4L5bgoHdQH+kvQIocNID+CiQVxEREQGoYWNzXzx4eUA/GrNDgA+epa6c0jljh05pODzI23xup05fQk1gIz0hVJG77wqz0vvS5jXgevzLOdu4O6E6U3AqcXWQ0RERKrb4ys25zxX0Cc98aHTp/HAkmY6u6E2lX5+NM2fNZ762hQdnd3qSyh9qrcHchERERGpyMWnTsm08IXPRXoqlUph3d2kUpX2aqrcGceP5d5PzWfxup3MnzVerXzSZxT0iYiISL8Qtuo9vmIzF586Ra180mOL1+2ks6sbB7q6+ia98ozjxyrYkz6noE9ERET6jY+eNUPBnvQapVeKpCnoExERGWCWbmhVuphICZReKdViYWNzj7IgFPSJiIgMIOEQ8O2d3dTXpo76b46JDDRKr5SBrjdGNj76PVpFRESkYklDwIuISPVKGtm4XAr6REREBpCwj1KNoT5KIiKDQHwk40pGNlZ6p4iIyACiPkoiIoNLb4xsbOnfUx94GhoavKmpqa9XQ0RERCSRBtwRkSPNzJa6e0Ox+dTSJyIiItLL+vuAOwpI+x/tEzmSFPSJHGW6qIuIVL+kAXf6yzW/vwekg9HSDa1cdccLdHQ5dTXGfdeerX0ivUoDucigsXRDK7c/u5alG1r7dB0+dudivvnz1XzszsV9ui4iIgPNwsZmPn5XIwsbm/t6VYrqzwPuaATY/uehl1po73IcaO9yHnqppa9X6YjpD+WxwUgtfTIo9Jdazf5c8ysi0peKZUH0xu9UHU39ecCd+bPGU1uToqOzm5qa/hWQDlY72g4VfF4t+kt5bDBS0CeDQn8JtsKa347O7n5X8ysicjQkBXelFASTfqeqPwd90M9/FDwcyG+ADuhXbeJ7oVr3Sn8pjw1GCvpkUOjtYGthY3NFw+b255rf3qR+iyKSJF9wV0pB8OJTp2Ra+MLnUpnF63bS2Z1OJezqdhW8+4GJI4cUfF4tKi2PqVzRcz0K+sxsPdAGdAGd7t5gZuOA+4GZwHrgz9y91cwM+DfgEmA/8El3fylYztXAl4LFft3d7+nJeknlqvWk6s1gq6cpRvGa31K2+UDaL72VutGft8tA2h/9WX/ex4NRocqsYvuh0OvR1/IFd6UUBHv6O1V9cSz1xmceifMkur1rUsam3QdY2NhM6/72fn+uVbJNe7If8p0XPVlm+N6xw+sz2/yDp0/jR0tbMufAB0+fVtYyS/kOc6eMYuSwuiNyPJa6Pc44fixf/sDczPqE/UnPOH5szraObqebfrayrHJFOedNdD/09Niv5LiotCGhXL3R0ne+u++IPL8ReMbdbzGzG4PnnwcuBmYHf2cB3wbOCoLErwANpFuzl5rZo+4+qHp39oeCjfKsS9ObKUalbPNy9kt/OI56I3Wj3O1SmzI+0jCdD54+7Yh/b50nvaPUfazR7HpP/PoQfb56S1veyqxi+6rQ6/HXvvyBuYnBXakVc3Mmj6R1fztzJo8s+7v35nlbaoGyp5/Z2/eIULi9H3qphQeXtrCwsRkHUsYRua711r2pku/ak/2Qr5I36doEZL5j+DgpmAjX51BHd842v+/TvZ8JFP8OBgypyz1PS/ncfNuy3HLKVx5dQUeX86s1OzLf/5Nnz+Q7z6/LrGfzzn18/4X1tHd2kzKj273kckUp5YNC+6EnAXEp26HQtfe51dv4zB+9LTGgbjvQwcrNeysODo9EeuelwHnB43uA50gHfZcCP/D0r8EvNrMxZjYlmPcpd98FYGZPAQuA+47AuuXVl4Xl/lKIHAh51pXWhlS6jZM+rzdTjErZ5qXul/5SQO6NVNpyt0t7l7OwsZmHXmo54ufPQDhPBoKs/ZdnO4aj2cHh0ey0rSuTFHxFa86njRmWNf/9S5oz17xix3yh1+Ovte5vzxvcFev/1pN7ZW+et6WuR6mfWei+1pv3iLgwrbazqzvTf+xIXNd6s4xTyTZt3d9e0ntueWwVT6zcwoK5k7nxkpNZuqGVO55/PWuesJI3fm36zi9f51drtmeCDMzo6EwOJsLvkLTNrz//xF6/xsUrqp3s7VDO/sm3/cs5Br/7y9fp6DrcYzF8zxMrt2TN98TKLZll4k4qZRieaZleuqG14HqGwVy+8kGh/XAkj8/49p4zKbsC6+evbuX5NdtzAuqDHd2ZeSodyKqnQZ8DPzczB77r7ncAk9x9M4C7bzazicG8U4GNkfe2BNPyTc9hZtcC1wLMmNF7zZ99HXT1l0Jkfx9kpCdplZVs43yf19MUo6hStnmp++VIFJALtQzkW3ZvpNIW+85LN7Ty5u4DmdHnnPTFqL0je98eicqc6LqZwc9XbmHs8PqsVJSjlXZUrqOVQlKKscPr0zdz0jfbscPrc+axIs+lsEJplY+v2Jz1fM+Bjqz3dnQdLmAUOx8LvZ70WrHgLp+sglxH/gJVtIUlrBmfO2VU0etoqediqfeTUq7dxe5rvXmPSBK+t72jm27SAUpPt09cufffQtepSrbpdefOKvqeWx5blWll+s7z69iy9yA/e2UTnd3Z84WVvPFr0fKW3Ye/Y1f6jpQvmJg/azyplNEd3K8LbfPeEK+oNrI/r5z9k2/7l3MMbt17MGeaO2zafSBr2oK5k/n+C+szy/zyB+ayYtMeHlzawn0vFq7kHTu8PmsgnHigG13nUo79qELnwfxZ46lNGR1d6eB0/qzxOfPHt/fEUUOBPVnLSQqo4yrJMutp0HeOu28KArunzOz3BeZNul97gem5E9NB5R0ADQ0NvTawUV8HXf0l2CqlsH4k8p+Tlp+03Hht1R3Pv86cySPL7r9Q6jYulMZZaYpRXCnbPGmepO3U2wXkYi0DhSpHKi3URd+fb7vE0zbePXMsL65PZ4N3czh4qCTNotTa8Xs/NZ/v/PJ1nnp1K79r2cPvWpZnpaKEnwcUPZ96UuFUzrr31nD3vRU4tu5vx0hf7FPB87gPnj6N+5s20tnl1NZYr/ZxqXbF0iovPnUKS9bvyjwfPayO7W8d3gd1NYd/xrfYdeqM48fyybNnZlpJ4q13vdWfOlqQi57r8e8cBoZRYeE/2p8pPH/WbG1j8bqdbH+rHXcvei6Wej8p5bsX6y5QbBnhd/jyB+bSur+dscPrs/pIFbtGRJdf6L7ek2tVUkE4n2LXqVK26f1Lsn/D8YV1O4u+J97K9OTKLVkB37gR9fzdhXMy6xL2vwsL41v3Hsq06oUtfZ2dycHE6i1tdEZaui44eVJOOl9vilZUJ/Xpmz+r9J/vyLf9Sz3Pl25ozQlyJo8cwpa2Q5lK64kj67nhgvS2fv/cyVnLvP3ZtXR2BRkiHd3c+vRr3HDBSTnHeuv+dlJGpmIxHujG17nUMm0p54FH/lZvacspN8WvH9f90ds4f85E7l/SzKub99Ld7Zl1TargDlWSZdajoM/dNwX/t5nZw8CZwFYzmxK08k0BtgWztwDTI2+fBmwKpp8Xm/5cT9arFNGDo9AFvDcKOMWW0Zs3xVIUugkUKqwfifzn+PKvjKQnLoqlJ86dMiqrtmrDzv187M7FZfVfCHOib336taL7NCmNc+mGVh56qYUHmjbS1UtplKUESNF58l105h43Ous98eflKtYy0NuVI0k569eff2LB9erqdobU1WQu7ik7HDyUkj5YaUHmjOPHcrCjK2taNBWlo7Obh15q4ccvtRRcdk8qnMrt01iscBlPbUrSm7+TNn/WeIbUFS84pyyd0pMytfOVo9S0yvDeBGT2LcAV787er4WuUwsbm7NaSdbt2JdViC12jSu18iJakIue6/HvnK9GeOXmvfzwmrMynxlPmQrFz8X4PTzpnp3vPl/su5fSXSBpGQsbmzOFxK5upzZlnDdnIs+9tp3OrvwVdeF2ihfYi113elw5bkEVT5HzuJQ+88XWNx5UTBw1lKdWbuGJlVtoO9CR+N4FcydnjmGAIXU1HIgcG+NG1Ofs16/+yVzueP51Nuzcn2nBOOfEY7nhgpOA/H364t/xQEdXSdsy33lyw6KXee617Zx30gRuvfK0xPnCiuq851gZP98R3/7Rz0u6Z0fnC+9ZBtTVpCsAXnkzu5Wrvcsz2zr+WfHWud+s3cGS9btyjvVoJVdN5P4IcPuza7MyDqIBYzHFzoMfv9SSSV3t6HLuX9KcM//155+Yc/044/ixOdlCQGZ7pQzeOW00Jxw7gp372o9+nz4zGwGk3L0teHwhcBPwKHA1cEvw/yfBWx4FPmtmi0gP5LInCAyfBG42s3CrXQh8oZx1KTcFLamgl3Qz7I0CTqnL6GnLSKmSan+TLgRJ2/BI5D9HRfO8O7qc7/7yde74REPm9ZHD6jItA5DbXF9shK2xw+tZtnE3T726FSi+T+NpnHMmj8wpJFSSRllK4TqfpRtaufXp1zLrcDCS4rRyU/aFM3xeacVFvDIk3jLQWy3SYeFlxaY9RDLKMvuneee+rO0VT6/cvPsANSnDIrVjUFr6YE8KMvFKiHnTx7Bl78HM9jHIWXZY8Ej6LuVu06ygtoQ+jYUKl/HUJiDn2LzlsVV8/4X1WdN6MohRKZVd0f5GnV3qP1mO6LEV9oEBMoWypRta+epPV9LR2U3jG7u479Pzufnyd1R0rYgXYuPhb9JRAAAgAElEQVR9Ugopp+KlUGp19PWwQBgXPebzpUxBdotAvnt49J5d6D6fdC+NTquku0D080LtXc7Pg3sbJFfUlVIRlU9Pr1XhedxV5DyOX1fnThlV8udAettOGDmEmhR0dUNtCkbU1xS9vr1/7mS+9+s36OpOt0aeNPGYTAYJwAnHjsj5nJt+tjKrPOCkj7FoMJ0UTFTyHfOdJzcseplHlm0C4JFlm9i1r50X1+/KCfSjwdaEkUO4bN7UzDZYvO7wz3e0dzkfu3MxC+ZO5tYrTytrvVKWrmy+4t0zEo/j6D2L4LOeX7OD2RNGsHv/4fTy806akPfzwvvGrU+/xm/W7shbKZ1UyZWvojS6fcLpc48bnWk5j5aRi50H8ZB54qih1G9tSxy4Kl/Lezj99mfXZhpZuh1eadnD8pY9DB9Sw/gR6fJMtNKuFD1p6ZsEPJz+JQZqgYXu/oSZLQEeMLNrgGbgI8H8j5H+uYa1pH+y4c8B3H2XmX0NWBLMd1M4qEspKklBSyroJXWeLXWUxnJSEvv6x2Sj3/1QRzdf/skKumPpLPkuLpXmP5cqnucdfx62DCR9fqERtvKl+0Dx/dG8cx8bd+2neee+TGfwuHLaH0opXEcl1frEa6Z/1LSR+bPGJ/6wa08qLpIK5XMmj8wE0NEUokolFV6ibn92DW/uTh8H0e0VTa9cu30fABeekp0iE00fNJLTB5MKxoU6h0fFKyF27mvPqkSBdD/L8GK/Zmtb5uYc/y6VtPKH6x4e20l9FqIKFS6TOtBHj8vocRs1rK6GpRtac4LZUCmpZYW+czxw/93G3SXvn8EuPH/DzISFjc38qGljJjMhLPxDunLixy+18MHTp1WUth6vUIDSK1HKqXg54/h0GukDTRvZtb8jk1oNZK5NC+ZOZtnG3cybPobZk0ZmZQ7MmTwyU8sfnj/x6+m0MUP5q/Nn522VSbpn5Jsn6V4K5EyL9hUvRTx9MS5MZYtX1EUrotqDILCUa088hbTSa1Up19mRw+qyvkf0eXx9iqX+X3lWulD/uQeWZb0/fn2D9HHokdauEyeN5KXmVjqDwPG6P3pbzvxJ5YHofSZfWWrvoc6s9+w91Fm0MjjfefLca9uz5gsDvuh8QFawtWXvoax7UPxcONjRnblXJQV++foKdztZ52S+/pjxc27nvnYum3dcVmtlIWccP5YbLjgpc2zXpIxhdTXU1qTo6srfdzirT3CXc29wTfxIw/SsCtR7G9PnV/T+Xl+b4r5Pzy+aNfah06fxwJLmrOPm/DkTM/fdcs6bNVvbcvolOvDWoS4eWbYps49+tWYHqeFjji1lmRUHfe6+DnhXwvSdwPsSpjtwfZ5l3Q3cXcl6VJKCVmr+cilpF8VqKSsd6bGc1ply+vVEC1FOOj0uXljMd3GJHuy90acvvt5XvHtG5mIB2elF8ZtO9EZ+xvFjufXp17KWHd50i6X75NsfSze0csvjq1gS1PR95/l1XDbvuKyg14BUCla8uYeFjc0l3bTjhetFTRt5f6wPTPj5D73Uwo+C/kx1tSk+csa0xJvM+iDN9csfmEttiszF5tTjRucdeaxcP3xhPZ97YBnzpo9h+JBa/u2ZNZkUop6k98YLS3EHYjeH8GadlF4ZT5GJ9v9xklv6ihWMC5k/azw1wfaG9IV38bqdWWnJYT+nedPH5Nyco98lrGyJpp0UE133B5e2ZN3s8gkLl/HPiqc2LZg7OWddo+prDAeeXrWVZ1ZtJeyeEi1IlFMDnE80cAd4qowWJEkfIw+91JLpPxTNTIhfE7e1HerVAc2K9Q0KldOCFE0jjbp/STOrt7ZlFSbX79zPzZe/I6tlM16b//ZJI/n91jaOHVFPZ7ez/a12Nu05yE0/W5npL15Kq0y++3zSvRRyMwDybefL/v3XrNi0lxPGD+ey06dlztdJsfTFqWOHsb3tEF1d2alsZxw/NitTYsb4EVmVKD9q2khXd/4+jOF96MGlLRVf76P37hWb9rDoxWbubWxm0ZJmHvjMe3KCtjd3H6CuxjL3vfjxUKjMFU/9P27MsJKub5B7HH7o9Gl86PRpeSs58wUwbcGASGFWTtLAQ/GK4pc3tLJqSxuQvzI433kyc9xwlu0/fCxMHzOMjbsPZM23ektbZr9HPbFyS6bPXNhgEv0+8XtW0vYP0yjj2+Gfn/w9L76xMysVMbxn/fl/vsjeg4cD3+H1NSW1KkbF739Pr9qaDvTPnJE59uNdRsaPqM+57rV3Oa9tTd4+0UlhxVh4v169pY1/eXI1kFuhnkqlsO5uMOO7v3w9k3K9ZP2uksehAFi2cXfJ2yM1dERJCz0SP9lwVGxrO8TSDa2Vp6DlyV8uN+2iWC1lT1M38v1mR3R9C/0+UjwYjLd+1KQM9+yLa9LFJRqEFsrZLkW+G8mcySOpq7FMn76wtjl+s472WwhPonw33aTWyXgBNOnHQJNa1J57bXtWZ/lnV2/LGsgDireixW8+e/Z35PRLTPr89s5utrcdojZlmc7OUR2d3azYtCfrYvPVn67MCRLLSQNYuqGVq763OGsZ63fuz/ncpEJLqZUWSS0EACdOPIYL3j6Rpc2t7Np3uOY0erPO1+cy2pE7Kv483oqaVDAuZPWWtpyR3Tq6nM8/9Ap/cc4JmeMDcrcbpNNBo+tSyW8OhjegsHBSKKU9qZ9AeO6FBYx8Nc3x43biyCFs2nMw8Ub5w8UbuPGSk7NqVfPVAMf7osSFrfultmZKrnwDPH3o9Gk82LQxc72dOHJIwXtZORktAN3d6UISFM4GiFcmLl63k9Vb2hIrFfNVEg2pTSVWiOX72YlobT5Ay+6DTBxZjyf8Dli0Rd9It8rc/uzarIrPfPf5pBauuceNzhvkRrfx1366kmUt6cL8mu37+JcnV1Nfk742nDdnIr9YvS0zwNFtV56W2Noe72s5bsThii8jfc1LOqei/QXDeUiYr5B4n8P62hQnRILOrm74xuOreOC692S+ezQrxyCxf1m+Mld0wIt4BdiNl5zMq5v38uL6XZw5c1xiS1rScRi2CCeVscL5r793KVv2Hsos55FlbzJj/IicACo68FD8R9jj96akyuB86fDxltCNuw+wYO5kZk8amZlv8bqdWZVnoXnTx2R9tzNnjuP5yD01Kc0yX1/hMPMmtHt/R1ZLVDQAvPHik7MyfP7q/Nk5nxMq1qixcdf+zAAnnZFAv1Cf3bjNsVFD84luv3yt+9ldEnJTrsu5d8Xvu8PrUuzP8326D+4r6bfNB2zQt3XvQT7ynd9y1ZkzclIOnlixmRfX7+Ltk9LpHl/76Up+v7WNM2eO428uOIlbn36NjuBC1tnlmRqcaCASzeudP2t83nSX+bMOj0plRlbaQrSWoRxJ/SOeWbWVU6fm1pTnq0mMthLV1BhXBIXIaOtETQo+9QcnsHLzXgwyLTmzJ43kk2fPzLSkFfrR3nIc7ruVvgmEousdTu/scj73wDKuPfdtWb+xE++3cLCjm2vuWcKVDdO57txZmVaV1v3tLGxspnV/e1agFv0P8OkfNOX08cuXxrl7fwf/8PByPnrWDObPGp+TYnPzY68W3TY3XnIyW/Ye5ImVWzgY3NwOxYYeDwvLcelUk9ybYBi8r3xzT6TfhNOZ0L75yMstme8Yv4jGA7Vo+leSpNGwwuUkHS9JgeBHz5pB8859LGramMnpN+DME8Zx56/X5QRVM8Yf7lcRLWiNH1GfVcBIGYyJtexFz8P4oEGnRQIwgCdWbOHU40bn3ZdJv98UWrvtrYIpq6HZkd/miaedJPXPC7ff+BH1mZvni2/s5LnXtjNhRD0d3U7jup2ZfiXRPkVXfW9xpoARthiH14wvPbyczXsPMiEoEG7Ze5Dbn12bqR3dsvsAG3cfYNqYoZnWkDd3H8wM5hQ/JMOh/uNDZofCgni8LwpkpxKF189Pnj2TF9btZMWmPQT1GWWl4VarUitW9sVSycLnZxw/lq/+6alZfZZ/FASBcLi/HJBTeI8OCLJmaxsrYwMxQPoeU6yfabS/9Zu7D/Bvz6zJ+9tmkL+SCPIfi9HPqK1JDg4BtrWl7wkGWCQFMTrgUE3KWBgJFqPrmDSic7w14r4Xm7P60kfTw+ZMHpl1nnZ15a5nGKymDL5+2Tsy1/HVW9oSB9KJlyWiFWipFJgZXQn7O+n6le96H4oej0nL6Ojs5vXtb2VNW7V5b+bx4nU7c/rHdXV7TiE5mqlF0K+z7UAHd//mDTq60tf+sKwUvXaGwczza3awsLE5q6tC/H54xXd/my4jBctKKmOFZbu9sfLdlr2HMt1m4tuvdX975nj8i/fMzLQ+LVmf3aMprAyOl23j6YoLG5tzApYwNXPamKGZ/fnm7gOZY6rL0+sydcxQdu5rP3zf6ezmrFnjGTeiPnNPWbZxN7c8tioTJIeBdSpleGQk1jOOH8v3PtHAwsZm/vnJ32f1zwtFA8ALT5nEubOP5ZU393DeSRMK3mej9+l/+tNTad3fnhltNxwxNRTtu5+vHJVkVyzovvCUSZw3ZyIrNu3JDNoH8OiyN9l/qJPJo4bmXPM27znIwsbmrGy6qPj5U0qGXrwyduXmvVnXvxMnjGDKmGHMnTKKL91eU1I8Z17CSD390ZAps33K1bcCMLQuuVNrkqTajuvOncVdwQUjn9pI4BSv/bzijheyht+trTHeG7RGxW8wN1/+joI36IWNzVn9mJJElxHWZkR/xyRewxQaWpfik2fPzKo5SLpRZn3vVLpV7Hcte7Le886po3n/3MmZA3jxup00rtuZOYnjtfaF+m7V1xhf/dNTWbFpD/e92JxTuXfZvOMK7tNi3yVl8I6p6VGP3tixj+Vv7sn7nd81bTRf/pO5BfsBQnpbnjB+RCYlIyq+j6M3wzmTR/Jn330hK+iF9DEYplm0HehITGHK58QJI9iwa3+mRjZszSwQrwHpwvOD16XTa+L758SJx/DWgQ62tB3K+/6w70t8xKmbfroy63iZOmYow+pqMn3v4PA2SmpNBDh2ZD072nL74I2or+Gvzj8xa8S8u3+9LmvZ+bxr2mh+8tk/AODaHzRlVR4cU1/DW+1dOe85ceIx/MU5J+QMDPRn3/0tCWWyslw277hMbWy0YiVkwB/MTo8El/R6McPqarho7iRGDKnNatW48JRJmVaCcs0cPzyr1fIPZx/L8pbd7D5wOLCYcEw9S770fv7h4eVZnxv9/M/80dtyamHHDK9j2ZcvBAoPvQ+9P3LwQBM/X6P9WeOFifP+5dmsfTZz/HCe+/vzc0bSGz2sjtb9HXmveaEagyvOnMGDTRsTsw7iUgZzJo1k896DvHPqaM6aNZ7GdTt5qbmVtw7lnnPxz/rbC+dkZZcsbGzmq4+uyPrs0cNq2XOgM+f9YcE2bEHvhpKP++gxBul73A9fWJ/VqhOuY7g90j9JkO6aEE0xu/Xp1/j1mh2Z6/P7Tp7EG9vfyrpunRn56RkoXKsPMHnUEGZPGsn4oJAeL2gn3e+TvmP8Xjh2eC2t+3O35bgR9Zw7+9isFiQg8RqcdP2ur0m3MUf3W/Scv+zff51p2QzVpODKyLaEoMwVBGWFhGWXK949g8dXbM4qLL9r2mhWb23LalWsC8oh+e4n4fFQqIwVla+s+f0X1he8rkV/YiA6Um280r9Yf/hQXY1lRnedMnoYG3blZp2EwvtyvA93WD6JX5PDcvHIIbWZ38J8fce+rBa/Utx8+TsSg/Dv/vL1rPt0sfIqpK+FdwQBaLn3zPAzPhe55tyw6OXE32vMJ34eh8KyZXhNCIPZ+DGer2/nDYte5rHlm7POn8vmHcfwIbU8uLSFDXf+NYe2rCk6xERVBH2QvngcU19DS4FgKUnKYNaEY1i77a3iM0POTwl88eHlWTV/xYwbUcf3PvHuxHS4SgqvkF1b+viKzZkRjeJqDKaPG56YalbIyZNHJgY3kP8kvGzecZnAb+mGVj59zxJ2JdT+lGLm+OGZIZGPtHfPHMt5cyYydng9/+/J3xdc5/qa5FTLcP/c8tiqzIADoXihOTR51BB27e+gM4gkil3YCpk5fjgTRw5JvPAkmTdtNA5ZgVqpalMwc/yIzHFrwIxxwwveWCC9ja549wxue+a1nEJUKQyyfp+vFO8/ZRLfC0aDveCbz2Wda0k36KhoIP9n3/lt4ucWWkaNpVPQkgpxYW1y0vYPCyND6mpoO5hbECvF5FFDsrZxofO5XGHfm+j3rk0Za2++JO+18cQJI3hj5/6cio9509IVSeF1LCwkF/L3F83pcbr5QPTxuxpzWryG1uUOZPblD8zl4ZdbMn2TIV2Au/GSk7n92bV88+ery77WDK1Lce7sCVmFsSOlPuEncRY2NvOlR5aXtN4nTjyGddvfotuLn+NJ4kHniV98LCfboiYFJ0SugaFwf5S6rvH7yZDaFIdKLWkmSAHnzD4WIz2sfQV1PAV97KwZjBxSW1IFZX1Nis7u7pztcOKEETz9ufMAOOkfHstbiRA9Dsotc0FuOWXKqCFsbTuUsz6FgooTJx7DNz70Thav28n/e3J1ReWRYXU1HOzo6lFZJgyQPv2DpqyW22JqgoHvCgWrHz1rBjdf/g7m3/x01j1j8qghfPzsmRVdL0oxbngdb7V35bTyjxxSm/XboaUYNbSWGy8+mZv/+9XEitxCDBgSaUTKN4BZIccMqUmszBo1tJZZx45gd9AyHC8H1temuOTUyVkNHGGw/aWHlyfes1OWzoB2YPM9N3Boc/Ggb8Cmd8bt3t+R2KRcTG1Nih1tpQeK8Z8SKPeXo3bty+7DtXRDa04udDH1tamcaW/uPlD0hKxJpfttlBv0vbbtLa47dxZ3/GpdzvLzfd4jyzaxfsc+Tpk6mgeXFk4TLCaennQkvdScHh2wvjaFFbm45btBTRo1NO/FIt+2ryTwyWf9zv1l7eNlLXsq/iH3zm6yCjsORQM+SI9KVUktXPRzygn4IHv0tfg5ZFb454lueXxVpgN2c57vV+hw6XI4lOd46fL8AXeY7tneVfk5sD3WWvtaiRVcpUjKjjhmSA2QHkgoSb6KreWb9vK7lj1lFYi+/5s3BmXQFx9cBNIDRdzx/OuZmvhDHd38w8PLM9vzmCE1TBk1NDMoT3RQj1JNHFnPB0+bxkNBX70jrb3LM/0CgbLvlRe8fSLfbw36/Hh5QV+YNh/t0z6sLkVbrEDX1Z18THd0dvOtp0ovJMfvJz0J+CDdhyxfKmxvuLexueT7RnuetIi9Bzsyg6CNH1HP5jz3wbCfNZCYSlxMfB9s3nso3dc/to0L7au3DnaweksbyzburjhoO9BRXhCSJN7KXUzYYliX0Gcv7me/28SoIbXU1GTfH2eMG57O6op8bKmVKGEg9cmzZ/L0qq2J50q8cj1Mpd1H+fe9vQc7Ky5bvDOojF68bic3Pvg71pTQCBOXL3th78HOnJbsqPbObp5elX1te2TZm4ndXEJZx2uJh0TVtPRVKhVctcq5+Y0ZVsuyr1wE5B/KvOBnAp+7aE6mg3ApHU2jhtWl+K8g5eShl1pY9GJzzvrHC7HxmpRyDa1LMX3MsIpOgoGoxsgMQFGumy9/B3c8/3rZwTVUVhstpZk3bTSPBC3k59zyTMEU6iQ1wYioo4fVFbxx9jdH+5iqTRk3XXoqKzftSUzv7G3rb/njI/4Z/U1Si1O5JhxTX3Ytel9JGaRSVnZKcphR0Lq/PTE1s5j62hR/8Z7CKZL5DK3L/3uBR1KY1lioG0N/c925s3hh3c6C2SZTxw5jy54DPU6rD9XXGDPGjyg5yyvUG9fTo3lNvu7cWYwcVpe3G0EpHvrL9/DDF9ZntUINqbG8FZlRk0cN4a/fdxIvvrGzrDTJ2hpj3PC6TF/bo2HU0BoOdnqPGil6YuSQmqxKpeH1Kfa3l7Yum/7zf3a0b12XO0R5zKAP+ioVBkFv7NxX8kEcdd25s1i5eW/eVMxiaoNO2IX6IUZNHFnP9rb2Hl1o/nD2sUe05rC/qLF0DW85tWkhA94+eSRrtuWO7FhMmB+/aElzr93YJNt1585ixvgR/OMjy3s93UmyTR45pGCf0N4yGIO+mTf+d1+vQsVK6ZfTm2prjPuvPTtrNMxSpSydmniwzIt5yuDaP5xVUbDYU0Y6lf2pV7cWvd/XBT9gnvTtjmZgEk1Tq1S562vA2OF1FXc7GSjCoG/s8Hr+7+Ov0naw/NbGc2cfy29f31lxRVOlx1JNcHwOBjUGw+qzU0PL2W6DLr3zaDvY0d2jVq/v/Wpdjwqd6XtQ6QvojdqSMN0l3hen2tSkrOKLm0PF/aXCEaJ8kFzk+kJfFMIGqx37jnzAN1gN5IyAo3376Ay6ZGzZW17LPqTXtdyAL3xfX11rHErub1koyeho7qaeBnxQ/vud3LTCatQbx2FPM1sq3beDJeCDdDeP7tjF8Uicg7mdw+SoiAZ8lfanOtp+s3ZH1Qd8kO4/0Bdf00n3kxhE1zmpYn2UITMofObcWX29CgPKL36/raKULRWQjo7qL1WIFFdotN7eomtaPzBQLnhKhxMR6XvxH2SWwjq7vaJWnfo6FZGk/zDSo7qKVEpHj4gMKgOlZV0kn3w/kC2965Nnz+zrVRDJcHo+qqsMbgr6RGRQUYO1DHRf++nKvl6FQUF9gEWkmijoExERGUDKHYVSREREQZ+IiIiIiEgV6zdBn5ktMLPVZrbWzG7s6/URERERERGpBv0i6DOzGuB24GLgFOAqMzulb9dKRERERERk4OsXQR9wJrDW3de5ezuwCLi0j9dJRERERERkwOsvQd9UYGPkeUswLYuZXWtmTWbWdNTWTEREREREZADrL0Ff0k9n5Yys7u53uHuDuzcchXUSEREREREZ8PpL0NcCTI88nwZs6qN1ERGRAWD9LX/c16vQJwbr9xYRkcqZe9//VLGZ1QKvAe8D3gSWAB9197y/QNvQ0OBNTcryFBERERGRwcnMlpaSBVl7NFamGHfvNLPPAk8CNcDdhQI+ERERERERKU2/CPoA3P0x4LG+Xg8REREREZFq0l/69ImIiIiIiMgRoKBPRERERESkivWLgVwqYWbbgQ19uArHAjv68POlNNpPA4P208Cg/TQwaD8NHNpXA4P208AwWPfT8e4+odhMAzbo62tm1qTfC+z/tJ8GBu2ngUH7aWDQfho4tK8GBu2ngUH7qTCld4qIiIiIiFQxBX0iIiIiIiJVTEFf5e7o6xWQkmg/DQzaTwOD9tPAoP00cGhfDQzaTwOD9lMB6tMnIiIiIiJSxdTSJyIiIiIiUsUU9CUws6Fm9qKZ/c7MVprZPwXTv29mb5jZsuBvXjDdzOw2M1trZq+Y2el9+w0GFzOrMbOXzexnwfMTzKzRzNaY2f1mVh9MHxI8Xxu8PrMv13uwSdhPOp/6ITNbb2bLg33SFEwbZ2ZPBefUU2Y2NpiufdVH8uynr5rZm5Fz6pLI/F8I9tNqM7uo79Z8cDGzMWb2oJn93sxWmdnZOp/6nzz7SedTP2JmcyL7YpmZ7TWzG3Q+lU5BX7JDwHvd/V3APGCBmc0PXvt7d58X/C0Lpl0MzA7+rgW+fdTXeHD7G2BV5Pk3gG+5+2ygFbgmmH4N0OruJwLfCuaToye+n0DnU391frBPwqGvbwSeCc6pZ4LnoH3V1+L7CdLXvvCcegzAzE4BrgTmAguA/zCzmj5Y38Ho34An3P3twLtIXwN1PvU/SfsJdD71G+6+OtwXwBnAfuBhdD6VTEFfAk97K3haF/wV6vx4KfCD4H2LgTFmNuVIr6eAmU0D/hi4M3huwHuBB4NZ7gEuCx5fGjwneP19wfxyhMX3UxE6n/qf6LkTP6e0r/q/S4FF7n7I3d8A1gJn9vE6VT0zGwWcC9wF4O7t7r4bnU/9SoH9lI/Op773PuB1d9+AzqeSKejLI0hFWwZsA55y98bgpf8TNBN/y8yGBNOmAhsjb28JpsmRdyvwv4Hu4Pl4YLe7dwbPo/sis5+C1/cE88uRF99PIZ1P/Y8DPzezpWZ2bTBtkrtvBgj+Twyma1/1naT9BPDZ4Jy6O0xzQvupr8wCtgP/aenU9jvNbAQ6n/qbfPsJdD71V1cC9wWPdT6VSEFfHu7eFTQhTwPONLNTgS8AbwfeDYwDPh/MntRapGFRjzAz+wCwzd2XRicnzOolvCZHSJ79BDqf+qtz3P100qkx15vZuQXm1b7qO0n76dvA20h3S9gMfDOYV/upb9QCpwPfdvfTgH0cTj1Lov3UN/LtJ51P/ZClx2n4U+BHxWZNmDao95OCviKCJv7ngAXuvjloJj4E/CeHm/NbgOmRt00DNh3VFR2czgH+1MzWA4tIp3XeSroJvzaYJ7ovMvspeH00sOtorvAglbOfzOy/dD71T+6+Kfi/jXR/iTOBrWFaTPB/WzC79lUfSdpP7r41qLDsBr6Hzqm+1gK0RDKFHiQdXOh86l8S95POp37rYuAld98aPNf5VCIFfQnMbIKZjQkeDwMuAH4fOaiMdM7wiuAtjwKfCEYKmg/sCZua5chx9y+4+zR3n0m6qf8X7v4x4Fngw8FsVwM/CR4/GjwneP0Xrh+qPOLy7Kf/ofOp/zGzEWY2MnwMXEh6v0TPnfg5pX11lOXbT7H+KpeTfU5daekRjE8gPbDBi0dznQcjd98CbDSzOcGk9wGvovOpX8m3n3Q+9VtXcTi1E3Q+lay2+CyD0hTgnmA0phTwgLv/zMx+YWYTSDcZLwOuC+Z/DLiEdGfe/cCf98E6y2GfBxaZ2deBlwk6Zwf/f2hma0m38F3ZR+snaffqfOp3JgEPB+Mb1QIL3f0JM1sCPGBm1wDNwEeC+bWv+ka+/fRDS//0iQPrgc8AuPtKM3uAdMDRCVzv7l19suaDz/8kfa2rB9aRPkdS6Hzqb5L20206n/oXMxsOvJ9gXwRuQedTSUwNHSIiIiIiItVL6Sq2IEMAAAHFSURBVJ0iIiIiIiJVTEGfiIiIiIhIFVPQJyIiIiIiUsUU9ImIiIiIiFQxBX0iIiIiIiJVTEGfiIiIiIhIFVPQJyIiAphZl5ktM7OVZvY7M/tbM0uZ2UXB9GVm9paZrQ4e/yDPcs4zsz1m9nIw7/Nm9oGj/X1ERERC+nF2ERGRtAPuPg/AzCYCC4HR7v4V4Mlg+nPA37l7U5Fl/crdPxC8Zx7wiJkdcPdnjtjai4iI5KGWPhERkRh33wZcC3zWzKyHy1oG3AR8tjfWTUREpFwK+kRERBK4+zrS98mJvbC4l4C398JyREREyqagT0REJL8etfIdgeWIiIiUTUGfiIhIAjObBXQB23phcacBq3phOSIiImXTQC4iIiIxZjYB+A7w7+7uPVzWO4F/BD7VG+smIiJSLgV9IiIiacPMbBlQB3QCPwT+tcJl/aGZvQwMJ91S+NcauVNERPqK9bACU0RERERERPox9ekTERERERGpYkrvFBERqYCZXQR8Izb5DXe/vC/WR0REJB+ld4qIiIiIiFQxpXeKiIiIiIhUMQV9IiIiIiIiVUxBn4iIiIiISBVT0CciIiIiIlLFFPSJiIiIiIhUsf8PSsDjm9iMSywAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1080x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "########################### TransactionAmt\n",
    "i_cols = ['TransactionAmt']\n",
    "periods = ['DT_D']\n",
    "\n",
    "temp_df = pd.concat([train_df[['TransactionDT']+i_cols+periods], test_df[['TransactionDT']+i_cols+periods]])\n",
    "for period in periods:\n",
    "    for col in i_cols:\n",
    "        for df in [temp_df]:\n",
    "            df.set_index(period)[col].plot(style='.', title=col, figsize=(15, 3))\n",
    "            plt.show()\n",
    "\n",
    "# Clip Values\n",
    "train_df['TransactionAmt'] = train_df['TransactionAmt'].clip(0,5000)\n",
    "test_df['TransactionAmt']  = test_df['TransactionAmt'].clip(0,5000)\n",
    "\n",
    "# Check if the Transaction Amount is common or not (we can use freq encoding here)\n",
    "# In our dialog with a model we are telling to trust or not to these values   \n",
    "train_df['TransactionAmt_check'] = np.where(train_df['TransactionAmt'].isin(test_df['TransactionAmt']), 1, 0)\n",
    "test_df['TransactionAmt_check']  = np.where(test_df['TransactionAmt'].isin(train_df['TransactionAmt']), 1, 0)\n",
    "\n",
    "# For our model current TransactionAmt is a noise\n",
    "# https://www.kaggle.com/kyakovlev/ieee-check-noise\n",
    "# (even if features importances are telling contrariwise)\n",
    "# There are many unique values and model doesn't generalize well\n",
    "# Lets do some aggregations\n",
    "i_cols = ['TransactionAmt']\n",
    "uids = ['card1','card2','card3','card5','uid','uid2','uid3','uid4','uid5','bank_type']\n",
    "aggregations = ['mean','std']\n",
    "\n",
    "# uIDs aggregations\n",
    "train_df, test_df = uid_aggregation(train_df, test_df, i_cols, uids, aggregations)\n",
    " \n",
    "# TransactionAmt Normalization\n",
    "periods = ['DT_D','DT_W','DT_M']\n",
    "for df in [train_df, test_df]:\n",
    "    df = values_normalization(df, periods, i_cols)\n",
    "\n",
    "# Product type\n",
    "train_df['product_type'] = train_df['ProductCD'].astype(str)+'_'+train_df['TransactionAmt'].astype(str)\n",
    "test_df['product_type'] = test_df['ProductCD'].astype(str)+'_'+test_df['TransactionAmt'].astype(str)\n",
    "\n",
    "i_cols = ['product_type']\n",
    "periods = ['DT_D','DT_W','DT_M']\n",
    "train_df, test_df = timeblock_frequency_encoding(train_df, test_df, periods, i_cols, \n",
    "                                                 with_proportions=False, only_proportions=True)\n",
    "train_df, test_df = frequency_encoding(train_df, test_df, i_cols, self_encoding=True)\n",
    "\n",
    "# Small \"hack\" to transform distribution \n",
    "# (doesn't affect auc much, but I like it more)\n",
    "# please see how distribution transformation can boost your score \n",
    "# (not our case but related)\n",
    "# https://scikit-learn.org/stable/auto_examples/compose/plot_transformed_target.html\n",
    "train_df['TransactionAmt'] = np.log1p(train_df['TransactionAmt'])\n",
    "test_df['TransactionAmt'] = np.log1p(test_df['TransactionAmt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "711\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.955716\tvalid_1's auc: 0.899667\n",
      "[200]\ttraining's auc: 0.975678\tvalid_1's auc: 0.912911\n",
      "[300]\ttraining's auc: 0.98774\tvalid_1's auc: 0.921018\n",
      "[400]\ttraining's auc: 0.994089\tvalid_1's auc: 0.926342\n",
      "[500]\ttraining's auc: 0.997333\tvalid_1's auc: 0.929194\n",
      "[600]\ttraining's auc: 0.99885\tvalid_1's auc: 0.930784\n",
      "[700]\ttraining's auc: 0.999534\tvalid_1's auc: 0.931761\n",
      "[800]\ttraining's auc: 0.999824\tvalid_1's auc: 0.932743\n",
      "[900]\ttraining's auc: 0.999937\tvalid_1's auc: 0.933045\n",
      "[1000]\ttraining's auc: 0.999982\tvalid_1's auc: 0.933355\n",
      "[1100]\ttraining's auc: 0.999996\tvalid_1's auc: 0.933685\n",
      "[1200]\ttraining's auc: 0.999999\tvalid_1's auc: 0.934018\n",
      "[1300]\ttraining's auc: 1\tvalid_1's auc: 0.93405\n",
      "[1400]\ttraining's auc: 1\tvalid_1's auc: 0.934111\n",
      "Early stopping, best iteration is:\n",
      "[1379]\ttraining's auc: 1\tvalid_1's auc: 0.93416\n"
     ]
    }
   ],
   "source": [
    "features = [x for x in train_df.columns if x not in remove_features and train_df[x].dtype != 'object'\n",
    "           ]\n",
    "print(len(features))\n",
    "_, model = local_valid(train_df, 'isFraud', features, lgb_params, return_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### C Columns\n",
    "i_cols = ['C'+str(i) for i in range(1,15)]\n",
    "\n",
    "####### Global Self frequency encoding\n",
    "# self_encoding=False because \n",
    "# I want to keep original values\n",
    "train_df, test_df = frequency_encoding(train_df, test_df, i_cols, self_encoding=False)\n",
    "\n",
    "####### Clip max values\n",
    "for df in [train_df, test_df]:\n",
    "    for col in i_cols:\n",
    "        max_value = train_df[train_df['DT_M']==train_df['DT_M'].max()][col].max()\n",
    "        df[col] = df[col].clip(None,max_value) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "725\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.955197\tvalid_1's auc: 0.898273\n",
      "[200]\ttraining's auc: 0.975762\tvalid_1's auc: 0.911662\n",
      "[300]\ttraining's auc: 0.987743\tvalid_1's auc: 0.920209\n",
      "[400]\ttraining's auc: 0.994201\tvalid_1's auc: 0.925473\n",
      "[500]\ttraining's auc: 0.997404\tvalid_1's auc: 0.928602\n",
      "[600]\ttraining's auc: 0.998903\tvalid_1's auc: 0.930172\n",
      "[700]\ttraining's auc: 0.999554\tvalid_1's auc: 0.930981\n",
      "[800]\ttraining's auc: 0.999826\tvalid_1's auc: 0.931772\n",
      "[900]\ttraining's auc: 0.999941\tvalid_1's auc: 0.932091\n",
      "[1000]\ttraining's auc: 0.999983\tvalid_1's auc: 0.932456\n",
      "[1100]\ttraining's auc: 0.999996\tvalid_1's auc: 0.932778\n",
      "[1200]\ttraining's auc: 0.999999\tvalid_1's auc: 0.933088\n",
      "[1300]\ttraining's auc: 1\tvalid_1's auc: 0.933147\n",
      "Early stopping, best iteration is:\n",
      "[1281]\ttraining's auc: 1\tvalid_1's auc: 0.933222\n"
     ]
    }
   ],
   "source": [
    "features = [x for x in train_df.columns if x not in remove_features and train_df[x].dtype != 'object'\n",
    "           ]\n",
    "print(len(features))\n",
    "_, model = local_valid(train_df, 'isFraud', features, lgb_params, return_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [train_identity, test_identity]:\n",
    "    ########################### Device info\n",
    "    df['DeviceInfo'] = df['DeviceInfo'].fillna('unknown_device').str.lower()\n",
    "    df['DeviceInfo_device'] = df['DeviceInfo'].apply(lambda x: ''.join([i for i in x if i.isalpha()]))\n",
    "    df['DeviceInfo_version'] = df['DeviceInfo'].apply(lambda x: ''.join([i for i in x if i.isnumeric()]))\n",
    "    \n",
    "    ########################### Device info 2\n",
    "    df['id_30'] = df['id_30'].fillna('unknown_device').str.lower()\n",
    "    df['id_30_device'] = df['id_30'].apply(lambda x: ''.join([i for i in x if i.isalpha()]))\n",
    "    df['id_30_version'] = df['id_30'].apply(lambda x: ''.join([i for i in x if i.isnumeric()]))\n",
    "    \n",
    "    ########################### Browser\n",
    "    df['id_31'] = df['id_31'].fillna('unknown_device').str.lower()\n",
    "    df['id_31_device'] = df['id_31'].apply(lambda x: ''.join([i for i in x if i.isalpha()]))\n",
    "    \n",
    "########################### Merge Identity columns\n",
    "temp_df = train_df[['TransactionID']]\n",
    "temp_df = temp_df.merge(train_identity, on=['TransactionID'], how='left')\n",
    "del temp_df['TransactionID']\n",
    "train_df = pd.concat([train_df,temp_df], axis=1)\n",
    "    \n",
    "temp_df = test_df[['TransactionID']]\n",
    "temp_df = temp_df.merge(test_identity, on=['TransactionID'], how='left')\n",
    "del temp_df['TransactionID']\n",
    "test_df = pd.concat([test_df,temp_df], axis=1)\n",
    "\n",
    "i_cols = [\n",
    "          'DeviceInfo','DeviceInfo_device','DeviceInfo_version',\n",
    "          'id_30','id_30_device','id_30_version',\n",
    "          'id_31','id_31_device',\n",
    "          'id_33',\n",
    "         ]\n",
    "\n",
    "####### Global Self frequency encoding\n",
    "# self_encoding=True because \n",
    "# we don't need original values anymore\n",
    "train_df, test_df = frequency_encoding(train_df, test_df, i_cols, self_encoding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "771\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.955814\tvalid_1's auc: 0.897945\n",
      "[200]\ttraining's auc: 0.97629\tvalid_1's auc: 0.91215\n",
      "[300]\ttraining's auc: 0.98843\tvalid_1's auc: 0.921438\n",
      "[400]\ttraining's auc: 0.994614\tvalid_1's auc: 0.926923\n",
      "[500]\ttraining's auc: 0.997634\tvalid_1's auc: 0.929625\n",
      "[600]\ttraining's auc: 0.999047\tvalid_1's auc: 0.931583\n",
      "[700]\ttraining's auc: 0.999636\tvalid_1's auc: 0.932707\n",
      "[800]\ttraining's auc: 0.999872\tvalid_1's auc: 0.933307\n",
      "[900]\ttraining's auc: 0.999961\tvalid_1's auc: 0.934055\n",
      "[1000]\ttraining's auc: 0.999991\tvalid_1's auc: 0.934505\n",
      "[1100]\ttraining's auc: 0.999999\tvalid_1's auc: 0.934926\n",
      "[1200]\ttraining's auc: 1\tvalid_1's auc: 0.935066\n",
      "[1300]\ttraining's auc: 1\tvalid_1's auc: 0.935246\n",
      "[1400]\ttraining's auc: 1\tvalid_1's auc: 0.935233\n",
      "Early stopping, best iteration is:\n",
      "[1349]\ttraining's auc: 1\tvalid_1's auc: 0.935315\n"
     ]
    }
   ],
   "source": [
    "features = [x for x in train_df.columns if x not in remove_features and train_df[x].dtype != 'object'\n",
    "           ]\n",
    "print(len(features))\n",
    "_, model = local_valid(train_df, 'isFraud', features, lgb_params, return_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### ProductCD and M4 Target mean\n",
    "# As we already have frequency encoded columns\n",
    "# We can have different global transformation on them\n",
    "# Target mean?\n",
    "# We will transform original values as we don't need them\n",
    "# Leakage over folds?\n",
    "# Yes, we will have some,\n",
    "# But in the same time we already have leakage from \n",
    "# V columns and card1->card6 columns\n",
    "# So, no much harm here\n",
    "for col in ['ProductCD','M4']:\n",
    "    temp_dict = train_df.groupby([col])[TARGET].agg(['mean']).reset_index().rename(\n",
    "                                                        columns={'mean': col+'_target_mean'})\n",
    "    temp_dict.index = temp_dict[col].values\n",
    "    temp_dict = temp_dict[col+'_target_mean'].to_dict()\n",
    "\n",
    "    train_df[col] = train_df[col].map(temp_dict)\n",
    "    test_df[col]  = test_df[col].map(temp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P_emaildomain\n",
      "R_emaildomain\n",
      "uid\n",
      "uid2\n",
      "uid3\n",
      "uid4\n",
      "uid5\n",
      "bank_type\n",
      "DeviceType\n"
     ]
    }
   ],
   "source": [
    "########################### Encode Str columns\n",
    "# For all such columns (probably not)\n",
    "# we already did frequency encoding (numeric feature)\n",
    "# so we will use astype('category') here\n",
    "for col in list(train_df):\n",
    "    if train_df[col].dtype=='O':\n",
    "        print(col)\n",
    "        train_df[col] = train_df[col].fillna('unseen_before_label')\n",
    "        test_df[col]  = test_df[col].fillna('unseen_before_label')\n",
    "        \n",
    "        train_df[col] = train_df[col].astype(str)\n",
    "        test_df[col] = test_df[col].astype(str)\n",
    "        \n",
    "        le = LabelEncoder()\n",
    "        le.fit(list(train_df[col])+list(test_df[col]))\n",
    "        train_df[col] = le.transform(train_df[col])\n",
    "        test_df[col]  = le.transform(test_df[col])\n",
    "        \n",
    "        train_df[col] = train_df[col].astype('category')\n",
    "        test_df[col] = test_df[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "774\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.956621\tvalid_1's auc: 0.899567\n",
      "[200]\ttraining's auc: 0.977357\tvalid_1's auc: 0.914579\n",
      "[300]\ttraining's auc: 0.988985\tvalid_1's auc: 0.92339\n",
      "[400]\ttraining's auc: 0.994901\tvalid_1's auc: 0.928576\n",
      "[500]\ttraining's auc: 0.997778\tvalid_1's auc: 0.931536\n",
      "[600]\ttraining's auc: 0.999096\tvalid_1's auc: 0.933239\n",
      "[700]\ttraining's auc: 0.99966\tvalid_1's auc: 0.934239\n",
      "[800]\ttraining's auc: 0.99988\tvalid_1's auc: 0.934991\n",
      "[900]\ttraining's auc: 0.999963\tvalid_1's auc: 0.935396\n",
      "[1000]\ttraining's auc: 0.999991\tvalid_1's auc: 0.93578\n",
      "[1100]\ttraining's auc: 0.999999\tvalid_1's auc: 0.936011\n",
      "[1200]\ttraining's auc: 1\tvalid_1's auc: 0.936337\n",
      "[1300]\ttraining's auc: 1\tvalid_1's auc: 0.936624\n",
      "[1400]\ttraining's auc: 1\tvalid_1's auc: 0.936499\n",
      "Early stopping, best iteration is:\n",
      "[1303]\ttraining's auc: 1\tvalid_1's auc: 0.936641\n"
     ]
    }
   ],
   "source": [
    "features = [x for x in train_df.columns if x not in remove_features and train_df[x].dtype != 'object'\n",
    "           ]\n",
    "print(len(features))\n",
    "_, model = local_valid(train_df, 'isFraud', features, lgb_params, return_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base score 0.93671\n",
      "column: uid_D1_mean - 0.93672\n",
      "column: uid_D1_std - 0.93671\n",
      "column: uid2_D1_mean - 0.9367\n",
      "column: uid2_D1_std - 0.9367\n",
      "column: uid3_D1_mean - 0.93676\n",
      "column: uid3_D1_std - 0.93678\n",
      "column: uid4_D1_mean - 0.93671\n",
      "column: uid4_D1_std - 0.93666\n",
      "column: uid5_D1_mean - 0.93675\n",
      "column: uid5_D1_std - 0.93674\n",
      "column: bank_type_D1_mean - 0.93673\n",
      "column: bank_type_D1_std - 0.93673\n",
      "column: uid_D2_mean - 0.93669\n",
      "column: uid_D2_std - 0.93668\n",
      "column: uid2_D2_mean - 0.9367\n",
      "column: uid2_D2_std - 0.93656\n",
      "column: uid3_D2_mean - 0.93679\n",
      "column: uid3_D2_std - 0.93662\n",
      "column: uid4_D2_mean - 0.93643\n",
      "column: uid4_D2_std - 0.93657\n",
      "column: uid5_D2_mean - 0.93658\n",
      "column: uid5_D2_std - 0.93657\n",
      "column: bank_type_D2_mean - 0.93671\n",
      "column: bank_type_D2_std - 0.93677\n",
      "column: uid_D3_mean - 0.93673\n",
      "column: uid_D3_std - 0.93661\n",
      "column: uid2_D3_mean - 0.93673\n",
      "column: uid2_D3_std - 0.93652\n",
      "column: uid3_D3_mean - 0.93671\n",
      "column: uid3_D3_std - 0.93671\n",
      "column: uid4_D3_mean - 0.93643\n",
      "column: uid4_D3_std - 0.93674\n",
      "column: uid5_D3_mean - 0.93664\n",
      "column: uid5_D3_std - 0.93661\n",
      "column: bank_type_D3_mean - 0.93677\n",
      "column: bank_type_D3_std - 0.93674\n",
      "column: uid_D4_mean - 0.93665\n",
      "column: uid_D4_std - 0.9366\n",
      "column: uid2_D4_mean - 0.93665\n",
      "column: uid2_D4_std - 0.93671\n",
      "column: uid3_D4_mean - 0.9367\n",
      "column: uid3_D4_std - 0.93657\n",
      "column: uid4_D4_mean - 0.93657\n",
      "column: uid4_D4_std - 0.93669\n",
      "column: uid5_D4_mean - 0.93668\n",
      "column: uid5_D4_std - 0.93661\n",
      "column: bank_type_D4_mean - 0.93673\n",
      "column: bank_type_D4_std - 0.93673\n",
      "column: uid_D5_mean - 0.93665\n",
      "column: uid_D5_std - 0.93656\n",
      "column: uid2_D5_mean - 0.93672\n",
      "column: uid2_D5_std - 0.93666\n",
      "column: uid3_D5_mean - 0.93672\n",
      "column: uid3_D5_std - 0.93638\n",
      "column: uid4_D5_mean - 0.9368\n",
      "column: uid4_D5_std - 0.93677\n",
      "column: uid5_D5_mean - 0.93682\n",
      "column: uid5_D5_std - 0.93658\n",
      "column: bank_type_D5_mean - 0.9367\n",
      "column: bank_type_D5_std - 0.93672\n",
      "column: uid_D6_mean - 0.93649\n",
      "column: uid_D6_std - 0.93665\n",
      "column: uid2_D6_mean - 0.93661\n",
      "column: uid2_D6_std - 0.93665\n",
      "column: uid3_D6_mean - 0.93647\n",
      "column: uid3_D6_std - 0.93668\n",
      "column: uid4_D6_mean - 0.93671\n",
      "column: uid4_D6_std - 0.93664\n",
      "column: uid5_D6_mean - 0.93674\n",
      "column: uid5_D6_std - 0.93672\n",
      "column: bank_type_D6_mean - 0.93673\n",
      "column: bank_type_D6_std - 0.93674\n",
      "column: uid_D7_mean - 0.93668\n",
      "column: uid_D7_std - 0.93661\n",
      "column: uid2_D7_mean - 0.93673\n",
      "column: uid2_D7_std - 0.93669\n",
      "column: uid3_D7_mean - 0.9367\n",
      "column: uid3_D7_std - 0.9366\n",
      "column: uid4_D7_mean - 0.93664\n",
      "column: uid4_D7_std - 0.93673\n",
      "column: uid5_D7_mean - 0.93667\n",
      "column: uid5_D7_std - 0.9367\n",
      "column: bank_type_D7_mean - 0.93676\n",
      "column: bank_type_D7_std - 0.93672\n",
      "column: uid_D8_mean - 0.93675\n",
      "column: uid_D8_std - 0.93665\n",
      "column: uid2_D8_mean - 0.93669\n",
      "column: uid2_D8_std - 0.93671\n",
      "column: uid3_D8_mean - 0.93647\n",
      "column: uid3_D8_std - 0.93666\n",
      "column: uid4_D8_mean - 0.93661\n",
      "column: uid4_D8_std - 0.93671\n",
      "column: uid5_D8_mean - 0.93679\n",
      "column: uid5_D8_std - 0.93657\n",
      "column: bank_type_D8_mean - 0.93666\n",
      "column: bank_type_D8_std - 0.93671\n",
      "column: uid_D9_mean - 0.93658\n",
      "column: uid_D9_std - 0.93662\n",
      "column: uid2_D9_mean - 0.93669\n",
      "column: uid2_D9_std - 0.9367\n",
      "column: uid3_D9_mean - 0.93658\n",
      "column: uid3_D9_std - 0.93681\n",
      "column: uid4_D9_mean - 0.93654\n",
      "column: uid4_D9_std - 0.93662\n",
      "column: uid5_D9_mean - 0.93661\n",
      "column: uid5_D9_std - 0.93664\n",
      "column: bank_type_D9_mean - 0.93672\n",
      "column: bank_type_D9_std - 0.93669\n",
      "column: uid_D10_mean - 0.93668\n",
      "column: uid_D10_std - 0.93667\n",
      "column: uid2_D10_mean - 0.93672\n",
      "column: uid2_D10_std - 0.93669\n",
      "column: uid3_D10_mean - 0.93673\n",
      "column: uid3_D10_std - 0.9367\n",
      "column: uid4_D10_mean - 0.93665\n",
      "column: uid4_D10_std - 0.93661\n",
      "column: uid5_D10_mean - 0.93659\n",
      "column: uid5_D10_std - 0.93667\n",
      "column: bank_type_D10_mean - 0.93677\n",
      "column: bank_type_D10_std - 0.93671\n",
      "column: uid_D11_mean - 0.93671\n",
      "column: uid_D11_std - 0.93665\n",
      "column: uid2_D11_mean - 0.93667\n",
      "column: uid2_D11_std - 0.93676\n",
      "column: uid3_D11_mean - 0.93658\n",
      "column: uid3_D11_std - 0.93667\n",
      "column: uid4_D11_mean - 0.93652\n",
      "column: uid4_D11_std - 0.9366\n",
      "column: uid5_D11_mean - 0.93675\n",
      "column: uid5_D11_std - 0.93678\n",
      "column: bank_type_D11_mean - 0.9367\n",
      "column: bank_type_D11_std - 0.93668\n",
      "column: uid_D12_mean - 0.93668\n",
      "column: uid_D12_std - 0.93671\n",
      "column: uid2_D12_mean - 0.9367\n",
      "column: uid2_D12_std - 0.93667\n",
      "column: uid3_D12_mean - 0.93676\n",
      "column: uid3_D12_std - 0.93675\n",
      "column: uid4_D12_mean - 0.93672\n",
      "column: uid4_D12_std - 0.93672\n",
      "column: uid5_D12_mean - 0.93672\n",
      "column: uid5_D12_std - 0.93673\n",
      "column: bank_type_D12_mean - 0.9368\n",
      "column: bank_type_D12_std - 0.93672\n",
      "column: uid_D13_mean - 0.93662\n",
      "column: uid_D13_std - 0.93668\n",
      "column: uid2_D13_mean - 0.93673\n",
      "column: uid2_D13_std - 0.93664\n",
      "column: uid3_D13_mean - 0.93672\n",
      "column: uid3_D13_std - 0.93673\n",
      "column: uid4_D13_mean - 0.93669\n",
      "column: uid4_D13_std - 0.93668\n",
      "column: uid5_D13_mean - 0.93667\n",
      "column: uid5_D13_std - 0.93671\n",
      "column: bank_type_D13_mean - 0.93677\n",
      "column: bank_type_D13_std - 0.93673\n",
      "column: uid_D14_mean - 0.93672\n",
      "column: uid_D14_std - 0.9366\n",
      "column: uid2_D14_mean - 0.93679\n",
      "column: uid2_D14_std - 0.9367\n",
      "column: uid3_D14_mean - 0.93665\n",
      "column: uid3_D14_std - 0.93658\n",
      "column: uid4_D14_mean - 0.93674\n",
      "column: uid4_D14_std - 0.93669\n",
      "column: uid5_D14_mean - 0.93666\n",
      "column: uid5_D14_std - 0.93667\n",
      "column: bank_type_D14_mean - 0.9367\n",
      "column: bank_type_D14_std - 0.93673\n",
      "column: uid_D15_mean - 0.9367\n",
      "column: uid_D15_std - 0.93664\n",
      "column: uid2_D15_mean - 0.93667\n",
      "column: uid2_D15_std - 0.93668\n",
      "column: uid3_D15_mean - 0.93667\n",
      "column: uid3_D15_std - 0.93674\n",
      "column: uid4_D15_mean - 0.93659\n",
      "column: uid4_D15_std - 0.93662\n",
      "column: uid5_D15_mean - 0.9367\n",
      "column: uid5_D15_std - 0.93664\n",
      "column: bank_type_D15_mean - 0.93671\n",
      "column: bank_type_D15_std - 0.93673\n",
      "column: D9_not_na - 0.93671\n",
      "column: D8_not_same_day - 0.93671\n",
      "column: D8_D9_decimal_dist - 0.93669\n",
      "column: D3_DT_D_min_max - 0.93674\n",
      "column: D3_DT_D_std_score - 0.93659\n",
      "column: D4_DT_D_min_max - 0.93656\n",
      "column: D4_DT_D_std_score - 0.93646\n",
      "column: D5_DT_D_min_max - 0.93669\n",
      "column: D5_DT_D_std_score - 0.93669\n",
      "column: D6_DT_D_min_max - 0.93668\n",
      "column: D6_DT_D_std_score - 0.93671\n",
      "column: D7_DT_D_min_max - 0.93671\n",
      "column: D7_DT_D_std_score - 0.93672\n",
      "column: D8_DT_D_min_max - 0.93669\n",
      "column: D8_DT_D_std_score - 0.93665\n",
      "column: D10_DT_D_min_max - 0.9366\n",
      "column: D10_DT_D_std_score - 0.93659\n",
      "column: D11_DT_D_min_max - 0.93664\n",
      "column: D11_DT_D_std_score - 0.93662\n",
      "column: D12_DT_D_min_max - 0.9367\n",
      "column: D12_DT_D_std_score - 0.93673\n",
      "column: D13_DT_D_min_max - 0.93673\n",
      "column: D13_DT_D_std_score - 0.93675\n",
      "column: D14_DT_D_min_max - 0.93666\n",
      "column: D14_DT_D_std_score - 0.93676\n",
      "column: D15_DT_D_min_max - 0.93647\n",
      "column: D15_DT_D_std_score - 0.93648\n",
      "column: D3_DT_W_min_max - 0.93669\n",
      "column: D3_DT_W_std_score - 0.93668\n",
      "column: D4_DT_W_min_max - 0.93665\n",
      "column: D4_DT_W_std_score - 0.93651\n",
      "column: D5_DT_W_min_max - 0.93668\n",
      "column: D5_DT_W_std_score - 0.93664\n",
      "column: D6_DT_W_min_max - 0.93671\n",
      "column: D6_DT_W_std_score - 0.93668\n",
      "column: D7_DT_W_min_max - 0.93671\n",
      "column: D7_DT_W_std_score - 0.93672\n",
      "column: D8_DT_W_min_max - 0.93671\n",
      "column: D8_DT_W_std_score - 0.93664\n",
      "column: D10_DT_W_min_max - 0.93666\n",
      "column: D10_DT_W_std_score - 0.93659\n",
      "column: D11_DT_W_min_max - 0.93666\n",
      "column: D11_DT_W_std_score - 0.93671\n",
      "column: D12_DT_W_min_max - 0.93671\n",
      "column: D12_DT_W_std_score - 0.93674\n",
      "column: D13_DT_W_min_max - 0.93669\n",
      "column: D13_DT_W_std_score - 0.93665\n",
      "column: D14_DT_W_min_max - 0.93672\n",
      "column: D14_DT_W_std_score - 0.93669\n",
      "column: D15_DT_W_min_max - 0.93652\n",
      "column: D15_DT_W_std_score - 0.93638\n",
      "column: D3_DT_M_min_max - 0.9366\n",
      "column: D3_DT_M_std_score - 0.9367\n",
      "column: D4_DT_M_min_max - 0.93667\n",
      "column: D4_DT_M_std_score - 0.93659\n",
      "column: D5_DT_M_min_max - 0.93668\n",
      "column: D5_DT_M_std_score - 0.93673\n",
      "column: D6_DT_M_min_max - 0.93672\n",
      "column: D6_DT_M_std_score - 0.93668\n",
      "column: D7_DT_M_min_max - 0.93671\n",
      "column: D7_DT_M_std_score - 0.93672\n",
      "column: D8_DT_M_min_max - 0.93672\n",
      "column: D8_DT_M_std_score - 0.9367\n",
      "column: D10_DT_M_min_max - 0.93665\n",
      "column: D10_DT_M_std_score - 0.93663\n",
      "column: D11_DT_M_min_max - 0.93669\n",
      "column: D11_DT_M_std_score - 0.93667\n",
      "column: D12_DT_M_min_max - 0.93671\n",
      "column: D12_DT_M_std_score - 0.93672\n",
      "column: D13_DT_M_min_max - 0.93672\n",
      "column: D13_DT_M_std_score - 0.93674\n",
      "column: D14_DT_M_min_max - 0.93669\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column: D14_DT_M_std_score - 0.9367\n",
      "column: D15_DT_M_min_max - 0.93655\n",
      "column: D15_DT_M_std_score - 0.93653\n",
      "column: D1_scaled - 0.93595\n",
      "column: D2_scaled - 0.93459\n",
      "column: TransactionAmt_check - 0.93671\n",
      "column: card1_TransactionAmt_mean - 0.93663\n",
      "column: card1_TransactionAmt_std - 0.9367\n",
      "column: card2_TransactionAmt_mean - 0.93651\n",
      "column: card2_TransactionAmt_std - 0.93667\n",
      "column: card3_TransactionAmt_mean - 0.93675\n",
      "column: card3_TransactionAmt_std - 0.93672\n",
      "column: card5_TransactionAmt_mean - 0.93662\n",
      "column: card5_TransactionAmt_std - 0.93669\n",
      "column: uid_TransactionAmt_mean - 0.93673\n",
      "column: uid_TransactionAmt_std - 0.93669\n",
      "column: uid2_TransactionAmt_mean - 0.93653\n",
      "column: uid2_TransactionAmt_std - 0.9367\n",
      "column: uid3_TransactionAmt_mean - 0.93654\n",
      "column: uid3_TransactionAmt_std - 0.93668\n",
      "column: uid4_TransactionAmt_mean - 0.93667\n",
      "column: uid4_TransactionAmt_std - 0.93671\n",
      "column: uid5_TransactionAmt_mean - 0.93663\n",
      "column: uid5_TransactionAmt_std - 0.93664\n",
      "column: bank_type_TransactionAmt_mean - 0.93671\n",
      "column: bank_type_TransactionAmt_std - 0.93675\n",
      "column: TransactionAmt_DT_D_min_max - 0.93638\n",
      "column: TransactionAmt_DT_D_std_score - 0.93654\n",
      "column: TransactionAmt_DT_W_min_max - 0.93664\n",
      "column: TransactionAmt_DT_W_std_score - 0.93667\n",
      "column: TransactionAmt_DT_M_min_max - 0.93654\n",
      "column: TransactionAmt_DT_M_std_score - 0.93672\n",
      "column: product_type - 0.93656\n",
      "column: product_type_DT_D - 0.9363\n",
      "column: product_type_DT_W - 0.93661\n",
      "column: product_type_DT_M - 0.93656\n"
     ]
    }
   ],
   "source": [
    "df = train_df\n",
    "n = df.shape[0]\n",
    "valid_idx = list(df.index[int(n*0.8):])\n",
    "X_val, y_val = df.loc[valid_idx, features], df.loc[valid_idx, TARGET]\n",
    "\n",
    "per_res = permutation_importance_lgb(model, X_val, y_val, roc_auc_score, features[425:713], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "655\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.95558\tvalid_1's auc: 0.89924\n",
      "[200]\ttraining's auc: 0.976481\tvalid_1's auc: 0.913529\n",
      "[300]\ttraining's auc: 0.988257\tvalid_1's auc: 0.922833\n",
      "[400]\ttraining's auc: 0.994459\tvalid_1's auc: 0.928262\n",
      "[500]\ttraining's auc: 0.997521\tvalid_1's auc: 0.931148\n",
      "[600]\ttraining's auc: 0.998971\tvalid_1's auc: 0.932859\n",
      "[700]\ttraining's auc: 0.999603\tvalid_1's auc: 0.934166\n",
      "[800]\ttraining's auc: 0.999857\tvalid_1's auc: 0.934988\n",
      "[900]\ttraining's auc: 0.999955\tvalid_1's auc: 0.935522\n",
      "[1000]\ttraining's auc: 0.999989\tvalid_1's auc: 0.93602\n",
      "[1100]\ttraining's auc: 0.999998\tvalid_1's auc: 0.936379\n",
      "[1200]\ttraining's auc: 1\tvalid_1's auc: 0.936601\n",
      "[1300]\ttraining's auc: 1\tvalid_1's auc: 0.936892\n",
      "[1400]\ttraining's auc: 1\tvalid_1's auc: 0.937034\n",
      "Early stopping, best iteration is:\n",
      "[1370]\ttraining's auc: 1\tvalid_1's auc: 0.936953\n"
     ]
    }
   ],
   "source": [
    "remove_features1 = remove_features + [x for x in per_res if x!= 'base_score' and  per_res[x]>=0.9367]\n",
    "features = [x for x in train_df.columns if x not in remove_features1 and train_df[x].dtype != 'object'\n",
    "          #  and not re.match('uid[0-9]{0,1}_DT_', x)\n",
    "           ]\n",
    "print(len(features))\n",
    "_, model = local_valid(train_df, 'isFraud', features, lgb_params, return_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "537\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.952138\tvalid_1's auc: 0.89808\n",
      "[200]\ttraining's auc: 0.973643\tvalid_1's auc: 0.912771\n",
      "[300]\ttraining's auc: 0.986082\tvalid_1's auc: 0.922297\n",
      "[400]\ttraining's auc: 0.992921\tvalid_1's auc: 0.928216\n",
      "[500]\ttraining's auc: 0.996648\tvalid_1's auc: 0.931149\n",
      "[600]\ttraining's auc: 0.998522\tvalid_1's auc: 0.932864\n",
      "[700]\ttraining's auc: 0.999388\tvalid_1's auc: 0.934126\n",
      "[800]\ttraining's auc: 0.999761\tvalid_1's auc: 0.935002\n",
      "[900]\ttraining's auc: 0.999916\tvalid_1's auc: 0.935646\n",
      "[1000]\ttraining's auc: 0.999974\tvalid_1's auc: 0.936198\n",
      "[1100]\ttraining's auc: 0.999994\tvalid_1's auc: 0.936469\n",
      "[1200]\ttraining's auc: 0.999999\tvalid_1's auc: 0.936584\n",
      "[1300]\ttraining's auc: 1\tvalid_1's auc: 0.936951\n",
      "[1400]\ttraining's auc: 1\tvalid_1's auc: 0.937082\n",
      "[1500]\ttraining's auc: 1\tvalid_1's auc: 0.937367\n",
      "Early stopping, best iteration is:\n",
      "[1494]\ttraining's auc: 1\tvalid_1's auc: 0.937331\n"
     ]
    }
   ],
   "source": [
    "remove_features1 = remove_features + [x for x in per_res if x!= 'base_score' and  per_res[x]>=0.9366]\n",
    "features = [x for x in train_df.columns if x not in remove_features1 and train_df[x].dtype != 'object'\n",
    "          #  and not re.match('uid[0-9]{0,1}_DT_', x)\n",
    "           ]\n",
    "print(len(features))\n",
    "_, model = local_valid(train_df, 'isFraud', features, lgb_params, return_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's auc: 0.942788\n",
      "[200]\ttraining's auc: 0.96878\n",
      "[300]\ttraining's auc: 0.983268\n",
      "[400]\ttraining's auc: 0.99096\n",
      "[500]\ttraining's auc: 0.995133\n",
      "[600]\ttraining's auc: 0.997398\n",
      "[700]\ttraining's auc: 0.99862\n",
      "[800]\ttraining's auc: 0.999247\n",
      "[900]\ttraining's auc: 0.999587\n",
      "[1000]\ttraining's auc: 0.99977\n",
      "[1100]\ttraining's auc: 0.999872\n",
      "[1200]\ttraining's auc: 0.999931\n",
      "[1300]\ttraining's auc: 0.999962\n",
      "[1400]\ttraining's auc: 0.999981\n",
      "[1500]\ttraining's auc: 0.99999\n",
      "[1600]\ttraining's auc: 0.999995\n",
      "[1700]\ttraining's auc: 0.999998\n",
      "[1800]\ttraining's auc: 0.999999\n",
      "[1900]\ttraining's auc: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.7,\n",
       "        importance_type='split', learning_rate=0.01, max_bin=255,\n",
       "        max_depth=-1, metric='auc', min_child_samples=20,\n",
       "        min_child_weight=0.001, min_split_gain=0.0, n_estimators=1900,\n",
       "        n_jobs=-1, num_leaves=256, objective='binary', random_state=None,\n",
       "        reg_alpha=0.0, reg_lambda=0.0, seed=42, silent=True, subsample=0.7,\n",
       "        subsample_for_bin=200000, subsample_freq=1, tree_learner='serial',\n",
       "        verbose=100)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_features += [x for x in per_res if x!= 'base_score' and  per_res[x]>=0.9366]\n",
    "features = [x for x in train_df.columns if x not in remove_features and train_df[x].dtype != 'object'\n",
    "          #  and not re.match('uid[0-9]{0,1}_DT_', x)\n",
    "           ]\n",
    "params = {\n",
    "                    'objective':'binary',\n",
    "                    'boosting_type':'gbdt',\n",
    "                    'metric':'auc',\n",
    "                    'n_jobs':-1,\n",
    "                    'learning_rate':0.01,\n",
    "                    'num_leaves': 2**8,\n",
    "                    'max_depth':-1,\n",
    "                    'tree_learner':'serial',\n",
    "                    'colsample_bytree': 0.7,\n",
    "                    'subsample_freq':1,\n",
    "                    'subsample':0.7,\n",
    "                    'n_estimators': 1900,\n",
    "                    'max_bin':255,\n",
    "                    'verbose':100,\n",
    "                    'seed': SEED,\n",
    "                }\n",
    "X_train = train_df[features]\n",
    "y_train = train_df['isFraud']\n",
    "model = lgb.LGBMClassifier(**params)\n",
    "model.fit(X_train, y_train, \n",
    "        eval_set=[(X_train, y_train)], eval_metric='auc', verbose=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506691, 806)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "test_df = pickle.load(open('../input/df_test_baseline.pkl', 'rb'))\n",
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['isFraud'] = model.predict_proba(test_df[features])[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[['TransactionID', 'isFraud']].to_csv('../baseline_0914.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
